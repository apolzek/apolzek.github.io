{
    "version": "https://jsonfeed.org/version/1",
    "title": "apolzek",
    "home_page_url": "https://apolzek.github.io/",
    "feed_url": "https://apolzek.github.io/feed.json",
    "description": "üî•",
    "icon": "https://apolzek.github.io/apple-touch-icon.png",
    "favicon": "https://apolzek.github.io/favicon.ico",
    "expired": false,
    
    "author":  {
        "name": "apolzek",
        "url": null,
        "avatar": null
    },
    
"items": [
    
        {
            "id": "https://apolzek.github.io/2025/10/13/sre-interview-questions",
            "title": "SRE interview questions",
            "summary": null,
            "content_text": "If you could choose one person to share trenches with, what qualities and skills would you prioritize?Although I have a solid foundation in various technology topics and in-depth knowledge in many of them, I still lack the confidence to conduct interviews. You never know what you might encounter on the other side. Regardless, I would like to share my thought process for conducting a technical interview for the position of Site Reliability Engineer or DevOps Engineer.NetworkingSuppose you have a proxy that operates at the TCP level and another that operates only at the HTTP level. What are the main implications of this configuration? How can these differences affect error handling, security, and network scalability ?KubernetesIn the context of Kubernetes, you are designing an application that requires different pod management strategies to meet specific requirements. Explain how you would utilize ReplicaSets, Deployments, StatefulSets, and DaemonSets to address these needs. In particular, discuss the ideal use cases for each of these objects and how they behave in relation to scalability, data persistence, and version updates. Additionally, what considerations should you keep in mind when choosing between these types of pod controllers for different components of your application ?PrometheusIn the context of monitoring with Prometheus, you encounter a cardinality problem where the number of time series becomes excessive, resulting in performance degradation and excessive resource usage. What are the common causes of cardinality issues in Prometheus, and what strategies can you employ to mitigate these problems ?CI/CDIn a continuous integration and continuous delivery (CI/CD) environment, the execution time of pipelines can significantly impact the speed of development and software delivery. What techniques and practices would you implement to optimize the execution time of CI/CD pipelines?You are managing a project that uses Jenkins for continuous integration and GitLab CI for continuous delivery. Discuss how you would integrate these two tools into a unified CI/CD workflow. What considerations would you have regarding pipeline configuration, credential management, and infrastructure versioning? Additionally, analyze the advantages and disadvantages of using Jenkins alongside GitLab CI, considering aspects such as flexibility, scalability, and maintenance complexity.",
            "content_html": "<p>If you could choose one person to share trenches with, what qualities and skills would you prioritize?</p><p>Although I have a solid foundation in various technology topics and in-depth knowledge in many of them, I still lack the confidence to conduct interviews. You never know what you might encounter on the other side. Regardless, I would like to share my thought process for conducting a technical interview for the position of Site Reliability Engineer or DevOps Engineer.</p><h2 id=\"networking\">Networking</h2><p>Suppose you have a proxy that operates at the TCP level and another that operates only at the HTTP level. What are the main implications of this configuration? How can these differences affect error handling, security, and network scalability ?</p><h2 id=\"kubernetes\">Kubernetes</h2><p>In the context of Kubernetes, you are designing an application that requires different pod management strategies to meet specific requirements. Explain how you would utilize ReplicaSets, Deployments, StatefulSets, and DaemonSets to address these needs. In particular, discuss the ideal use cases for each of these objects and how they behave in relation to scalability, data persistence, and version updates. Additionally, what considerations should you keep in mind when choosing between these types of pod controllers for different components of your application ?</p><h2 id=\"prometheus\">Prometheus</h2><p>In the context of monitoring with Prometheus, you encounter a cardinality problem where the number of time series becomes excessive, resulting in performance degradation and excessive resource usage. What are the common causes of cardinality issues in Prometheus, and what strategies can you employ to mitigate these problems ?</p><h2 id=\"cicd\">CI/CD</h2><p>In a continuous integration and continuous delivery (CI/CD) environment, the execution time of pipelines can significantly impact the speed of development and software delivery. What techniques and practices would you implement to optimize the execution time of CI/CD pipelines?</p><p>You are managing a project that uses Jenkins for continuous integration and GitLab CI for continuous delivery. Discuss how you would integrate these two tools into a unified CI/CD workflow. What considerations would you have regarding pipeline configuration, credential management, and infrastructure versioning? Additionally, analyze the advantages and disadvantages of using Jenkins alongside GitLab CI, considering aspects such as flexibility, scalability, and maintenance complexity.</p>",
            "url": "https://apolzek.github.io/2025/10/13/sre-interview-questions",
            
            
            
            "tags": ["sre","interview"],
            
            "date_published": "2025-10-13T00:00:00+00:00",
            "date_modified": "2025-10-13T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/13/review-nixos",
            "title": "üêß REVIEW NixOS",
            "summary": null,
            "content_text": "",
            "content_html": "",
            "url": "https://apolzek.github.io/2025/10/13/review-nixos",
            
            
            
            "tags": ["os","review","nixos,","linux,","distro"],
            
            "date_published": "2025-10-13T00:00:00+00:00",
            "date_modified": "2025-10-13T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/13/lets-talk-about-amazon-elasticache",
            "title": "Let's talk about Amazon ElastiCache",
            "summary": null,
            "content_text": "            Configura√ß√£o      Modo      Nodes      Shards      R√©plicas por Shard      Total R√©plicas                  1 Node, 1 Shard, Sem R√©plica      Sem Cluster      1      1      0      0              2 Nodes, 1 Shard, 1 R√©plica      Sem Cluster      2      1      1      1              3 Nodes, 1 Shard, 2 R√©plicas      Sem Cluster      3      1      2      2              4 Nodes, 1 Shard, 3 R√©plicas      Sem Cluster      4      1      3      3              2 Nodes, 1 Shard, 1 R√©plica      Cluster      2      1      1      1              4 Nodes, 2 Shards, 1 R√©plica      Cluster      4      2      1      2              6 Nodes, 3 Shards, 1 R√©plica      Cluster      6      3      1      3              8 Nodes, 4 Shards, 1 R√©plica      Cluster      8      4      1      4      ",
            "content_html": "<table>  <thead>    <tr>      <th>Configura√ß√£o</th>      <th>Modo</th>      <th>Nodes</th>      <th>Shards</th>      <th>R√©plicas por Shard</th>      <th>Total R√©plicas</th>    </tr>  </thead>  <tbody>    <tr>      <td>1 Node, 1 Shard, Sem R√©plica</td>      <td>Sem Cluster</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <td>2 Nodes, 1 Shard, 1 R√©plica</td>      <td>Sem Cluster</td>      <td>2</td>      <td>1</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <td>3 Nodes, 1 Shard, 2 R√©plicas</td>      <td>Sem Cluster</td>      <td>3</td>      <td>1</td>      <td>2</td>      <td>2</td>    </tr>    <tr>      <td>4 Nodes, 1 Shard, 3 R√©plicas</td>      <td>Sem Cluster</td>      <td>4</td>      <td>1</td>      <td>3</td>      <td>3</td>    </tr>    <tr>      <td>2 Nodes, 1 Shard, 1 R√©plica</td>      <td>Cluster</td>      <td>2</td>      <td>1</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <td>4 Nodes, 2 Shards, 1 R√©plica</td>      <td>Cluster</td>      <td>4</td>      <td>2</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <td>6 Nodes, 3 Shards, 1 R√©plica</td>      <td>Cluster</td>      <td>6</td>      <td>3</td>      <td>1</td>      <td>3</td>    </tr>    <tr>      <td>8 Nodes, 4 Shards, 1 R√©plica</td>      <td>Cluster</td>      <td>8</td>      <td>4</td>      <td>1</td>      <td>4</td>    </tr>  </tbody></table>",
            "url": "https://apolzek.github.io/2025/10/13/lets-talk-about-amazon-elasticache",
            
            
            
            "tags": ["aws","redis","elasticache"],
            
            "date_published": "2025-10-13T00:00:00+00:00",
            "date_modified": "2025-10-13T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/13/crew",
            "title": "CREW",
            "summary": null,
            "content_text": "Collaborative Reliability Engineering Workforce            Subgroup      Description                  OpenSource Tools      Tools that are freely available and have open source code, allowing customization and contributions from the community.              Kubernetes Ecosystem      A suite of tools and services that work with Kubernetes to enhance container orchestration and manage microservices.              Fundamentals      Basic principles and foundational knowledge required to understand and work effectively with a system or technology.              Internal Solutions      Custom-built tools or software developed within an organization to meet specific internal needs.              News/Notifications      Updates, announcements, or alerts related to industry trends, technology advancements, or system status.              Cloud      Infrastructure, services, and platforms delivered over the internet, providing scalable computing resources.      ",
            "content_html": "<h2 id=\"collaborative-reliability-engineering-workforce\">Collaborative Reliability Engineering Workforce</h2><table>  <thead>    <tr>      <th>Subgroup</th>      <th>Description</th>    </tr>  </thead>  <tbody>    <tr>      <td>OpenSource Tools</td>      <td>Tools that are freely available and have open source code, allowing customization and contributions from the community.</td>    </tr>    <tr>      <td>Kubernetes Ecosystem</td>      <td>A suite of tools and services that work with Kubernetes to enhance container orchestration and manage microservices.</td>    </tr>    <tr>      <td>Fundamentals</td>      <td>Basic principles and foundational knowledge required to understand and work effectively with a system or technology.</td>    </tr>    <tr>      <td>Internal Solutions</td>      <td>Custom-built tools or software developed within an organization to meet specific internal needs.</td>    </tr>    <tr>      <td>News/Notifications</td>      <td>Updates, announcements, or alerts related to industry trends, technology advancements, or system status.</td>    </tr>    <tr>      <td>Cloud</td>      <td>Infrastructure, services, and platforms delivered over the internet, providing scalable computing resources.</td>    </tr>  </tbody></table>",
            "url": "https://apolzek.github.io/2025/10/13/crew",
            
            
            
            "tags": ["team","sre"],
            
            "date_published": "2025-10-13T00:00:00+00:00",
            "date_modified": "2025-10-13T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/10/special-ops-team",
            "title": "Special Ops Team",
            "summary": null,
            "content_text": "",
            "content_html": "",
            "url": "https://apolzek.github.io/2025/10/10/special-ops-team",
            
            
            
            "tags": ["team","ops"],
            
            "date_published": "2025-10-10T00:00:00+00:00",
            "date_modified": "2025-10-10T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/10/review-of-computer-networks",
            "title": "Review of computer networks",
            "summary": null,
            "content_text": "",
            "content_html": "",
            "url": "https://apolzek.github.io/2025/10/10/review-of-computer-networks",
            
            
            
            
            
            "date_published": "2025-10-10T00:00:00+00:00",
            "date_modified": "2025-10-10T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/10/nixos",
            "title": "NixOS",
            "summary": null,
            "content_text": "scala examplecurl -L https://nixos.org/nix/install | shsource ~/.nix-profile/etc/profile.d/nix.shmkdir hello-scalacd hello-scala{ pkgs ? import &lt;nixpkgs&gt; {} }:pkgs.mkShell {  buildInputs = [ pkgs.scala pkgs.sbt ];}  shell.nixnix-shellsbt new scala/scala-seed.g8cd   # Substitua pelo nome do seu projetocd src/main/scalatouch HelloWorld.scalaobject HelloWorld {  def main(args: Array[String]): Unit = {    println(\"Hello, World!\")  }}  HelloWorld.scalacd ../../..sbt run",
            "content_html": "<h2 id=\"scala-example\">scala example</h2><div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>curl -L https://nixos.org/nix/install | shsource ~/.nix-profile/etc/profile.d/nix.shmkdir hello-scalacd hello-scala</code></pre></div></div><div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>{ pkgs ? import &lt;nixpkgs&gt; {} }:pkgs.mkShell {  buildInputs = [ pkgs.scala pkgs.sbt ];}</code></pre></div></div><blockquote>  <p>shell.nix</p></blockquote><p>nix-shellsbt new scala/scala-seed.g8cd <nome-do-projeto>  # Substitua pelo nome do seu projetocd src/main/scalatouch HelloWorld.scala</nome-do-projeto></p><div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>object HelloWorld {  def main(args: Array[String]): Unit = {    println(\"Hello, World!\")  }}</code></pre></div></div><blockquote>  <p>HelloWorld.scala</p></blockquote><p>cd ../../..<br />sbt run</p>",
            "url": "https://apolzek.github.io/2025/10/10/nixos",
            
            
            
            "tags": ["nix","os","distro","linux"],
            
            "date_published": "2025-10-10T00:00:00+00:00",
            "date_modified": "2025-10-10T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/10/l0calh0t-startup-day2",
            "title": "üí° l0calh0t Startup - day 2",
            "summary": "Building the l0calh0t Startup",
            "content_text": "render.com.. The solution is amazing, and the free tier surprised meSince my idea has A LOT to do with what render.com offers, it makes total sense for me to learn from them. First off, just know that they‚Äôre good. I‚Äôve already liked a lot of what I found on their free tier. I‚Äôll dive into the details here and connect it to some technical concepts just to get the wheels turning on architecture and product thinking.",
            "content_html": "<h2 id=\"rendercom-the-solution-is-amazing-and-the-free-tier-surprised-me\">render.com.. The solution is amazing, and the free tier surprised me</h2><p>Since my idea has A LOT to do with what <strong>render.com</strong> offers, it makes total sense for me to learn from them. First off, just know that they‚Äôre good. I‚Äôve already liked a lot of what I found on their free tier. I‚Äôll dive into the details here and connect it to some technical concepts just to get the wheels turning on architecture and product thinking.</p>",
            "url": "https://apolzek.github.io/2025/10/10/l0calh0t-startup-day2",
            
            
            
            "tags": ["devops","sre","project","startup"],
            
            "date_published": "2025-10-10T00:00:00+00:00",
            "date_modified": "2025-10-10T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/10/getting-started-x-production-ready",
            "title": "The distance between \"getting started\" and \"production ready\"",
            "summary": null,
            "content_text": "When embarking on the journey of implementing a new tool, it is essential to recognize the significant gap between the initial ‚Äúgetting started‚Äù phase and achieving a fully functional production-ready system. In the beginning, users often interact with a simplified version of the tool, which showcases its basic functionalities. However, to fully harness the capabilities of the tool and integrate it into the organization‚Äôs ecosystem, several critical aspects must be addressed.Deployment is one of the first challenges encountered when moving from a basic setup to a production-ready state. In the initial stages, deployment may be as straightforward as running a local instance. However, in a production environment, organizations must consider robust deployment strategies, including automated deployment pipelines, continuous integration/continuous deployment (CI/CD) practices, and the use of containerization technologies such as Docker. These practices ensure that the tool can be deployed seamlessly, with minimal downtime and maximum efficiency.Scalability is another crucial factor that differentiates basic usage from a production-ready application. While a basic setup may function adequately for a small number of users or limited workloads, production environments must accommodate growth. This requires careful planning for horizontal and vertical scaling, load balancing, and resource allocation to ensure that the tool can handle increasing demands without compromising performance or user experience.The adaptation to company processes is also vital in this transition. A basic implementation might showcase generic use cases, but to be effective in a production environment, the tool must align with the specific workflows and procedures of the organization. This may involve customizing features, integrating with existing systems, and training employees to ensure that the tool complements their daily tasks and contributes to overall productivity.Security is a paramount concern when moving towards production readiness. Initial setups may overlook critical security protocols, while a production-ready tool must implement stringent security measures. This includes user authentication and authorization, data encryption, secure APIs, and compliance with industry regulations. Organizations must also conduct regular security audits and vulnerability assessments to protect sensitive data and maintain trust with users.Traceability is another important aspect that sets a production-ready tool apart from its basic counterpart. In a production environment, tracking changes, actions, and data flows becomes essential for accountability and compliance. Implementing features like audit logs, change tracking, and comprehensive reporting enables organizations to maintain oversight and transparency in their operations.Permissioning is a vital component of ensuring that users have appropriate access levels to various functionalities and data within the tool. In the basic mode, permission settings may be minimal, but in a production environment, fine-grained access control is essential. This allows organizations to enforce the principle of least privilege, ensuring that users can only access the information and functions necessary for their roles.Lastly, organizations must consider the Software Development Operations (SDOX) aspect, which encompasses the entire lifecycle of the tool‚Äîfrom development and deployment to maintenance and support. In a production-ready setup, this requires a well-defined process for software updates, user feedback, and incident management to ensure continuous improvement and responsiveness to user needs.In conclusion, while the ‚Äúgetting started‚Äù phase of a tool provides a valuable introduction to its functionalities, the journey towards a production-ready state is complex and multifaceted. Organizations must invest time and resources to address deployment strategies, scalability, process adaptation, security measures, traceability, permissioning, and SDOX practices. Only then can they fully leverage the tool‚Äôs potential and ensure it aligns with their operational goals.",
            "content_html": "<p>When embarking on the journey of implementing a new tool, it is essential to recognize the significant gap between the initial ‚Äúgetting started‚Äù phase and achieving a fully functional production-ready system. In the beginning, users often interact with a simplified version of the tool, which showcases its basic functionalities. However, to fully harness the capabilities of the tool and integrate it into the organization‚Äôs ecosystem, several critical aspects must be addressed.</p><p>Deployment is one of the first challenges encountered when moving from a basic setup to a production-ready state. In the initial stages, deployment may be as straightforward as running a local instance. However, in a production environment, organizations must consider robust deployment strategies, including automated deployment pipelines, continuous integration/continuous deployment (CI/CD) practices, and the use of containerization technologies such as Docker. These practices ensure that the tool can be deployed seamlessly, with minimal downtime and maximum efficiency.</p><p>Scalability is another crucial factor that differentiates basic usage from a production-ready application. While a basic setup may function adequately for a small number of users or limited workloads, production environments must accommodate growth. This requires careful planning for horizontal and vertical scaling, load balancing, and resource allocation to ensure that the tool can handle increasing demands without compromising performance or user experience.</p><p>The adaptation to company processes is also vital in this transition. A basic implementation might showcase generic use cases, but to be effective in a production environment, the tool must align with the specific workflows and procedures of the organization. This may involve customizing features, integrating with existing systems, and training employees to ensure that the tool complements their daily tasks and contributes to overall productivity.</p><p>Security is a paramount concern when moving towards production readiness. Initial setups may overlook critical security protocols, while a production-ready tool must implement stringent security measures. This includes user authentication and authorization, data encryption, secure APIs, and compliance with industry regulations. Organizations must also conduct regular security audits and vulnerability assessments to protect sensitive data and maintain trust with users.</p><p>Traceability is another important aspect that sets a production-ready tool apart from its basic counterpart. In a production environment, tracking changes, actions, and data flows becomes essential for accountability and compliance. Implementing features like audit logs, change tracking, and comprehensive reporting enables organizations to maintain oversight and transparency in their operations.</p><p>Permissioning is a vital component of ensuring that users have appropriate access levels to various functionalities and data within the tool. In the basic mode, permission settings may be minimal, but in a production environment, fine-grained access control is essential. This allows organizations to enforce the principle of least privilege, ensuring that users can only access the information and functions necessary for their roles.</p><p>Lastly, organizations must consider the Software Development Operations (SDOX) aspect, which encompasses the entire lifecycle of the tool‚Äîfrom development and deployment to maintenance and support. In a production-ready setup, this requires a well-defined process for software updates, user feedback, and incident management to ensure continuous improvement and responsiveness to user needs.</p><p>In conclusion, while the ‚Äúgetting started‚Äù phase of a tool provides a valuable introduction to its functionalities, the journey towards a production-ready state is complex and multifaceted. Organizations must invest time and resources to address deployment strategies, scalability, process adaptation, security measures, traceability, permissioning, and SDOX practices. Only then can they fully leverage the tool‚Äôs potential and ensure it aligns with their operational goals.</p>",
            "url": "https://apolzek.github.io/2025/10/10/getting-started-x-production-ready",
            
            
            
            
            
            "date_published": "2025-10-10T00:00:00+00:00",
            "date_modified": "2025-10-10T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/10/entropy-in-the-corporate-world",
            "title": "Entropy in the Corporate World",
            "summary": null,
            "content_text": "What results from not cleaning your house regularly ?The subject discussed here is entropy, obviously‚Ä¶ so I‚Äôll start by saying the obvious and then pull out some threads for reflection.Entropy in a corporate environment refers to the natural tendency for things to become disorganized or chaotic over time. It‚Äôs like how your desk gets messy if you don‚Äôt clean it up regularly, or how projects can spin out of control without proper management. In the business world, this concept applies to everything from company processes to team dynamics.As businesses grow or face changes‚Äîwhether it‚Äôs new technology, market shifts, or internal restructuring‚Äîthings can become increasingly complex and harder to manage. Without regular attention, processes can slow down, communication can break down, and overall efficiency drops. This is corporate entropy in action: the gradual decline into disorder unless steps are taken to maintain structure.Leaders and managers often have to deal with this by putting systems in place to keep the ‚Äúchaos‚Äù under control. They use strategies like improving communication, streamlining workflows, or even bringing in new tech to reduce entropy and keep the company running smoothly.In essence, entropy is just a reminder that without constant effort to maintain order, things in the business world can quickly become chaotic, leading to inefficiency and potential failure. It‚Äôs why companies need to stay proactive in managing change and complexity.Different roles and what they really wantIn the world of technology, there are numerous roles such as Software Engineer, DevOps Engineer, Security Analyst, Project Manager, Software Architect, Data Analyst, Data Engineer, Data Scientist, Network Engineer, IT Manager, User Experience Designer, Technical Support Analyst, AI Specialist, Database Administrator, Cloud Specialist, Quality Engineer, Systems Analyst, and many more. To keep it concise, we‚Äôll focus on detailing just a few of these. There‚Äôs a purpose behind this, and I‚Äôll explain it to you shortly.SREAs SREs, our main goal is to make sure our service levels are always met. We want to maintain a healthy and stable system/product, one that can be updated without causing disruptions. It‚Äôs crucial to have visibility into its state and all its components. We need to collaborate effectively with a strong focus on security, stay within budget, automate repetitive tasks, and be prepared to handle any potential incidents swiftly and efficiently.DBREA Database Reliability Engineer (DBRE) aims to ensure that databases are always reliable, highly available, and optimized for performance. Their main goal is to maintain the stability and scalability of database systems, ensuring they can handle increasing loads without sacrificing efficiency. They focus on automating database management tasks like backups, scaling, and monitoring, while ensuring data security and integrity. A DBRE wants a database that is resilient, can be updated or maintained without downtime, and operates efficiently under all conditions, providing a solid foundation for applications to run smoothly.Software EngineerA Software Engineer focuses on designing, developing, and maintaining reliable and efficient software solutions. Their main goal is to build applications that are scalable, robust, and user-friendly, addressing both functionality and performance. They write clean, maintainable code and collaborate with teams to solve complex problems through software. A Software Engineer aims to deliver products that meet user needs, integrate seamlessly with other systems, and can evolve over time with minimal technical debt, ensuring the software remains flexible and adaptable as requirements change.Security AnalystA Security Analyst is responsible for protecting an organization‚Äôs information systems and sensitive data from cyber threats. Their main goal is to identify vulnerabilities, monitor for security breaches, and respond to incidents to mitigate risks. They conduct regular security assessments, implement security policies, and ensure compliance with regulations and standards. A Security Analyst analyzes security events, investigates potential threats, and collaborates with other teams to strengthen the organization‚Äôs overall security posture. Ultimately, they aim to create a secure environment that safeguards the organization‚Äôs assets and maintains the trust of customers and stakeholders.ManagerA Manager plays a crucial role in guiding and overseeing teams to achieve organizational goals. Their main responsibility is to plan, coordinate, and execute projects while ensuring that team members have the resources and support they need to succeed. Managers focus on setting clear objectives, monitoring progress, and fostering a positive work environment that encourages collaboration and productivity. They also handle budgeting, performance evaluations, and conflict resolution, ensuring that the team operates efficiently and effectively. Ultimately, a Manager aims to align team efforts with the company‚Äôs vision, drive results, and facilitate professional development for team members.Demotivating technical people",
            "content_html": "<h2 id=\"what-results-from-not-cleaning-your-house-regularly-\">What results from not cleaning your house regularly ?</h2><p>The subject discussed here is entropy, obviously‚Ä¶ so I‚Äôll start by saying the obvious and then pull out some threads for reflection.</p><p>Entropy in a corporate environment refers to the natural tendency for things to become disorganized or chaotic over time. It‚Äôs like how your desk gets messy if you don‚Äôt clean it up regularly, or how projects can spin out of control without proper management. In the business world, this concept applies to everything from company processes to team dynamics.</p><p>As businesses grow or face changes‚Äîwhether it‚Äôs new technology, market shifts, or internal restructuring‚Äîthings can become increasingly complex and harder to manage. Without regular attention, processes can slow down, communication can break down, and overall efficiency drops. This is corporate entropy in action: the gradual decline into disorder unless steps are taken to maintain structure.</p><p>Leaders and managers often have to deal with this by putting systems in place to keep the ‚Äúchaos‚Äù under control. They use strategies like improving communication, streamlining workflows, or even bringing in new tech to reduce entropy and keep the company running smoothly.</p><p>In essence, entropy is just a reminder that without constant effort to maintain order, things in the business world can quickly become chaotic, leading to inefficiency and potential failure. It‚Äôs why companies need to stay proactive in managing change and complexity.</p><h2 id=\"different-roles-and-what-they-really-want\">Different roles and what they really want</h2><p>In the world of technology, there are numerous roles such as Software Engineer, DevOps Engineer, Security Analyst, Project Manager, Software Architect, Data Analyst, Data Engineer, Data Scientist, Network Engineer, IT Manager, User Experience Designer, Technical Support Analyst, AI Specialist, Database Administrator, Cloud Specialist, Quality Engineer, Systems Analyst, and many more. To keep it concise, we‚Äôll focus on detailing just a few of these. There‚Äôs a purpose behind this, and I‚Äôll explain it to you shortly.</p><h3 id=\"sre\">SRE</h3><p>As SREs, our main goal is to make sure our service levels are always met. We want to maintain a healthy and stable system/product, one that can be updated without causing disruptions. It‚Äôs crucial to have visibility into its state and all its components. We need to collaborate effectively with a strong focus on security, stay within budget, automate repetitive tasks, and be prepared to handle any potential incidents swiftly and efficiently.</p><h3 id=\"dbre\">DBRE</h3><p>A Database Reliability Engineer (DBRE) aims to ensure that databases are always reliable, highly available, and optimized for performance. Their main goal is to maintain the stability and scalability of database systems, ensuring they can handle increasing loads without sacrificing efficiency. They focus on automating database management tasks like backups, scaling, and monitoring, while ensuring data security and integrity. A DBRE wants a database that is resilient, can be updated or maintained without downtime, and operates efficiently under all conditions, providing a solid foundation for applications to run smoothly.</p><h3 id=\"software-engineer\">Software Engineer</h3><p>A Software Engineer focuses on designing, developing, and maintaining reliable and efficient software solutions. Their main goal is to build applications that are scalable, robust, and user-friendly, addressing both functionality and performance. They write clean, maintainable code and collaborate with teams to solve complex problems through software. A Software Engineer aims to deliver products that meet user needs, integrate seamlessly with other systems, and can evolve over time with minimal technical debt, ensuring the software remains flexible and adaptable as requirements change.</p><h3 id=\"security-analyst\">Security Analyst</h3><p>A Security Analyst is responsible for protecting an organization‚Äôs information systems and sensitive data from cyber threats. Their main goal is to identify vulnerabilities, monitor for security breaches, and respond to incidents to mitigate risks. They conduct regular security assessments, implement security policies, and ensure compliance with regulations and standards. A Security Analyst analyzes security events, investigates potential threats, and collaborates with other teams to strengthen the organization‚Äôs overall security posture. Ultimately, they aim to create a secure environment that safeguards the organization‚Äôs assets and maintains the trust of customers and stakeholders.</p><h3 id=\"manager\">Manager</h3><p>A Manager plays a crucial role in guiding and overseeing teams to achieve organizational goals. Their main responsibility is to plan, coordinate, and execute projects while ensuring that team members have the resources and support they need to succeed. Managers focus on setting clear objectives, monitoring progress, and fostering a positive work environment that encourages collaboration and productivity. They also handle budgeting, performance evaluations, and conflict resolution, ensuring that the team operates efficiently and effectively. Ultimately, a Manager aims to align team efforts with the company‚Äôs vision, drive results, and facilitate professional development for team members.</p><h2 id=\"demotivating-technical-people\">Demotivating technical people</h2>",
            "url": "https://apolzek.github.io/2025/10/10/entropy-in-the-corporate-world",
            
            
            
            
            
            "date_published": "2025-10-10T00:00:00+00:00",
            "date_modified": "2025-10-10T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/10/aws-iam",
            "title": "AWS IAM",
            "summary": null,
            "content_text": "IAM OverviewAWS Identity and Access Management (IAM) is a crucial service within Amazon Web Services (AWS) that helps organizations securely manage access to their cloud resources. Effective access management is vital for maintaining security and operational efficiency, especially in production environments where misconfigurations can lead to vulnerabilities.IAM Users, Groups, and Roles      IAM Users: These are individual identities within AWS, typically representing people or applications. Each user has specific credentials, such as access keys for programmatic access or passwords for the AWS Management Console. Users are granted permissions tailored to their roles‚Äîfor instance, a developer may access AWS Lambda and S3, while an application user might only need API Gateway access.        IAM Groups: Groups are collections of IAM users that share the same permissions. By assigning permissions to a group rather than individual users, organizations can simplify permission management, especially in larger teams. For example, a ‚ÄúDevelopers‚Äù group can be assigned permissions to deploy code, ensuring efficient access control.        IAM Roles: Roles are temporary identities that can be assumed by users or services. Unlike IAM users, roles do not have long-term credentials. They provide temporary security credentials, making them ideal for scenarios like allowing EC2 instances to access S3 without hardcoding credentials. Roles are also useful for cross-account access, enhancing security by limiting the exposure of long-term credentials.  Best Practices for IAM  Principle of Least Privilege: Grant users only the permissions they need to perform their tasks, reducing the risk of accidental or malicious misuse.  Avoid Using Root Account: The root account has unrestricted access and should be reserved for specific administrative tasks.  Implement Multi-Factor Authentication (MFA): MFA adds an extra layer of security, requiring users to verify their identity with a second factor, like a mobile device.  Regular Audits and Monitoring: Utilize tools like AWS CloudTrail to track who accesses what resources, helping to identify excessive permissions and unusual activity.By following these best practices, organizations can create a secure and efficient environment in AWS.Advanced IAM ConceptsAs organizations grow their use of AWS, managing permissions becomes more complex. Advanced features such as Permission Boundaries and Service Control Policies (SCPs) are essential for maintaining security in larger, multi-account setups.Permission BoundariesPermission Boundaries define the maximum permissions that IAM users or roles can have. They act as guardrails to prevent users from granting themselves excessive permissions. For instance, a DevOps team might be allowed to create new IAM roles but restricted from managing critical infrastructure.Service Control Policies (SCPs)SCPs work within AWS Organizations to control access across multiple accounts. They don‚Äôt grant permissions themselves but set the maximum allowable permissions in an account. SCPs are particularly useful for enforcing security policies, like restricting access to certain AWS regions or preventing risky actions across accounts.Advanced IAM Security Practices  IAM Policy Conditions: These allow for fine-tuning permissions based on attributes like IP addresses or specific time frames.  IAM Access Analyzer: This tool helps identify publicly shared resources or access to external accounts, highlighting potential security risks.  MFA Enforcement: Require users, especially those with privileged roles, to authenticate using MFA for sensitive actions.ConclusionAWS IAM offers a comprehensive set of tools for managing permissions in cloud environments. As organizations scale, leveraging advanced features like Permission Boundaries and SCPs becomes crucial for maintaining security and compliance. By implementing best practices and advanced techniques, organizations can effectively mitigate risks and ensure a robust security posture in their AWS environments.",
            "content_html": "<h2 id=\"iam-overview\">IAM Overview</h2><p>AWS Identity and Access Management (IAM) is a crucial service within Amazon Web Services (AWS) that helps organizations securely manage access to their cloud resources. Effective access management is vital for maintaining security and operational efficiency, especially in production environments where misconfigurations can lead to vulnerabilities.</p><h3 id=\"iam-users-groups-and-roles\">IAM Users, Groups, and Roles</h3><ul>  <li>    <p><strong>IAM Users</strong>: These are individual identities within AWS, typically representing people or applications. Each user has specific credentials, such as access keys for programmatic access or passwords for the AWS Management Console. Users are granted permissions tailored to their roles‚Äîfor instance, a developer may access AWS Lambda and S3, while an application user might only need API Gateway access.</p>  </li>  <li>    <p><strong>IAM Groups</strong>: Groups are collections of IAM users that share the same permissions. By assigning permissions to a group rather than individual users, organizations can simplify permission management, especially in larger teams. For example, a ‚ÄúDevelopers‚Äù group can be assigned permissions to deploy code, ensuring efficient access control.</p>  </li>  <li>    <p><strong>IAM Roles</strong>: Roles are temporary identities that can be assumed by users or services. Unlike IAM users, roles do not have long-term credentials. They provide temporary security credentials, making them ideal for scenarios like allowing EC2 instances to access S3 without hardcoding credentials. Roles are also useful for cross-account access, enhancing security by limiting the exposure of long-term credentials.</p>  </li></ul><h3 id=\"best-practices-for-iam\">Best Practices for IAM</h3><ol>  <li><strong>Principle of Least Privilege</strong>: Grant users only the permissions they need to perform their tasks, reducing the risk of accidental or malicious misuse.</li>  <li><strong>Avoid Using Root Account</strong>: The root account has unrestricted access and should be reserved for specific administrative tasks.</li>  <li><strong>Implement Multi-Factor Authentication (MFA)</strong>: MFA adds an extra layer of security, requiring users to verify their identity with a second factor, like a mobile device.</li>  <li><strong>Regular Audits and Monitoring</strong>: Utilize tools like AWS CloudTrail to track who accesses what resources, helping to identify excessive permissions and unusual activity.</li></ol><p>By following these best practices, organizations can create a secure and efficient environment in AWS.</p><h2 id=\"advanced-iam-concepts\">Advanced IAM Concepts</h2><p>As organizations grow their use of AWS, managing permissions becomes more complex. Advanced features such as <strong>Permission Boundaries</strong> and <strong>Service Control Policies (SCPs)</strong> are essential for maintaining security in larger, multi-account setups.</p><h3 id=\"permission-boundaries\">Permission Boundaries</h3><p>Permission Boundaries define the maximum permissions that IAM users or roles can have. They act as guardrails to prevent users from granting themselves excessive permissions. For instance, a DevOps team might be allowed to create new IAM roles but restricted from managing critical infrastructure.</p><h3 id=\"service-control-policies-scps\">Service Control Policies (SCPs)</h3><p>SCPs work within AWS Organizations to control access across multiple accounts. They don‚Äôt grant permissions themselves but set the maximum allowable permissions in an account. SCPs are particularly useful for enforcing security policies, like restricting access to certain AWS regions or preventing risky actions across accounts.</p><h3 id=\"advanced-iam-security-practices\">Advanced IAM Security Practices</h3><ol>  <li><strong>IAM Policy Conditions</strong>: These allow for fine-tuning permissions based on attributes like IP addresses or specific time frames.</li>  <li><strong>IAM Access Analyzer</strong>: This tool helps identify publicly shared resources or access to external accounts, highlighting potential security risks.</li>  <li><strong>MFA Enforcement</strong>: Require users, especially those with privileged roles, to authenticate using MFA for sensitive actions.</li></ol><h3 id=\"conclusion\">Conclusion</h3><p>AWS IAM offers a comprehensive set of tools for managing permissions in cloud environments. As organizations scale, leveraging advanced features like Permission Boundaries and SCPs becomes crucial for maintaining security and compliance. By implementing best practices and advanced techniques, organizations can effectively mitigate risks and ensure a robust security posture in their AWS environments.</p>",
            "url": "https://apolzek.github.io/2025/10/10/aws-iam",
            
            
            
            
            
            "date_published": "2025-10-10T00:00:00+00:00",
            "date_modified": "2025-10-10T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/10/09/shortcuts",
            "title": "shortcuts",
            "summary": null,
            "content_text": "VIM            Shortcut      Description                  i      Enter insert mode at cursor position.              I      Enter insert mode at the beginning of the current line.              a      Enter insert mode after the cursor position.              A      Enter insert mode at the end of the current line.              o      Open a new line below and enter insert mode.              O      Open a new line above and enter insert mode.              :w      Save (write) the current file.              :q      Quit Vim.              :wq      Save and quit.              :q!      Quit without saving.              u      Undo the last change.              Ctrl + r      Redo the last undone change.              yy      Yank (copy) the entire current line.              p      Paste the yanked text after the cursor.              P      Paste the yanked text before the cursor.              dd      Delete (cut) the entire current line.              dw      Delete (cut) from the cursor to the end of the current word.              d$      Delete (cut) from the cursor to the end of the line.              x      Delete (cut) the character under the cursor.              r      Replace the character under the cursor with a new one.              v      Enter visual mode (text selection).              V      Enter visual line mode (select entire lines).              Ctrl + v      Enter visual block mode (select rectangular blocks of text).              :s/foo/bar/g      Replace all occurrences of ‚Äúfoo‚Äù with ‚Äúbar‚Äù in the current line.              :%s/foo/bar/g      Replace all occurrences of ‚Äúfoo‚Äù with ‚Äúbar‚Äù in the entire file.              /pattern      Search for a pattern in the file.              n      Jump to the next occurrence of the search pattern.              N      Jump to the previous occurrence of the search pattern.              gg      Go to the beginning of the file.              G      Go to the end of the file.              :e filename      Open a new file named ‚Äúfilename‚Äù.              :bd      Close the current buffer (file).              Ctrl + o      Go to the last cursor position.              Ctrl + i      Go forward to the next cursor position.              Ctrl + z      Suspend Vim (send to background in terminal).              J      Join the current line with the line below it.              .      Repeat the last command.              %      Jump to the matching pair (e.g., parentheses, brackets).              :!command      Run a shell command from within Vim.              Ctrl + f      Scroll one page forward.              Ctrl + b      Scroll one page backward.              Ctrl + u      Scroll half a page up.              Ctrl + d      Scroll half a page down.              H      Move the cursor to the top of the screen.              M      Move the cursor to the middle of the screen.              L      Move the cursor to the bottom of the screen.              :help      Open Vim‚Äôs help documentation.      ",
            "content_html": "<h2 id=\"vim\">VIM</h2><table>  <thead>    <tr>      <th><strong>Shortcut</strong></th>      <th><strong>Description</strong></th>    </tr>  </thead>  <tbody>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">i</code></td>      <td>Enter insert mode at cursor position.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">I</code></td>      <td>Enter insert mode at the beginning of the current line.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">a</code></td>      <td>Enter insert mode after the cursor position.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">A</code></td>      <td>Enter insert mode at the end of the current line.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">o</code></td>      <td>Open a new line below and enter insert mode.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">O</code></td>      <td>Open a new line above and enter insert mode.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">:w</code></td>      <td>Save (write) the current file.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">:q</code></td>      <td>Quit Vim.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">:wq</code></td>      <td>Save and quit.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">:q!</code></td>      <td>Quit without saving.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">u</code></td>      <td>Undo the last change.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">Ctrl + r</code></td>      <td>Redo the last undone change.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">yy</code></td>      <td>Yank (copy) the entire current line.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">p</code></td>      <td>Paste the yanked text after the cursor.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">P</code></td>      <td>Paste the yanked text before the cursor.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">dd</code></td>      <td>Delete (cut) the entire current line.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">dw</code></td>      <td>Delete (cut) from the cursor to the end of the current word.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">d$</code></td>      <td>Delete (cut) from the cursor to the end of the line.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">x</code></td>      <td>Delete (cut) the character under the cursor.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">r</code></td>      <td>Replace the character under the cursor with a new one.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">v</code></td>      <td>Enter visual mode (text selection).</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">V</code></td>      <td>Enter visual line mode (select entire lines).</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">Ctrl + v</code></td>      <td>Enter visual block mode (select rectangular blocks of text).</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">:s/foo/bar/g</code></td>      <td>Replace all occurrences of ‚Äúfoo‚Äù with ‚Äúbar‚Äù in the current line.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">:%s/foo/bar/g</code></td>      <td>Replace all occurrences of ‚Äúfoo‚Äù with ‚Äúbar‚Äù in the entire file.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">/pattern</code></td>      <td>Search for a pattern in the file.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">n</code></td>      <td>Jump to the next occurrence of the search pattern.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">N</code></td>      <td>Jump to the previous occurrence of the search pattern.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">gg</code></td>      <td>Go to the beginning of the file.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">G</code></td>      <td>Go to the end of the file.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">:e filename</code></td>      <td>Open a new file named ‚Äúfilename‚Äù.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">:bd</code></td>      <td>Close the current buffer (file).</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">Ctrl + o</code></td>      <td>Go to the last cursor position.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">Ctrl + i</code></td>      <td>Go forward to the next cursor position.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">Ctrl + z</code></td>      <td>Suspend Vim (send to background in terminal).</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">J</code></td>      <td>Join the current line with the line below it.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">.</code></td>      <td>Repeat the last command.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">%</code></td>      <td>Jump to the matching pair (e.g., parentheses, brackets).</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">:!command</code></td>      <td>Run a shell command from within Vim.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">Ctrl + f</code></td>      <td>Scroll one page forward.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">Ctrl + b</code></td>      <td>Scroll one page backward.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">Ctrl + u</code></td>      <td>Scroll half a page up.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">Ctrl + d</code></td>      <td>Scroll half a page down.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">H</code></td>      <td>Move the cursor to the top of the screen.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">M</code></td>      <td>Move the cursor to the middle of the screen.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">L</code></td>      <td>Move the cursor to the bottom of the screen.</td>    </tr>    <tr>      <td><code class=\"language-plaintext highlighter-rouge\">:help</code></td>      <td>Open Vim‚Äôs help documentation.</td>    </tr>  </tbody></table>",
            "url": "https://apolzek.github.io/2025/10/09/shortcuts",
            
            
            
            
            
            "date_published": "2025-10-09T00:00:00+00:00",
            "date_modified": "2025-10-09T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/09/29/sre-kit-for-the-end-of-the-world",
            "title": "üõ†Ô∏è SRE Kit for the End of the World",
            "summary": "Chaos is Inevitable",
            "content_text": "            Tool      Description                  ping      Sends ICMP echo requests to a network host to test connectivity and latency. Useful for checking if a host is reachable.              traceroute      Traces the path packets take to a destination, identifying network hops and where delays or packet losses occur.              netstat      Displays network connections, routing tables, and interface statistics. Helpful for diagnosing network issues and checking active connections.              ss      A modern alternative to netstat, used for displaying more detailed socket and network connection information.              tcpdump      Captures network traffic for analysis. Useful for diagnosing low-level network issues and packet inspection.              dig      Queries DNS servers for domain information, such as IP addresses. Helpful for diagnosing DNS resolution issues.              nslookup      Similar to dig, used for querying DNS information. Useful for simple DNS queries and debugging domain resolution issues.              top      Displays real-time information about system processes, CPU, and memory usage. Useful for identifying resource-hungry processes.              htop      An improved version of top with an interactive, user-friendly interface. Useful for visualizing system resource usage.              iostat      Reports CPU and I/O statistics for devices. Useful for diagnosing disk I/O performance issues.              vmstat      Reports virtual memory statistics, including processes, memory, paging, and CPU usage. Useful for spotting memory bottlenecks.              df      Displays disk space usage for file systems. Useful for checking if any file system is running out of space.              du      Summarizes disk usage of files and directories. Useful for identifying large files or directories consuming disk space.              free      Shows the amount of free and used memory in the system. Useful for diagnosing memory availability issues.              lsof      Lists open files and network connections. Useful for identifying which processes have specific files or sockets open.              strace      Traces system calls made by a process. Useful for debugging issues where a program is failing due to system calls.              dstat      Combines system resource statistics in real-time (disk, network, CPU, memory). Useful for holistic system performance monitoring.              systemctl      Manages system services on Linux. Useful for starting, stopping, or checking the status of services and troubleshooting service issues.              journalctl      Queries and displays system logs from systemd. Useful for troubleshooting service issues, crashes, and other system events.              ps      Lists running processes. Useful for investigating which processes are running, hung, or consuming too many resources.              grep      Searches for patterns within text. Useful for filtering logs or command output for specific keywords or patterns.              awk      A powerful text processing tool used for extracting and transforming data from files or input streams.              sed      Stream editor for filtering and transforming text. Often used to edit configuration files or command outputs in scripts.              curl      Transfers data to or from a server using various protocols (HTTP, FTP). Useful for testing API endpoints or downloading files.              wget      Retrieves files from web servers. Can be used for downloading files or mirroring websites.              ip      Configures network interfaces and displays network configuration. Replaces older ifconfig for advanced network diagnostics.              hostnamectl      Controls and configures system hostname and related settings. Useful for managing the system identity over the network.              uptime      Displays how long the system has been running along with the system load average. Useful for diagnosing system stability issues.              nc (netcat)      A versatile networking tool for reading, writing, and redirecting data over TCP/IP networks. Useful for debugging connectivity issues.              arp      Displays or manipulates the ARP (Address Resolution Protocol) table. Useful for diagnosing issues with IP to MAC address resolution.              iptraf-ng      A real-time network monitoring utility that provides detailed statistics about network traffic. Useful for diagnosing traffic issues.              iftop      Displays bandwidth usage on an interface by host. Useful for identifying bandwidth-intensive connections.              mtr      Combines the functionality of ping and traceroute in a single tool, continuously analyzing the network route. Useful for long-term network diagnostics.              whois      Queries the WHOIS database for domain information such as ownership, expiration, and registrar data. Useful for domain-related troubleshooting.              sar      Collects, reports, and saves system activity information, including CPU, memory, I/O, and network statistics. Useful for long-term performance analysis.              perf      Performance analysis tool for Linux that measures CPU and system performance metrics. Useful for in-depth performance troubleshooting.              nmap      A network scanning tool that discovers devices and services on a network. Useful for security audits and network diagnostics.              ipmitool      Allows management and monitoring of hardware devices using IPMI. Useful for hardware troubleshooting and server health monitoring.              sshd      Secure Shell (SSH) daemon for remote system management. Useful for securely accessing systems to troubleshoot remotely.              rkhunter      Scans for rootkits and security vulnerabilities. Useful for identifying security breaches or malware.              rsync      Efficiently synchronizes files between systems over a network. Useful for backups, data migration, or troubleshooting file transfer issues.              ethtool      Displays and modifies network interface card (NIC) settings. Useful for diagnosing or tuning network performance issues at the hardware level.      ",
            "content_html": "<table>  <thead>    <tr>      <th><strong>Tool</strong></th>      <th><strong>Description</strong></th>    </tr>  </thead>  <tbody>    <tr>      <td><strong>ping</strong></td>      <td>Sends ICMP echo requests to a network host to test connectivity and latency. Useful for checking if a host is reachable.</td>    </tr>    <tr>      <td><strong>traceroute</strong></td>      <td>Traces the path packets take to a destination, identifying network hops and where delays or packet losses occur.</td>    </tr>    <tr>      <td><strong>netstat</strong></td>      <td>Displays network connections, routing tables, and interface statistics. Helpful for diagnosing network issues and checking active connections.</td>    </tr>    <tr>      <td><strong>ss</strong></td>      <td>A modern alternative to <code class=\"language-plaintext highlighter-rouge\">netstat</code>, used for displaying more detailed socket and network connection information.</td>    </tr>    <tr>      <td><strong>tcpdump</strong></td>      <td>Captures network traffic for analysis. Useful for diagnosing low-level network issues and packet inspection.</td>    </tr>    <tr>      <td><strong>dig</strong></td>      <td>Queries DNS servers for domain information, such as IP addresses. Helpful for diagnosing DNS resolution issues.</td>    </tr>    <tr>      <td><strong>nslookup</strong></td>      <td>Similar to <code class=\"language-plaintext highlighter-rouge\">dig</code>, used for querying DNS information. Useful for simple DNS queries and debugging domain resolution issues.</td>    </tr>    <tr>      <td><strong>top</strong></td>      <td>Displays real-time information about system processes, CPU, and memory usage. Useful for identifying resource-hungry processes.</td>    </tr>    <tr>      <td><strong>htop</strong></td>      <td>An improved version of <code class=\"language-plaintext highlighter-rouge\">top</code> with an interactive, user-friendly interface. Useful for visualizing system resource usage.</td>    </tr>    <tr>      <td><strong>iostat</strong></td>      <td>Reports CPU and I/O statistics for devices. Useful for diagnosing disk I/O performance issues.</td>    </tr>    <tr>      <td><strong>vmstat</strong></td>      <td>Reports virtual memory statistics, including processes, memory, paging, and CPU usage. Useful for spotting memory bottlenecks.</td>    </tr>    <tr>      <td><strong>df</strong></td>      <td>Displays disk space usage for file systems. Useful for checking if any file system is running out of space.</td>    </tr>    <tr>      <td><strong>du</strong></td>      <td>Summarizes disk usage of files and directories. Useful for identifying large files or directories consuming disk space.</td>    </tr>    <tr>      <td><strong>free</strong></td>      <td>Shows the amount of free and used memory in the system. Useful for diagnosing memory availability issues.</td>    </tr>    <tr>      <td><strong>lsof</strong></td>      <td>Lists open files and network connections. Useful for identifying which processes have specific files or sockets open.</td>    </tr>    <tr>      <td><strong>strace</strong></td>      <td>Traces system calls made by a process. Useful for debugging issues where a program is failing due to system calls.</td>    </tr>    <tr>      <td><strong>dstat</strong></td>      <td>Combines system resource statistics in real-time (disk, network, CPU, memory). Useful for holistic system performance monitoring.</td>    </tr>    <tr>      <td><strong>systemctl</strong></td>      <td>Manages system services on Linux. Useful for starting, stopping, or checking the status of services and troubleshooting service issues.</td>    </tr>    <tr>      <td><strong>journalctl</strong></td>      <td>Queries and displays system logs from <code class=\"language-plaintext highlighter-rouge\">systemd</code>. Useful for troubleshooting service issues, crashes, and other system events.</td>    </tr>    <tr>      <td><strong>ps</strong></td>      <td>Lists running processes. Useful for investigating which processes are running, hung, or consuming too many resources.</td>    </tr>    <tr>      <td><strong>grep</strong></td>      <td>Searches for patterns within text. Useful for filtering logs or command output for specific keywords or patterns.</td>    </tr>    <tr>      <td><strong>awk</strong></td>      <td>A powerful text processing tool used for extracting and transforming data from files or input streams.</td>    </tr>    <tr>      <td><strong>sed</strong></td>      <td>Stream editor for filtering and transforming text. Often used to edit configuration files or command outputs in scripts.</td>    </tr>    <tr>      <td><strong>curl</strong></td>      <td>Transfers data to or from a server using various protocols (HTTP, FTP). Useful for testing API endpoints or downloading files.</td>    </tr>    <tr>      <td><strong>wget</strong></td>      <td>Retrieves files from web servers. Can be used for downloading files or mirroring websites.</td>    </tr>    <tr>      <td><strong>ip</strong></td>      <td>Configures network interfaces and displays network configuration. Replaces older <code class=\"language-plaintext highlighter-rouge\">ifconfig</code> for advanced network diagnostics.</td>    </tr>    <tr>      <td><strong>hostnamectl</strong></td>      <td>Controls and configures system hostname and related settings. Useful for managing the system identity over the network.</td>    </tr>    <tr>      <td><strong>uptime</strong></td>      <td>Displays how long the system has been running along with the system load average. Useful for diagnosing system stability issues.</td>    </tr>    <tr>      <td><strong>nc (netcat)</strong></td>      <td>A versatile networking tool for reading, writing, and redirecting data over TCP/IP networks. Useful for debugging connectivity issues.</td>    </tr>    <tr>      <td><strong>arp</strong></td>      <td>Displays or manipulates the ARP (Address Resolution Protocol) table. Useful for diagnosing issues with IP to MAC address resolution.</td>    </tr>    <tr>      <td><strong>iptraf-ng</strong></td>      <td>A real-time network monitoring utility that provides detailed statistics about network traffic. Useful for diagnosing traffic issues.</td>    </tr>    <tr>      <td><strong>iftop</strong></td>      <td>Displays bandwidth usage on an interface by host. Useful for identifying bandwidth-intensive connections.</td>    </tr>    <tr>      <td><strong>mtr</strong></td>      <td>Combines the functionality of <code class=\"language-plaintext highlighter-rouge\">ping</code> and <code class=\"language-plaintext highlighter-rouge\">traceroute</code> in a single tool, continuously analyzing the network route. Useful for long-term network diagnostics.</td>    </tr>    <tr>      <td><strong>whois</strong></td>      <td>Queries the WHOIS database for domain information such as ownership, expiration, and registrar data. Useful for domain-related troubleshooting.</td>    </tr>    <tr>      <td><strong>sar</strong></td>      <td>Collects, reports, and saves system activity information, including CPU, memory, I/O, and network statistics. Useful for long-term performance analysis.</td>    </tr>    <tr>      <td><strong>perf</strong></td>      <td>Performance analysis tool for Linux that measures CPU and system performance metrics. Useful for in-depth performance troubleshooting.</td>    </tr>    <tr>      <td><strong>nmap</strong></td>      <td>A network scanning tool that discovers devices and services on a network. Useful for security audits and network diagnostics.</td>    </tr>    <tr>      <td><strong>ipmitool</strong></td>      <td>Allows management and monitoring of hardware devices using IPMI. Useful for hardware troubleshooting and server health monitoring.</td>    </tr>    <tr>      <td><strong>sshd</strong></td>      <td>Secure Shell (SSH) daemon for remote system management. Useful for securely accessing systems to troubleshoot remotely.</td>    </tr>    <tr>      <td><strong>rkhunter</strong></td>      <td>Scans for rootkits and security vulnerabilities. Useful for identifying security breaches or malware.</td>    </tr>    <tr>      <td><strong>rsync</strong></td>      <td>Efficiently synchronizes files between systems over a network. Useful for backups, data migration, or troubleshooting file transfer issues.</td>    </tr>    <tr>      <td><strong>ethtool</strong></td>      <td>Displays and modifies network interface card (NIC) settings. Useful for diagnosing or tuning network performance issues at the hardware level.</td>    </tr>  </tbody></table>",
            "url": "https://apolzek.github.io/2025/09/29/sre-kit-for-the-end-of-the-world",
            
            
            
            "tags": ["tools","sre","toolbox","linux"],
            
            "date_published": "2025-09-29T00:00:00+00:00",
            "date_modified": "2025-09-29T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2025/09/28/containers-mastery",
            "title": "üì¶ Containers Mastery",
            "summary": "Tips and Tricks for Containers",
            "content_text": "What is Linux container ?A Linux container is a lightweight and portable unit that encapsulates an application and its dependencies. Containers utilize key Linux kernel features for process isolation and resource management, including namespaces (for isolating resources like PID, network, and filesystem) and control groups (cgroups) (for limiting and prioritizing resource usage). Additionally, union file systems enable efficient layering and storage of container images. Together, these features allow containers to operate efficiently and securely on a shared host. Basically a container image is composed ofDependencies  + Application code + Container configuration + Base imageContainer runtimeA container runtime is a software component that is responsible for running and managing containers.  Docker  containerd  CRI-O  runc  Podman  LXC/LXD  systemd-nspawn (Don‚Äôt be angry with me)Don‚Äôt compare Docker with KubernetesIt just doesn‚Äôt make sense.. comparing Docker and Kubernetes can be confusing for beginners because they serve different purposes: Docker implements the concept of containers, while Kubernetes orchestrates those containers. An analogy is comparing a car (Docker) to a traffic system (Kubernetes); the car allows you to drive (create and run containers), while the traffic system manages the flow of multiple cars (orchestrates the deployment and scaling of containers). This distinction is crucial, as it clarifies that Docker focuses on the containerization process itself, while Kubernetes handles the management of containerized applications at scale.Container SecurityHaving secure base images for containers is crucial for maintaining the overall security of the host system. Images without elevated privileges help minimize potential attack vectors, reducing the risk of container escape and unauthorized access to the host. While concerns about insecure images are valid, it‚Äôs important to note that this is not the worst-case scenario, as containers typically run in a private network. For an attacker to exploit these vulnerabilities significantly, they would need to compromise additional components of the infrastructure, making it a more complex attack path. Therefore, while secure base images are essential, the overall security posture can still be robust with proper network isolation and access controls in place.Now, talking about the application code that is inside the container.. SAST (Static Application Security Testing) and SCA (Software Composition Analysis) are essential complementary approaches for ensuring application security. While SAST analyzes the source code for vulnerabilities before execution, SCA focuses on third-party libraries and dependencies, checking for known flaws. Integrating both practices is crucial, as it allows for the identification of internal code issues and external risks associated with software components. Tools like SonarQube and Fortify for SAST, and Black Duck and Snyk for SCA, provide robust solutions to mitigate vulnerabilities, offering more comprehensive security throughout the software development lifecycle.In summary, ensure that you use secure base images that prevent vulnerabilities and do not allow root access. Conduct thorough security testing and utilize a scanning tool with an up-to-date CVE database. Keep your images minimal, as even a simple curl command can be exploited by skilled attackers. Implement read-only filesystems to enhance security and adopt practices that make updating images simple and efficient.  Quay  trivy  Docker Desktop (Docker Scout) Vulnerability ScanContainer registryA container registry is a centralized repository where container images are stored, managed, and distributed. Examples of usage include:  Docker Hub  Google Container Registry (GCR)  Amazon Elastic Container Registry (ECR)  Azure Container Registry (ACR)  Harbor  Quay  GitLab Container Registry  JFrog Container RegistryTools for working with containers  dive  Docker CLI  ctr  lazydockerSpecial images  dbeaver/cloudbeaver  netdata/netdata  lscr.io/linuxserver/wireshark:latest  nicolargo/glances  minio/minioBuilding my imagesTypically, each programming language adheres to certain conventions for images. The goal is usually to create a lightweight and secure image. We can leverage concepts such as multi-stage builds and base images with community support. Some best practices include:  Use Multi-Stage Builds: This approach allows you to minimize the final image size by separating the build environment from the production environment.  Choose Official Base Images: Opt for official images from reputable sources to ensure security and reliability.  Keep Images Lightweight: Remove unnecessary files and dependencies to reduce the image size and improve performance.  Regularly Update Images: Stay current with updates to base images and dependencies to mitigate security vulnerabilities.  Use Specific Version Tags: Instead of using ‚Äúlatest,‚Äù specify the exact version of images to avoid unexpected changes in your application.  Scan for Vulnerabilities: Regularly scan your images for known vulnerabilities to maintain security.  Document Image Purpose and Usage: Include clear documentation about the image‚Äôs purpose, usage, and configuration to facilitate easier maintenance and onboarding.Deep dive ? not today..but you need to knowNamespaces and Cgroups ArchitectureNamespaces are a fundamental aspect of containerization, providing isolation for various resources on a Linux system. Each namespace creates a distinct environment for processes, ensuring that they only interact with their own set of resources. For example, the PID namespace allows processes to have their own process IDs, making it appear as though they are the only ones running on the system. Similarly, network namespaces enable containers to have unique network interfaces and IP addresses, preventing interference between containers. Understanding how these namespaces work is essential for developers to effectively manage resource allocation and maintain a secure environment.Control groups (cgroups) complement namespaces by allowing for fine-grained resource management. They enable administrators to limit and prioritize CPU, memory, and I/O usage for groups of processes, ensuring that no single container can monopolize system resources. With cgroups, users can define resource limits, monitor usage, and enforce constraints in a way that is transparent to the applications running within the containers. This architecture not only optimizes resource allocation but also enhances overall system stability by preventing resource contention.Overlay Filesystem and Copy-on-WriteThe Overlay filesystem is a crucial technology in containerization, facilitating the creation of layered filesystems that optimize storage and performance. By allowing multiple layers to be stacked, OverlayFS enables efficient management of container images, where each layer can be modified without affecting the underlying layers. This Copy-on-Write (CoW) mechanism ensures that changes made to a file in a container do not overwrite the original file in the base image. Instead, the container creates a new layer for modifications, allowing for quick and efficient updates while conserving disk space.Using OverlayFS not only improves storage efficiency but also enhances the speed of container operations. As containers are deployed, they only need to load the layers that have changed, significantly reducing the time required to start a container. Additionally, this layering approach allows for easy version control and rollback capabilities. If a change introduces an issue, reverting to a previous version can be done swiftly by switching back to the corresponding base image, thereby minimizing downtime and potential disruptions.Container Runtimes ComparisonContainer runtimes are essential components that facilitate the execution and management of containers, each with unique features and capabilities. Docker, for instance, is a widely recognized runtime that simplifies the process of building, running, and sharing containers. On the other hand, containerd serves as a high-level container runtime, providing a robust platform for managing the complete lifecycle of containers. CRI-O, specifically designed for Kubernetes, focuses on optimizing the performance and resource utilization of containerized applications within orchestration environments. Each runtime caters to different needs, making it important for developers to choose the right one based on their specific use cases and operational requirements.When comparing these runtimes, one must consider factors such as performance, compatibility, and community support. While Docker provides an all-in-one solution for container management, it may introduce overhead that isn‚Äôt present in lighter runtimes like runc, which focuses solely on running containers. Additionally, Podman offers a daemonless experience that enables users to run containers without needing a central service, appealing to those who prioritize security and simplicity. Ultimately, understanding the distinctions between these runtimes helps developers select the most appropriate tools for their containerization strategies.Network Namespaces and Networking ModelsNetwork namespaces are critical for ensuring that containers can communicate while remaining isolated from one another. Each network namespace has its own network stack, including interfaces, routing tables, and firewall rules, allowing containers to function as if they are on separate hosts. This isolation is essential for security, as it prevents unauthorized access between containers and enhances overall system integrity. Additionally, networking models such as bridge networking, overlay networking, and macvlan provide different levels of connectivity and isolation, enabling users to tailor their networking setup based on application needs and deployment scenarios.Understanding these networking models is crucial for optimizing communication between containers. For instance, bridge networking is often used for simpler applications that require direct communication with the host, while overlay networking is ideal for applications deployed across multiple hosts in a cluster, such as those orchestrated by Kubernetes. By leveraging tools like Flannel, Calico, or Cilium, developers can create robust networking solutions that enhance container security and performance. The choice of networking model significantly impacts the architecture of containerized applications and their ability to scale effectively.Advanced Container SecurityAdvanced security measures extend beyond just using secure images; they also encompass implementing Linux capabilities to limit permissions, using Seccomp to filter system calls, and configuring AppArmor profiles for enhanced security. Rootless containers further elevate security by allowing users to run containers without root privileges, significantly reducing the risk of privilege escalation attacks. By integrating these practices, organizations can create a layered security approach that effectively mitigates potential risks while ensuring that containerized applications remain robust and resilient against emerging threats.Volume Management and Data PersistenceEffective volume management is essential for ensuring data persistence in containerized applications. Unlike traditional virtual machines, containers are ephemeral, meaning any data stored within a container is lost once it is stopped or removed. To address this challenge, Docker and other container orchestration platforms provide mechanisms for managing volumes, which allow data to persist independently of the container lifecycle. Volumes can be created and managed easily, enabling developers to store important data, such as databases or user uploads, securely.There are two primary types of storage options for containers: bind mounts and named volumes. Bind mounts allow specific directories on the host to be mounted into a container, providing direct access to host files. However, they can introduce complexity and potential security risks if not managed properly. In contrast, named volumes are managed by the container runtime, offering a more abstracted approach that simplifies data management. By adopting best practices for volume management, such as isolating data from application logic and regularly backing up volumes, developers can ensure that their applications maintain data integrity and resilience in production environments.Advanced Container OrchestrationAdvanced container orchestration is crucial for managing the deployment, scaling, and operation of containerized applications in complex environments. Kubernetes, as a leading orchestration platform, provides robust features for automating the management of containerized applications across clusters. It facilitates load balancing, automated scaling, and self-healing capabilities, allowing organizations to maintain high availability and performance in their applications. Understanding Kubernetes internals, such as the roles of the kubelet, kube-scheduler, and controller manager, empowers developers to optimize their deployment strategies and resource allocation effectively.In addition to Kubernetes, modern orchestration frameworks also support advanced deployment strategies, such as blue-green deployments and canary releases. These methods enable teams to introduce new features gradually, minimizing risk and ensuring a smooth user experience. By leveraging ConfigMaps and Secrets, developers can manage application configurations and sensitive data securely within the orchestration platform. Ultimately, mastering advanced orchestration techniques enhances the efficiency and reliability of containerized applications, driving innovation and agility in software development and deployment.",
            "content_html": "<h2 id=\"what-is-linux-container-\">What is Linux container ?</h2><p>A Linux container is a lightweight and portable unit that encapsulates an application and its dependencies. Containers utilize key Linux kernel features for process isolation and resource management, including namespaces (for isolating resources like PID, network, and filesystem) and control groups (cgroups) (for limiting and prioritizing resource usage). Additionally, union file systems enable efficient layering and storage of container images. Together, these features allow containers to operate efficiently and securely on a shared host. Basically a container image is composed of</p><p><code class=\"language-plaintext highlighter-rouge\">Dependencies  + Application code + Container configuration + Base image</code></p><h2 id=\"container-runtime\">Container runtime</h2><p>A container runtime is a software component that is responsible for running and managing containers.</p><ul>  <li>Docker</li>  <li>containerd</li>  <li>CRI-O</li>  <li>runc</li>  <li>Podman</li>  <li>LXC/LXD</li>  <li>systemd-nspawn (Don‚Äôt be angry with me)</li></ul><h2 id=\"dont-compare-docker-with-kubernetes\">Don‚Äôt compare Docker with Kubernetes</h2><p>It just doesn‚Äôt make sense.. comparing Docker and Kubernetes can be confusing for beginners because they serve different purposes: Docker implements the concept of containers, while Kubernetes orchestrates those containers. An analogy is comparing a car (Docker) to a traffic system (Kubernetes); the car allows you to drive (create and run containers), while the traffic system manages the flow of multiple cars (orchestrates the deployment and scaling of containers). This distinction is crucial, as it clarifies that Docker focuses on the containerization process itself, while Kubernetes handles the management of containerized applications at scale.</p><h2 id=\"container-security\">Container Security</h2><p>Having secure base images for containers is crucial for maintaining the overall security of the host system. Images without elevated privileges help minimize potential attack vectors, reducing the risk of container escape and unauthorized access to the host. While concerns about insecure images are valid, it‚Äôs important to note that this is not the worst-case scenario, as containers typically run in a private network. For an attacker to exploit these vulnerabilities significantly, they would need to compromise additional components of the infrastructure, making it a more complex attack path. Therefore, while secure base images are essential, the overall security posture can still be robust with proper network isolation and access controls in place.</p><p>Now, talking about the application code that is inside the container.. SAST (Static Application Security Testing) and SCA (Software Composition Analysis) are essential complementary approaches for ensuring application security. While SAST analyzes the source code for vulnerabilities before execution, SCA focuses on third-party libraries and dependencies, checking for known flaws. Integrating both practices is crucial, as it allows for the identification of internal code issues and external risks associated with software components. Tools like SonarQube and Fortify for SAST, and Black Duck and Snyk for SCA, provide robust solutions to mitigate vulnerabilities, offering more comprehensive security throughout the software development lifecycle.</p><p>In summary, ensure that you use secure base images that prevent vulnerabilities and do not allow root access. Conduct thorough security testing and utilize a scanning tool with an up-to-date CVE database. Keep your images minimal, as even a simple curl command can be exploited by skilled attackers. Implement read-only filesystems to enhance security and adopt practices that make updating images simple and efficient.</p><ul>  <li>Quay</li>  <li>trivy</li>  <li>Docker Desktop (Docker Scout) Vulnerability Scan</li></ul><h2 id=\"container-registry\">Container registry</h2><p>A container registry is a centralized repository where container images are stored, managed, and distributed. Examples of usage include:</p><ul>  <li>Docker Hub</li>  <li>Google Container Registry (GCR)</li>  <li>Amazon Elastic Container Registry (ECR)</li>  <li>Azure Container Registry (ACR)</li>  <li>Harbor</li>  <li>Quay</li>  <li>GitLab Container Registry</li>  <li>JFrog Container Registry</li></ul><h2 id=\"tools-for-working-with-containers\">Tools for working with containers</h2><ul>  <li>dive</li>  <li>Docker CLI</li>  <li>ctr</li>  <li>lazydocker</li></ul><h2 id=\"special-images\">Special images</h2><ul>  <li>dbeaver/cloudbeaver</li>  <li>netdata/netdata</li>  <li>lscr.io/linuxserver/wireshark:latest</li>  <li>nicolargo/glances</li>  <li>minio/minio</li></ul><h2 id=\"building-my-images\">Building my images</h2><p>Typically, each programming language adheres to certain conventions for images. The goal is usually to create a lightweight and secure image. We can leverage concepts such as multi-stage builds and base images with community support. Some best practices include:</p><ul>  <li>Use Multi-Stage Builds: This approach allows you to minimize the final image size by separating the build environment from the production environment.</li>  <li>Choose Official Base Images: Opt for official images from reputable sources to ensure security and reliability.</li>  <li>Keep Images Lightweight: Remove unnecessary files and dependencies to reduce the image size and improve performance.</li>  <li>Regularly Update Images: Stay current with updates to base images and dependencies to mitigate security vulnerabilities.</li>  <li>Use Specific Version Tags: Instead of using ‚Äúlatest,‚Äù specify the exact version of images to avoid unexpected changes in your application.</li>  <li>Scan for Vulnerabilities: Regularly scan your images for known vulnerabilities to maintain security.</li>  <li>Document Image Purpose and Usage: Include clear documentation about the image‚Äôs purpose, usage, and configuration to facilitate easier maintenance and onboarding.</li></ul><h2 id=\"deep-dive--not-todaybut-you-need-to-know\">Deep dive ? not today..but you need to know</h2><h4 id=\"namespaces-and-cgroups-architecture\">Namespaces and Cgroups Architecture</h4><p>Namespaces are a fundamental aspect of containerization, providing isolation for various resources on a Linux system. Each namespace creates a distinct environment for processes, ensuring that they only interact with their own set of resources. For example, the PID namespace allows processes to have their own process IDs, making it appear as though they are the only ones running on the system. Similarly, network namespaces enable containers to have unique network interfaces and IP addresses, preventing interference between containers. Understanding how these namespaces work is essential for developers to effectively manage resource allocation and maintain a secure environment.</p><p>Control groups (cgroups) complement namespaces by allowing for fine-grained resource management. They enable administrators to limit and prioritize CPU, memory, and I/O usage for groups of processes, ensuring that no single container can monopolize system resources. With cgroups, users can define resource limits, monitor usage, and enforce constraints in a way that is transparent to the applications running within the containers. This architecture not only optimizes resource allocation but also enhances overall system stability by preventing resource contention.</p><h4 id=\"overlay-filesystem-and-copy-on-write\">Overlay Filesystem and Copy-on-Write</h4><p>The Overlay filesystem is a crucial technology in containerization, facilitating the creation of layered filesystems that optimize storage and performance. By allowing multiple layers to be stacked, OverlayFS enables efficient management of container images, where each layer can be modified without affecting the underlying layers. This Copy-on-Write (CoW) mechanism ensures that changes made to a file in a container do not overwrite the original file in the base image. Instead, the container creates a new layer for modifications, allowing for quick and efficient updates while conserving disk space.</p><p>Using OverlayFS not only improves storage efficiency but also enhances the speed of container operations. As containers are deployed, they only need to load the layers that have changed, significantly reducing the time required to start a container. Additionally, this layering approach allows for easy version control and rollback capabilities. If a change introduces an issue, reverting to a previous version can be done swiftly by switching back to the corresponding base image, thereby minimizing downtime and potential disruptions.</p><h4 id=\"container-runtimes-comparison\">Container Runtimes Comparison</h4><p>Container runtimes are essential components that facilitate the execution and management of containers, each with unique features and capabilities. Docker, for instance, is a widely recognized runtime that simplifies the process of building, running, and sharing containers. On the other hand, containerd serves as a high-level container runtime, providing a robust platform for managing the complete lifecycle of containers. CRI-O, specifically designed for Kubernetes, focuses on optimizing the performance and resource utilization of containerized applications within orchestration environments. Each runtime caters to different needs, making it important for developers to choose the right one based on their specific use cases and operational requirements.</p><p>When comparing these runtimes, one must consider factors such as performance, compatibility, and community support. While Docker provides an all-in-one solution for container management, it may introduce overhead that isn‚Äôt present in lighter runtimes like runc, which focuses solely on running containers. Additionally, Podman offers a daemonless experience that enables users to run containers without needing a central service, appealing to those who prioritize security and simplicity. Ultimately, understanding the distinctions between these runtimes helps developers select the most appropriate tools for their containerization strategies.</p><h4 id=\"network-namespaces-and-networking-models\">Network Namespaces and Networking Models</h4><p>Network namespaces are critical for ensuring that containers can communicate while remaining isolated from one another. Each network namespace has its own network stack, including interfaces, routing tables, and firewall rules, allowing containers to function as if they are on separate hosts. This isolation is essential for security, as it prevents unauthorized access between containers and enhances overall system integrity. Additionally, networking models such as bridge networking, overlay networking, and macvlan provide different levels of connectivity and isolation, enabling users to tailor their networking setup based on application needs and deployment scenarios.</p><p>Understanding these networking models is crucial for optimizing communication between containers. For instance, bridge networking is often used for simpler applications that require direct communication with the host, while overlay networking is ideal for applications deployed across multiple hosts in a cluster, such as those orchestrated by Kubernetes. By leveraging tools like Flannel, Calico, or Cilium, developers can create robust networking solutions that enhance container security and performance. The choice of networking model significantly impacts the architecture of containerized applications and their ability to scale effectively.</p><h4 id=\"advanced-container-security\">Advanced Container Security</h4><p>Advanced security measures extend beyond just using secure images; they also encompass implementing Linux capabilities to limit permissions, using Seccomp to filter system calls, and configuring AppArmor profiles for enhanced security. Rootless containers further elevate security by allowing users to run containers without root privileges, significantly reducing the risk of privilege escalation attacks. By integrating these practices, organizations can create a layered security approach that effectively mitigates potential risks while ensuring that containerized applications remain robust and resilient against emerging threats.</p><h4 id=\"volume-management-and-data-persistence\">Volume Management and Data Persistence</h4><p>Effective volume management is essential for ensuring data persistence in containerized applications. Unlike traditional virtual machines, containers are ephemeral, meaning any data stored within a container is lost once it is stopped or removed. To address this challenge, Docker and other container orchestration platforms provide mechanisms for managing volumes, which allow data to persist independently of the container lifecycle. Volumes can be created and managed easily, enabling developers to store important data, such as databases or user uploads, securely.</p><p>There are two primary types of storage options for containers: bind mounts and named volumes. Bind mounts allow specific directories on the host to be mounted into a container, providing direct access to host files. However, they can introduce complexity and potential security risks if not managed properly. In contrast, named volumes are managed by the container runtime, offering a more abstracted approach that simplifies data management. By adopting best practices for volume management, such as isolating data from application logic and regularly backing up volumes, developers can ensure that their applications maintain data integrity and resilience in production environments.</p><h4 id=\"advanced-container-orchestration\">Advanced Container Orchestration</h4><p>Advanced container orchestration is crucial for managing the deployment, scaling, and operation of containerized applications in complex environments. Kubernetes, as a leading orchestration platform, provides robust features for automating the management of containerized applications across clusters. It facilitates load balancing, automated scaling, and self-healing capabilities, allowing organizations to maintain high availability and performance in their applications. Understanding Kubernetes internals, such as the roles of the kubelet, kube-scheduler, and controller manager, empowers developers to optimize their deployment strategies and resource allocation effectively.</p><p>In addition to Kubernetes, modern orchestration frameworks also support advanced deployment strategies, such as blue-green deployments and canary releases. These methods enable teams to introduce new features gradually, minimizing risk and ensuring a smooth user experience. By leveraging ConfigMaps and Secrets, developers can manage application configurations and sensitive data securely within the orchestration platform. Ultimately, mastering advanced orchestration techniques enhances the efficiency and reliability of containerized applications, driving innovation and agility in software development and deployment.</p>",
            "url": "https://apolzek.github.io/2025/09/28/containers-mastery",
            
            
            
            "tags": ["linux","containers","docker"],
            
            "date_published": "2025-09-28T00:00:00+00:00",
            "date_modified": "2025-09-28T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2024/11/19/new-project-achados-do-github",
            "title": "NEW PROJECT - Achados do Github on YouTube",
            "summary": null,
            "content_text": "",
            "content_html": "<p><img src=\"https://raw.githubusercontent.com/apolzek/apolzek.github.io/refs/heads/main/assets/img/logo-achados-do-github.png\" alt=\"working\" /></p>",
            "url": "https://apolzek.github.io/2024/11/19/new-project-achados-do-github",
            
            
            
            "tags": ["git","github"],
            
            "date_published": "2024-11-19T00:00:00+00:00",
            "date_modified": "2024-11-19T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2024/09/29/shell-tips-for-linux-wizards",
            "title": "üßô Shell Tips for Linux Wizards",
            "summary": null,
            "content_text": "Index  Index          LOOPING: command x script                  command          script                    Signals                  SIGINT          SIGTERM          SIGHUB                    Background processes      Debugging      String Manipulation and Substitution      Shell Associative Arrays      YAML files      Check input      LOOPING: command x scriptcommandfor i in {1..5}; do echo $i; donecount=1; while [ $count -le 5 ]; do echo $count; ((count++)); donescript#!/bin/bashecho \"Counting to 5 with a for loop:\"for i in {1..5}; do    echo $idoneecho \"Counting to 5 with a while loop:\"count=1while [ $count -le 5 ]; do    echo $count    ((count++))doneSignalsSome scenarios that make sense to deal with signals..  Cleaning Temporary Files  Graceful Interruption of Services  Avoiding Database Corruption  Releasing Network or Hardware Resources  Maintaining Consistent Variable State-SIGINTThis script creates a temporary file and displays a goodbye message when it receives a SIGINT signal (e.g., when the user presses Ctrl+C).#!/bin/bash# Function that will be called when the script receives the SIGINT signalfunction exitMsg {    echo \"you sent a signal to end, byby !!\"    # command here    exit}# Sets up the trap to call the cleanup function when the script receives SIGINTtrap exitMsg SIGINTsleep 5echo \"Creating a temporary file...\"touch /tmp/apolzek || exit 1  # Creates a temporary file or exits with an errorSIGTERMThis script starts a web server that runs indefinitely and shuts down gracefully when it receives a SIGTERM signal. kill &lt;PID&gt;#!/bin/bash# Function called upon receiving SIGTERMfunction terminateMsg {    echo \"Received SIGTERM, shutting down the server gracefully...\"    # Here you can add commands to close connections or save the state    exit}# Sets up the trap for SIGTERMtrap terminateMsg SIGTERMecho \"Starting web server...\"while true; do    echo \"Server is running... (PID: $$)\"    sleep 2  # Simulates the server's running timedoneSIGHUBThis script starts a daemon that runs indefinitely and reloads its configuration when it receives a SIGHUP signal. kill -HUP &lt;PID&gt;#!/bin/bash# Function called upon receiving SIGHUPfunction reloadMsg {    echo \"Received SIGHUP, reloading configuration...\"    # Here you can add commands to reload the configurations    # Example: source /etc/mydaemon/config.conf}# Sets up the trap for SIGHUPtrap reloadMsg SIGHUPecho \"Starting my daemon...\"while true; do    echo \"Daemon is running... (PID: $$)\"    sleep 5  # Simulates the daemon's running timedoneBackground processes#!/bin/bashecho \"Starting background processes...\"# Process 1sleep 3 &amp;  # This simulates a long-running taskpid1=$!  # Get the process ID of process 1# Process 2sleep 9 &amp;  # This simulates a shorter taskpid2=$!  # Get the process ID of process 2# Wait for process 1 to finish and notifywait $pid1echo \"Process 1 has completed.\"# Wait for process 2 to finish and notifywait $pid2echo \"Process 2 has completed.\"echo \"All processes have finished.\"Debugging#!/bin/bashset -x  # Enable debugging modeecho \"Starting the script...\"echo \"Doing something...\"sleep 1echo \"Ending the script.\"set +x  # Disable debugging modeecho \"now debugging mode is disable\"echo \"did you understand ?\"#!/bin/bashset -xeuo pipefail# Uninitialized variable (throws an error with `set -u`)echo \"Attempting to access an uninitialized variable...\"echo \"Variable value: $UNINITIALIZED_VAR\"# This command will never be executed due to the previous errorecho \"End of script.\"String Manipulation and Substitution#!/bin/bash# Defining an original stringoriginal=\"Linux is amazing!\"# Converting to uppercaseuppercase=${original^^}echo \"Uppercase: $uppercase\"# Output: Uppercase: LINUX IS AMAZING!## another wayecho \"Linux is amazing!\" | tr '[:lower:]' '[:upper:]'echo \"Linux is amazing!\" | awk '{ print toupper($0) }'# Converting to lowercaselowercase=${original,,}echo \"Lowercase: $lowercase\"# Output: Lowercase: linux is amazing!# Replacing part of the stringmodified=${original//amazing/extravagant}echo \"Substitution: $modified\"# Output: Substitution: Linux is extravagant!# Extracting a substringsubstring=${original:7:9}  # Extracts \"is amazing\"echo \"Substring: $substring\"# Output: Substring: is amazing# Checking the length of the stringlength=${#original}echo \"Length of the string: $length characters\"# Output: Length of the string: 20 charactersShell Associative Arrays#!/bin/bash# Declare an associative arraydeclare -A user_info# Assign key-value pairsuser_info[name]=\"Alice\"user_info[email]=\"alice@example.com\"user_info[role]=\"Admin\"# Access elements by keyecho \"User Name: ${user_info[name]}\"echo \"User Email: ${user_info[email]}\"echo \"User Role: ${user_info[role]}\"# Looping over keys and valuesfor key in \"${!user_info[@]}\"; do    echo \"$key: ${user_info[$key]}\"doneYAML filesInstall yqsudo pacman -S yqCreate yaml exampleapiVersion: v1kind: ComplexConfigmetadata:  name: example-config  labels:    environment: production    version: \"1.0\"spec:  services:    - name: service1      type: LoadBalancer      ports:        - name: http          port: 80          targetPort: 8080        - name: https          port: 443          targetPort: 8443      hosts:        - host: \"service1.example.com\"          ip: \"192.168.1.10\"          regions:            - us-east-1            - eu-west-1    - name: service2      type: ClusterIP      ports:        - name: grpc          port: 50051          targetPort: 50051      hosts:        - host: \"service2.example.com\"          ip: \"192.168.1.20\"          regions:            - ap-south-1            - eu-central-1  config:    retries: 3    timeout: 5000  logging:    level: debug    format: json    outputs:      - type: file        path: \"/var/log/app.log\"      - type: stdoutfiltering datayq '.metadata.name' config.yamlyq '.spec.services[].name' config.yamlyq '.spec.services[1].type' config.yamlyq '.spec.services[] | select(.name == \"service1\") | .ports[] | {port, targetPort}' config.yamlyq '.spec.services[].hosts[] | {host, ip}' config.yamlyq '.spec.services[] | select(.name == \"service2\") | .hosts[].regions' config.yamlyq '.spec.logging.level' config.yamlyq -r '.metadata.name' config.yamlyq -r '.spec.services[].name' config.yamlyq -r '.spec.services[1].type' config.yamlyq -r '.spec.services[] | select(.name == \"service1\") | .ports[] | \"\\(.port) \\(.targetPort)\"' config.yamlyq -r '.spec.services[].hosts[] | \"\\(.host) \\(.ip)\"' config.yamlyq -r '.spec.services[] | select(.name == \"service2\") | .hosts[].regions[]' config.yamlyq -r '.spec.logging.level' config.yamlCheck input#!/bin/bash# Check if the argument is a directory.if [[ ! -d \"$1\" ]]; then    echo \"Error: $1 is not a directory.\"    exit 1fi#!/bin/bash# Check if the user provided a file path as an argumentif [[ -z \"$1\" ]]; then    echo \"No file path provided. Please enter the file path:\"    read -r file_pathelse    file_path=\"$1\"fi# Check if the file existsif [[ -f \"$file_path\" ]]; then    echo \"File exists, proceeding with backup.\"else    echo \"File does not exist. Please check the path and try again.\"    exit 1fi",
            "content_html": "<h2 id=\"index\">Index</h2><ul>  <li><a href=\"#index\">Index</a>    <ul>      <li><a href=\"#looping-command-x-script\">LOOPING: command x script</a>        <ul>          <li><a href=\"#command\">command</a></li>          <li><a href=\"#script\">script</a></li>        </ul>      </li>      <li><a href=\"#signals\">Signals</a>        <ul>          <li><a href=\"#sigint\">SIGINT</a></li>          <li><a href=\"#sigterm\">SIGTERM</a></li>          <li><a href=\"#sighub\">SIGHUB</a></li>        </ul>      </li>      <li><a href=\"#background-processes\">Background processes</a></li>      <li><a href=\"#debugging\">Debugging</a></li>      <li><a href=\"#string-manipulation-and-substitution\">String Manipulation and Substitution</a></li>      <li><a href=\"#shell-associative-arrays\">Shell Associative Arrays</a></li>      <li><a href=\"#yaml-files\">YAML files</a></li>      <li><a href=\"#check-input\">Check input</a></li>    </ul>  </li></ul><h3 id=\"looping-command-x-script\">LOOPING: command x script</h3><h4 id=\"command\">command</h4><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">for </span>i <span class=\"k\">in</span> <span class=\"o\">{</span>1..5<span class=\"o\">}</span><span class=\"p\">;</span> <span class=\"k\">do </span><span class=\"nb\">echo</span> <span class=\"nv\">$i</span><span class=\"p\">;</span> <span class=\"k\">done</span><span class=\"nv\">count</span><span class=\"o\">=</span>1<span class=\"p\">;</span> <span class=\"k\">while</span> <span class=\"o\">[</span> <span class=\"nv\">$count</span> <span class=\"nt\">-le</span> 5 <span class=\"o\">]</span><span class=\"p\">;</span> <span class=\"k\">do </span><span class=\"nb\">echo</span> <span class=\"nv\">$count</span><span class=\"p\">;</span> <span class=\"o\">((</span>count++<span class=\"o\">))</span><span class=\"p\">;</span> <span class=\"k\">done</span></code></pre></div></div><h4 id=\"script\">script</h4><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Counting to 5 with a for loop:\"</span><span class=\"k\">for </span>i <span class=\"k\">in</span> <span class=\"o\">{</span>1..5<span class=\"o\">}</span><span class=\"p\">;</span> <span class=\"k\">do    </span><span class=\"nb\">echo</span> <span class=\"nv\">$i</span><span class=\"k\">done</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Counting to 5 with a while loop:\"</span><span class=\"nv\">count</span><span class=\"o\">=</span>1<span class=\"k\">while</span> <span class=\"o\">[</span> <span class=\"nv\">$count</span> <span class=\"nt\">-le</span> 5 <span class=\"o\">]</span><span class=\"p\">;</span> <span class=\"k\">do    </span><span class=\"nb\">echo</span> <span class=\"nv\">$count</span>    <span class=\"o\">((</span>count++<span class=\"o\">))</span><span class=\"k\">done</span></code></pre></div></div><h3 id=\"signals\">Signals</h3><p>Some scenarios that make sense to deal with signals..</p><ul>  <li>Cleaning Temporary Files</li>  <li>Graceful Interruption of Services</li>  <li>Avoiding Database Corruption</li>  <li>Releasing Network or Hardware Resources</li>  <li>Maintaining Consistent Variable State-</li></ul><h4 id=\"sigint\">SIGINT</h4><p>This script creates a temporary file and displays a goodbye message when it receives a SIGINT signal (e.g., when the user presses Ctrl+C).</p><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"c\"># Function that will be called when the script receives the SIGINT signal</span><span class=\"k\">function </span>exitMsg <span class=\"o\">{</span>    <span class=\"nb\">echo</span> <span class=\"s2\">\"you sent a signal to end, byby !!\"</span>    <span class=\"c\"># command here</span>    <span class=\"nb\">exit</span><span class=\"o\">}</span><span class=\"c\"># Sets up the trap to call the cleanup function when the script receives SIGINT</span><span class=\"nb\">trap </span>exitMsg SIGINT<span class=\"nb\">sleep </span>5<span class=\"nb\">echo</span> <span class=\"s2\">\"Creating a temporary file...\"</span><span class=\"nb\">touch</span> /tmp/apolzek <span class=\"o\">||</span> <span class=\"nb\">exit </span>1  <span class=\"c\"># Creates a temporary file or exits with an error</span></code></pre></div></div><h4 id=\"sigterm\">SIGTERM</h4><p>This script starts a web server that runs indefinitely and shuts down gracefully when it receives a SIGTERM signal. <code class=\"language-plaintext highlighter-rouge\">kill &lt;PID&gt;</code></p><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"c\"># Function called upon receiving SIGTERM</span><span class=\"k\">function </span>terminateMsg <span class=\"o\">{</span>    <span class=\"nb\">echo</span> <span class=\"s2\">\"Received SIGTERM, shutting down the server gracefully...\"</span>    <span class=\"c\"># Here you can add commands to close connections or save the state</span>    <span class=\"nb\">exit</span><span class=\"o\">}</span><span class=\"c\"># Sets up the trap for SIGTERM</span><span class=\"nb\">trap </span>terminateMsg SIGTERM<span class=\"nb\">echo</span> <span class=\"s2\">\"Starting web server...\"</span><span class=\"k\">while </span><span class=\"nb\">true</span><span class=\"p\">;</span> <span class=\"k\">do    </span><span class=\"nb\">echo</span> <span class=\"s2\">\"Server is running... (PID: </span><span class=\"nv\">$$</span><span class=\"s2\">)\"</span>    <span class=\"nb\">sleep </span>2  <span class=\"c\"># Simulates the server's running time</span><span class=\"k\">done</span></code></pre></div></div><h4 id=\"sighub\">SIGHUB</h4><p>This script starts a daemon that runs indefinitely and reloads its configuration when it receives a SIGHUP signal. <code class=\"language-plaintext highlighter-rouge\">kill -HUP &lt;PID&gt;</code></p><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"c\"># Function called upon receiving SIGHUP</span><span class=\"k\">function </span>reloadMsg <span class=\"o\">{</span>    <span class=\"nb\">echo</span> <span class=\"s2\">\"Received SIGHUP, reloading configuration...\"</span>    <span class=\"c\"># Here you can add commands to reload the configurations</span>    <span class=\"c\"># Example: source /etc/mydaemon/config.conf</span><span class=\"o\">}</span><span class=\"c\"># Sets up the trap for SIGHUP</span><span class=\"nb\">trap </span>reloadMsg SIGHUP<span class=\"nb\">echo</span> <span class=\"s2\">\"Starting my daemon...\"</span><span class=\"k\">while </span><span class=\"nb\">true</span><span class=\"p\">;</span> <span class=\"k\">do    </span><span class=\"nb\">echo</span> <span class=\"s2\">\"Daemon is running... (PID: </span><span class=\"nv\">$$</span><span class=\"s2\">)\"</span>    <span class=\"nb\">sleep </span>5  <span class=\"c\"># Simulates the daemon's running time</span><span class=\"k\">done</span></code></pre></div></div><h3 id=\"background-processes\">Background processes</h3><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Starting background processes...\"</span><span class=\"c\"># Process 1</span><span class=\"nb\">sleep </span>3 &amp;  <span class=\"c\"># This simulates a long-running task</span><span class=\"nv\">pid1</span><span class=\"o\">=</span><span class=\"nv\">$!</span>  <span class=\"c\"># Get the process ID of process 1</span><span class=\"c\"># Process 2</span><span class=\"nb\">sleep </span>9 &amp;  <span class=\"c\"># This simulates a shorter task</span><span class=\"nv\">pid2</span><span class=\"o\">=</span><span class=\"nv\">$!</span>  <span class=\"c\"># Get the process ID of process 2</span><span class=\"c\"># Wait for process 1 to finish and notify</span><span class=\"nb\">wait</span> <span class=\"nv\">$pid1</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Process 1 has completed.\"</span><span class=\"c\"># Wait for process 2 to finish and notify</span><span class=\"nb\">wait</span> <span class=\"nv\">$pid2</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Process 2 has completed.\"</span><span class=\"nb\">echo</span> <span class=\"s2\">\"All processes have finished.\"</span></code></pre></div></div><h3 id=\"debugging\">Debugging</h3><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"nb\">set</span> <span class=\"nt\">-x</span>  <span class=\"c\"># Enable debugging mode</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Starting the script...\"</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Doing something...\"</span><span class=\"nb\">sleep </span>1<span class=\"nb\">echo</span> <span class=\"s2\">\"Ending the script.\"</span><span class=\"nb\">set</span> +x  <span class=\"c\"># Disable debugging mode</span><span class=\"nb\">echo</span> <span class=\"s2\">\"now debugging mode is disable\"</span><span class=\"nb\">echo</span> <span class=\"s2\">\"did you understand ?\"</span></code></pre></div></div><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"nb\">set</span> <span class=\"nt\">-xeuo</span> pipefail<span class=\"c\"># Uninitialized variable (throws an error with `set -u`)</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Attempting to access an uninitialized variable...\"</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Variable value: </span><span class=\"nv\">$UNINITIALIZED_VAR</span><span class=\"s2\">\"</span><span class=\"c\"># This command will never be executed due to the previous error</span><span class=\"nb\">echo</span> <span class=\"s2\">\"End of script.\"</span></code></pre></div></div><h3 id=\"string-manipulation-and-substitution\">String Manipulation and Substitution</h3><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"c\"># Defining an original string</span><span class=\"nv\">original</span><span class=\"o\">=</span><span class=\"s2\">\"Linux is amazing!\"</span><span class=\"c\"># Converting to uppercase</span><span class=\"nv\">uppercase</span><span class=\"o\">=</span><span class=\"k\">${</span><span class=\"nv\">original</span><span class=\"p\">^^</span><span class=\"k\">}</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Uppercase: </span><span class=\"nv\">$uppercase</span><span class=\"s2\">\"</span><span class=\"c\"># Output: Uppercase: LINUX IS AMAZING!</span><span class=\"c\">## another way</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Linux is amazing!\"</span> | <span class=\"nb\">tr</span> <span class=\"s1\">'[:lower:]'</span> <span class=\"s1\">'[:upper:]'</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Linux is amazing!\"</span> | <span class=\"nb\">awk</span> <span class=\"s1\">'{ print toupper($0) }'</span><span class=\"c\"># Converting to lowercase</span><span class=\"nv\">lowercase</span><span class=\"o\">=</span><span class=\"k\">${</span><span class=\"nv\">original</span><span class=\"p\">,,</span><span class=\"k\">}</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Lowercase: </span><span class=\"nv\">$lowercase</span><span class=\"s2\">\"</span><span class=\"c\"># Output: Lowercase: linux is amazing!</span><span class=\"c\"># Replacing part of the string</span><span class=\"nv\">modified</span><span class=\"o\">=</span><span class=\"k\">${</span><span class=\"nv\">original</span><span class=\"p\">//amazing/extravagant</span><span class=\"k\">}</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Substitution: </span><span class=\"nv\">$modified</span><span class=\"s2\">\"</span><span class=\"c\"># Output: Substitution: Linux is extravagant!</span><span class=\"c\"># Extracting a substring</span><span class=\"nv\">substring</span><span class=\"o\">=</span><span class=\"k\">${</span><span class=\"nv\">original</span>:7:9<span class=\"k\">}</span>  <span class=\"c\"># Extracts \"is amazing\"</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Substring: </span><span class=\"nv\">$substring</span><span class=\"s2\">\"</span><span class=\"c\"># Output: Substring: is amazing</span><span class=\"c\"># Checking the length of the string</span><span class=\"nv\">length</span><span class=\"o\">=</span><span class=\"k\">${#</span><span class=\"nv\">original</span><span class=\"k\">}</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Length of the string: </span><span class=\"nv\">$length</span><span class=\"s2\"> characters\"</span><span class=\"c\"># Output: Length of the string: 20 characters</span></code></pre></div></div><h3 id=\"shell-associative-arrays\">Shell Associative Arrays</h3><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"c\"># Declare an associative array</span><span class=\"nb\">declare</span> <span class=\"nt\">-A</span> user_info<span class=\"c\"># Assign key-value pairs</span>user_info[name]<span class=\"o\">=</span><span class=\"s2\">\"Alice\"</span>user_info[email]<span class=\"o\">=</span><span class=\"s2\">\"alice@example.com\"</span>user_info[role]<span class=\"o\">=</span><span class=\"s2\">\"Admin\"</span><span class=\"c\"># Access elements by key</span><span class=\"nb\">echo</span> <span class=\"s2\">\"User Name: </span><span class=\"k\">${</span><span class=\"nv\">user_info</span><span class=\"p\">[name]</span><span class=\"k\">}</span><span class=\"s2\">\"</span><span class=\"nb\">echo</span> <span class=\"s2\">\"User Email: </span><span class=\"k\">${</span><span class=\"nv\">user_info</span><span class=\"p\">[email]</span><span class=\"k\">}</span><span class=\"s2\">\"</span><span class=\"nb\">echo</span> <span class=\"s2\">\"User Role: </span><span class=\"k\">${</span><span class=\"nv\">user_info</span><span class=\"p\">[role]</span><span class=\"k\">}</span><span class=\"s2\">\"</span><span class=\"c\"># Looping over keys and values</span><span class=\"k\">for </span>key <span class=\"k\">in</span> <span class=\"s2\">\"</span><span class=\"k\">${</span><span class=\"p\">!user_info[@]</span><span class=\"k\">}</span><span class=\"s2\">\"</span><span class=\"p\">;</span> <span class=\"k\">do    </span><span class=\"nb\">echo</span> <span class=\"s2\">\"</span><span class=\"nv\">$key</span><span class=\"s2\">: </span><span class=\"k\">${</span><span class=\"nv\">user_info</span><span class=\"p\">[</span><span class=\"nv\">$key</span><span class=\"p\">]</span><span class=\"k\">}</span><span class=\"s2\">\"</span><span class=\"k\">done</span></code></pre></div></div><h3 id=\"yaml-files\">YAML files</h3><p>Install yq</p><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>pacman <span class=\"nt\">-S</span> yq</code></pre></div></div><p>Create yaml example</p><div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">ComplexConfig</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">example-config</span>  <span class=\"na\">labels</span><span class=\"pi\">:</span>    <span class=\"na\">environment</span><span class=\"pi\">:</span> <span class=\"s\">production</span>    <span class=\"na\">version</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">1.0\"</span><span class=\"na\">spec</span><span class=\"pi\">:</span>  <span class=\"na\">services</span><span class=\"pi\">:</span>    <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">service1</span>      <span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">LoadBalancer</span>      <span class=\"na\">ports</span><span class=\"pi\">:</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">http</span>          <span class=\"na\">port</span><span class=\"pi\">:</span> <span class=\"m\">80</span>          <span class=\"na\">targetPort</span><span class=\"pi\">:</span> <span class=\"m\">8080</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">https</span>          <span class=\"na\">port</span><span class=\"pi\">:</span> <span class=\"m\">443</span>          <span class=\"na\">targetPort</span><span class=\"pi\">:</span> <span class=\"m\">8443</span>      <span class=\"na\">hosts</span><span class=\"pi\">:</span>        <span class=\"pi\">-</span> <span class=\"na\">host</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">service1.example.com\"</span>          <span class=\"na\">ip</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">192.168.1.10\"</span>          <span class=\"na\">regions</span><span class=\"pi\">:</span>            <span class=\"pi\">-</span> <span class=\"s\">us-east-1</span>            <span class=\"pi\">-</span> <span class=\"s\">eu-west-1</span>    <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">service2</span>      <span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">ClusterIP</span>      <span class=\"na\">ports</span><span class=\"pi\">:</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">grpc</span>          <span class=\"na\">port</span><span class=\"pi\">:</span> <span class=\"m\">50051</span>          <span class=\"na\">targetPort</span><span class=\"pi\">:</span> <span class=\"m\">50051</span>      <span class=\"na\">hosts</span><span class=\"pi\">:</span>        <span class=\"pi\">-</span> <span class=\"na\">host</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">service2.example.com\"</span>          <span class=\"na\">ip</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">192.168.1.20\"</span>          <span class=\"na\">regions</span><span class=\"pi\">:</span>            <span class=\"pi\">-</span> <span class=\"s\">ap-south-1</span>            <span class=\"pi\">-</span> <span class=\"s\">eu-central-1</span>  <span class=\"na\">config</span><span class=\"pi\">:</span>    <span class=\"na\">retries</span><span class=\"pi\">:</span> <span class=\"m\">3</span>    <span class=\"na\">timeout</span><span class=\"pi\">:</span> <span class=\"m\">5000</span>  <span class=\"na\">logging</span><span class=\"pi\">:</span>    <span class=\"na\">level</span><span class=\"pi\">:</span> <span class=\"s\">debug</span>    <span class=\"na\">format</span><span class=\"pi\">:</span> <span class=\"s\">json</span>    <span class=\"na\">outputs</span><span class=\"pi\">:</span>      <span class=\"pi\">-</span> <span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">file</span>        <span class=\"na\">path</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">/var/log/app.log\"</span>      <span class=\"pi\">-</span> <span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">stdout</span></code></pre></div></div><p>filtering data</p><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>yq <span class=\"s1\">'.metadata.name'</span> config.yamlyq <span class=\"s1\">'.spec.services[].name'</span> config.yamlyq <span class=\"s1\">'.spec.services[1].type'</span> config.yamlyq <span class=\"s1\">'.spec.services[] | select(.name == \"service1\") | .ports[] | {port, targetPort}'</span> config.yamlyq <span class=\"s1\">'.spec.services[].hosts[] | {host, ip}'</span> config.yamlyq <span class=\"s1\">'.spec.services[] | select(.name == \"service2\") | .hosts[].regions'</span> config.yamlyq <span class=\"s1\">'.spec.logging.level'</span> config.yamlyq <span class=\"nt\">-r</span> <span class=\"s1\">'.metadata.name'</span> config.yamlyq <span class=\"nt\">-r</span> <span class=\"s1\">'.spec.services[].name'</span> config.yamlyq <span class=\"nt\">-r</span> <span class=\"s1\">'.spec.services[1].type'</span> config.yamlyq <span class=\"nt\">-r</span> <span class=\"s1\">'.spec.services[] | select(.name == \"service1\") | .ports[] | \"\\(.port) \\(.targetPort)\"'</span> config.yamlyq <span class=\"nt\">-r</span> <span class=\"s1\">'.spec.services[].hosts[] | \"\\(.host) \\(.ip)\"'</span> config.yamlyq <span class=\"nt\">-r</span> <span class=\"s1\">'.spec.services[] | select(.name == \"service2\") | .hosts[].regions[]'</span> config.yamlyq <span class=\"nt\">-r</span> <span class=\"s1\">'.spec.logging.level'</span> config.yaml</code></pre></div></div><h3 id=\"check-input\">Check input</h3><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"c\"># Check if the argument is a directory.</span><span class=\"k\">if</span> <span class=\"o\">[[</span> <span class=\"o\">!</span> <span class=\"nt\">-d</span> <span class=\"s2\">\"</span><span class=\"nv\">$1</span><span class=\"s2\">\"</span> <span class=\"o\">]]</span><span class=\"p\">;</span> <span class=\"k\">then    </span><span class=\"nb\">echo</span> <span class=\"s2\">\"Error: </span><span class=\"nv\">$1</span><span class=\"s2\"> is not a directory.\"</span>    <span class=\"nb\">exit </span>1<span class=\"k\">fi</span></code></pre></div></div><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"c\"># Check if the user provided a file path as an argument</span><span class=\"k\">if</span> <span class=\"o\">[[</span> <span class=\"nt\">-z</span> <span class=\"s2\">\"</span><span class=\"nv\">$1</span><span class=\"s2\">\"</span> <span class=\"o\">]]</span><span class=\"p\">;</span> <span class=\"k\">then    </span><span class=\"nb\">echo</span> <span class=\"s2\">\"No file path provided. Please enter the file path:\"</span>    <span class=\"nb\">read</span> <span class=\"nt\">-r</span> file_path<span class=\"k\">else    </span><span class=\"nv\">file_path</span><span class=\"o\">=</span><span class=\"s2\">\"</span><span class=\"nv\">$1</span><span class=\"s2\">\"</span><span class=\"k\">fi</span><span class=\"c\"># Check if the file exists</span><span class=\"k\">if</span> <span class=\"o\">[[</span> <span class=\"nt\">-f</span> <span class=\"s2\">\"</span><span class=\"nv\">$file_path</span><span class=\"s2\">\"</span> <span class=\"o\">]]</span><span class=\"p\">;</span> <span class=\"k\">then    </span><span class=\"nb\">echo</span> <span class=\"s2\">\"File exists, proceeding with backup.\"</span><span class=\"k\">else    </span><span class=\"nb\">echo</span> <span class=\"s2\">\"File does not exist. Please check the path and try again.\"</span>    <span class=\"nb\">exit </span>1</code></pre></div></div><p>fi</p>",
            "url": "https://apolzek.github.io/2024/09/29/shell-tips-for-linux-wizards",
            
            
            
            "tags": ["linux","shell","script","bash"],
            
            "date_published": "2024-09-29T00:00:00+00:00",
            "date_modified": "2024-09-29T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2024/09/29/kafka-and-rabbitmq-on-kubernetes",
            "title": "Kafka and RabbitMQ on Kubernetes using Kind",
            "summary": null,
            "content_text": "Index  Index          Create kubernetes cluster with kind      Kafka                  Kafka KRaft x Kafka with ZooKeeper                    RabbitMQ      Create kubernetes cluster with kind1) Create kind configuration(kind-config.yaml)cat &lt;&lt;EOF &gt; /tmp/kind-config.ymlapiVersion: kind.x-k8s.io/v1alpha4kind: Clusternodes:- role: control-plane  extraPortMappings:  - containerPort: 30092    hostPort: 30092    listenAddress: \"0.0.0.0\" # Optional, defaults to \"0.0.0.0\"    protocol: tcp # Optional, defaults to tcp- role: worker- role: worker- role: workerEOF2) Create a kind clusterkind create cluster --config /tmp/kind-config.yml --name my-clusterKafka1) Apply yamlcat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Namespacemetadata:  name: kafka  labels:    name: kafka---apiVersion: apps/v1kind: StatefulSetmetadata:  name: kafka  namespace: kafka  labels:    app: kafka-appspec:  serviceName: kafka-svc  replicas: 3  selector:    matchLabels:      app: kafka-app  template:    metadata:      labels:        app: kafka-app    spec:      containers:        - name: kafka-container          image: doughgle/kafka-kraft          ports:            - containerPort: 9092            - containerPort: 9093          env:            - name: REPLICAS              value: '3'            - name: SERVICE              value: kafka-svc            - name: NAMESPACE              value: kafka            - name: SHARE_DIR              value: /mnt/kafka            - name: CLUSTER_ID              value: bXktY2x1c3Rlci0xMjM0NQ==            - name: DEFAULT_REPLICATION_FACTOR              value: '3'            - name: DEFAULT_MIN_INSYNC_REPLICAS              value: '2'          volumeMounts:            - name: data              mountPath: /mnt/kafka  volumeClaimTemplates:    - metadata:        name: data      spec:        accessModes:          - \"ReadWriteOnce\"        resources:          requests:            storage: \"1Gi\"---apiVersion: v1kind: Servicemetadata:  name: kafka-svc  namespace: kafka  labels:    app: kafka-appspec:  type: NodePort  ports:    - name: '9092'      port: 9092      protocol: TCP      targetPort: 9092      nodePort: 30092  selector:    app: kafka-appEOF2) Create a topickubectl exec -it kafka-0 -n kafka -- bashkafka-topics.sh --create --topic my-topic --bootstrap-server kafka-svc:9092kafka-topics.sh --list --topic my-topic --bootstrap-server kafka-svc:9092# Produce messagekubectl exec -it kafka-1 -n kafka -- bashkafka-console-producer.sh --bootstrap-server kafka-svc:9092 --topic my-topic  All pods must be running3) Consume message# consumerkubectl exec -it kafka-1 -n kafka -- bashkafka-console-consumer.sh --bootstrap-server kafka-svc:9092 --topic my-topic  Run the producer and consumer in different Linux terminals4) Delete topickafka-topics.sh --delete --topic my-topic --bootstrap-server kafka-svc:9092Kafka KRaft x Kafka with ZooKeeperKafka KRaft Installation: KRaft is Kafka‚Äôs new built-in consensus mechanism that eliminates the need for ZooKeeper. In a KRaft-based installation, Kafka brokers manage metadata and leader election directly, which simplifies the architecture by reducing dependencies. KRaft is becoming the default option in newer Kafka versions because it provides better scalability, faster failover, and an overall more streamlined operation.Kafka with ZooKeeper: In traditional Kafka deployments, ZooKeeper is used to manage the cluster‚Äôs metadata, such as broker details and topic configurations. ZooKeeper handles tasks like leader election and tracking which brokers are active. While this setup has been robust for years, it adds complexity by requiring an additional service (ZooKeeper) that must be installed, managed, and maintained alongside Kafka.RabbitMQ1) Create a YAML file /tmp/rabbitmq.yml with the content belowapiVersion: v1kind: Namespacemetadata:  name: rabbitmqspec: {}status: {}---apiVersion: v1kind: ServiceAccountmetadata:  name: rabbitmq  namespace: rabbitmq---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata:  name: rabbitmq  namespace: rabbitmqrules:- apiGroups:    - \"\"  resources:    - endpoints  verbs:    - get    - list    - watch---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata:  name: rabbitmq  namespace: rabbitmqsubjects:- kind: ServiceAccount  name: rabbitmqroleRef:  apiGroup: rbac.authorization.k8s.io  kind: Role   name: rabbitmq---apiVersion: v1kind: Secretmetadata:  name: rabbit-secret  namespace: rabbitmqtype: Opaquedata:  RABBITMQ_ERLANG_COOKIE: V0lXVkhDRFRDSVVBV0FOTE1RQVc=  RABBITMQ_DEFAULT_USER: Y29lbGhv  RABBITMQ_DEFAULT_PASS: Y29lbGhvQFBhc3M=---apiVersion: v1kind: ConfigMapmetadata:  name: rabbitmq-config  namespace: rabbitmqdata:  enabled_plugins: |    [rabbitmq_management,rabbitmq_peer_discovery_k8s].  rabbitmq.conf: |    ## Cluster formation. See http://www.rabbitmq.com/cluster-formation.html to learn more.    cluster_formation.peer_discovery_backend  = rabbit_peer_discovery_k8s    cluster_formation.k8s.host = kubernetes.default.svc.cluster.local    ## Should RabbitMQ node name be computed from the pod's hostname or IP address?    ## IP addresses are not stable, so using [stable] hostnames is recommended when possible.    ## Set to \"hostname\" to use pod hostnames.    ## When this value is changed, so should the variable used to set the RABBITMQ_NODENAME    ## environment variable.    cluster_formation.k8s.address_type = hostname\t      ## Important - this is the suffix of the hostname, as each node gets \"rabbitmq-#\", we need to tell what's the suffix    ## it will give each new node that enters the way to contact the other peer node and join the cluster (if using hostname)    cluster_formation.k8s.hostname_suffix = .rabbitmq.test-rabbitmq.svc.cluster.local    ## How often should node cleanup checks run?    cluster_formation.node_cleanup.interval = 30    ## Set to false if automatic removal of unknown/absent nodes    ## is desired. This can be dangerous, see    ##  * http://www.rabbitmq.com/cluster-formation.html#node-health-checks-and-cleanup    ##  * https://groups.google.com/forum/#!msg/rabbitmq-users/wuOfzEywHXo/k8z_HWIkBgAJ    cluster_formation.node_cleanup.only_log_warning = true    cluster_partition_handling = autoheal    ## See http://www.rabbitmq.com/ha.html#master-migration-data-locality    queue_master_locator=min-masters    ## See http://www.rabbitmq.com/access-control.html#loopback-users    loopback_users.guest = false---apiVersion: apps/v1kind: StatefulSetmetadata:  name: rabbitmq  namespace: rabbitmqspec:  serviceName: rabbitmq  replicas: 3  selector:    matchLabels:      app: rabbitmq  template:    metadata:      labels:        app: rabbitmq    spec:      serviceAccountName: rabbitmq      initContainers:      - name: config        image: busybox        command: ['/bin/sh', '-c', 'cp /tmp/config/rabbitmq.conf /config/rabbitmq.conf &amp;&amp; ls -l /config/ &amp;&amp; cp /tmp/config/enabled_plugins /etc/rabbitmq/enabled_plugins']        volumeMounts:         - name: config          mountPath: /tmp/config/          readOnly: false        - name: config-file          mountPath: /config/        - name: plugins-file          mountPath: /etc/rabbitmq/        resources: # QoS Guaranteed limit e request iguais          limits:            cpu: 1            memory: 2Gi          requests:            cpu: 1            memory: 2Gi      containers:      - name: rabbitmq        image: rabbitmq:3.13.7-management        ports:        - containerPort: 15672          name: discovery        - containerPort: 5672          name: amqp        env:        - name: RABBIT_POD_NAME          valueFrom:            fieldRef:              apiVersion: v1              fieldPath: metadata.name        - name: RABBIT_POD_NAMESPACE          valueFrom:            fieldRef:              fieldPath: metadata.namespace        - name: RABBITMQ_NODENAME          value: rabbit@$(RABBIT_POD_NAME).rabbitmq.$(RABBIT_POD_NAMESPACE).svc.cluster.local        - name: RABBITMQ_USE_LONGNAME          value: \"true\"        - name: RABBITMQ_CONFIG_FILE          value: \"/config/rabbitmq\"        - name: RABBITMQ_DEFAULT_USER          # value: \"user\"          valueFrom:            secretKeyRef:              name: rabbit-secret              key: RABBITMQ_DEFAULT_USER        - name: RABBITMQ_DEFAULT_PASS          # value: \"password\"          valueFrom:            secretKeyRef:              name: rabbit-secret              key: RABBITMQ_DEFAULT_PASS        - name: K8S_HOSTNAME_SUFFIX          value: .rabbitmq.$(RABBIT_POD_NAMESPACE).svc.cluster.local        volumeMounts:        - name: rabbitmq-pvc-data          mountPath: /var/lib/rabbitmq          readOnly: false        - name: config-file          mountPath: /config/        - name: plugins-file          mountPath: /etc/rabbitmq/        resources: # QoS Guaranteed limit e request iguais          limits:            cpu: 1            memory: 2Gi          # requests:          #   cpu: 0.2m          #   memory: 128Mi      volumes:      - name: config-file        emptyDir: {}      - name: plugins-file        emptyDir: {}      - name: config        configMap:          name: rabbitmq-config          defaultMode: 0755  volumeClaimTemplates:  - metadata:      name: rabbitmq-pvc-data    spec:      accessModes: [\"ReadWriteOnce\"]      # storageClassName: huawei-csi      storageClassName: \"standard\"      resources:        requests:          storage: 1Gi---apiVersion: v1kind: Servicemetadata:  name: rabbitmq  namespace: rabbitmqspec:  type: ClusterIP  ports:  - port: 15672    targetPort: 15672    name: discovery  - port: 5672    targetPort: 5672    name: amqp  selector:    app: rabbitmq2) Apply file /tmp/rabbitmq.ymlkubectl apply -f /tmp/rabbitmq.yml3) Port-forwardkubectl port-forward svc/rabbitmq 15672:15672 -n rabbitmq  Access http://localhost:15672/ User: coelho Password: coelho@Pass",
            "content_html": "<h1 id=\"index\">Index</h1><ul>  <li><a href=\"#index\">Index</a>    <ul>      <li><a href=\"#create-kubernetes-cluster-with-kind\">Create kubernetes cluster with kind</a></li>      <li><a href=\"#kafka\">Kafka</a>        <ul>          <li><a href=\"#kafka-kraft-x-kafka-with-zookeeper\">Kafka KRaft x Kafka with ZooKeeper</a></li>        </ul>      </li>      <li><a href=\"#rabbitmq\">RabbitMQ</a></li>    </ul>  </li></ul><h2 id=\"create-kubernetes-cluster-with-kind\">Create kubernetes cluster with kind</h2><p>1) Create kind configuration(<em>kind-config.yaml</em>)</p><div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"s\">cat &lt;&lt;EOF &gt; /tmp/kind-config.yml</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">kind.x-k8s.io/v1alpha4</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Cluster</span><span class=\"na\">nodes</span><span class=\"pi\">:</span><span class=\"pi\">-</span> <span class=\"na\">role</span><span class=\"pi\">:</span> <span class=\"s\">control-plane</span>  <span class=\"na\">extraPortMappings</span><span class=\"pi\">:</span>  <span class=\"pi\">-</span> <span class=\"na\">containerPort</span><span class=\"pi\">:</span> <span class=\"m\">30092</span>    <span class=\"na\">hostPort</span><span class=\"pi\">:</span> <span class=\"m\">30092</span>    <span class=\"na\">listenAddress</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">0.0.0.0\"</span> <span class=\"c1\"># Optional, defaults to \"0.0.0.0\"</span>    <span class=\"na\">protocol</span><span class=\"pi\">:</span> <span class=\"s\">tcp</span> <span class=\"c1\"># Optional, defaults to tcp</span><span class=\"pi\">-</span> <span class=\"na\">role</span><span class=\"pi\">:</span> <span class=\"s\">worker</span><span class=\"pi\">-</span> <span class=\"na\">role</span><span class=\"pi\">:</span> <span class=\"s\">worker</span><span class=\"pi\">-</span> <span class=\"na\">role</span><span class=\"pi\">:</span> <span class=\"s\">worker</span><span class=\"s\">EOF</span></code></pre></div></div><p>2) Create a kind cluster</p><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>kind create cluster <span class=\"nt\">--config</span> /tmp/kind-config.yml <span class=\"nt\">--name</span> my-cluster</code></pre></div></div><h2 id=\"kafka\">Kafka</h2><p>1) Apply yaml</p><div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"s\">cat &lt;&lt;EOF | kubectl apply -f -</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Namespace</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span>  <span class=\"na\">labels</span><span class=\"pi\">:</span>    <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span><span class=\"nn\">---</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">apps/v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">StatefulSet</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span>  <span class=\"na\">labels</span><span class=\"pi\">:</span>    <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">kafka-app</span><span class=\"na\">spec</span><span class=\"pi\">:</span>  <span class=\"na\">serviceName</span><span class=\"pi\">:</span> <span class=\"s\">kafka-svc</span>  <span class=\"na\">replicas</span><span class=\"pi\">:</span> <span class=\"m\">3</span>  <span class=\"na\">selector</span><span class=\"pi\">:</span>    <span class=\"na\">matchLabels</span><span class=\"pi\">:</span>      <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">kafka-app</span>  <span class=\"na\">template</span><span class=\"pi\">:</span>    <span class=\"na\">metadata</span><span class=\"pi\">:</span>      <span class=\"na\">labels</span><span class=\"pi\">:</span>        <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">kafka-app</span>    <span class=\"na\">spec</span><span class=\"pi\">:</span>      <span class=\"na\">containers</span><span class=\"pi\">:</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">kafka-container</span>          <span class=\"na\">image</span><span class=\"pi\">:</span> <span class=\"s\">doughgle/kafka-kraft</span>          <span class=\"na\">ports</span><span class=\"pi\">:</span>            <span class=\"pi\">-</span> <span class=\"na\">containerPort</span><span class=\"pi\">:</span> <span class=\"m\">9092</span>            <span class=\"pi\">-</span> <span class=\"na\">containerPort</span><span class=\"pi\">:</span> <span class=\"m\">9093</span>          <span class=\"na\">env</span><span class=\"pi\">:</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">REPLICAS</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">3'</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">SERVICE</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s\">kafka-svc</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">NAMESPACE</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">SHARE_DIR</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s\">/mnt/kafka</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">CLUSTER_ID</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s\">bXktY2x1c3Rlci0xMjM0NQ==</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">DEFAULT_REPLICATION_FACTOR</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">3'</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">DEFAULT_MIN_INSYNC_REPLICAS</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">2'</span>          <span class=\"na\">volumeMounts</span><span class=\"pi\">:</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">data</span>              <span class=\"na\">mountPath</span><span class=\"pi\">:</span> <span class=\"s\">/mnt/kafka</span>  <span class=\"na\">volumeClaimTemplates</span><span class=\"pi\">:</span>    <span class=\"pi\">-</span> <span class=\"na\">metadata</span><span class=\"pi\">:</span>        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">data</span>      <span class=\"na\">spec</span><span class=\"pi\">:</span>        <span class=\"na\">accessModes</span><span class=\"pi\">:</span>          <span class=\"pi\">-</span> <span class=\"s2\">\"</span><span class=\"s\">ReadWriteOnce\"</span>        <span class=\"na\">resources</span><span class=\"pi\">:</span>          <span class=\"na\">requests</span><span class=\"pi\">:</span>            <span class=\"na\">storage</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">1Gi\"</span><span class=\"nn\">---</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Service</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">kafka-svc</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span>  <span class=\"na\">labels</span><span class=\"pi\">:</span>    <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">kafka-app</span><span class=\"na\">spec</span><span class=\"pi\">:</span>  <span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">NodePort</span>  <span class=\"na\">ports</span><span class=\"pi\">:</span>    <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">9092'</span>      <span class=\"na\">port</span><span class=\"pi\">:</span> <span class=\"m\">9092</span>      <span class=\"na\">protocol</span><span class=\"pi\">:</span> <span class=\"s\">TCP</span>      <span class=\"na\">targetPort</span><span class=\"pi\">:</span> <span class=\"m\">9092</span>      <span class=\"na\">nodePort</span><span class=\"pi\">:</span> <span class=\"m\">30092</span>  <span class=\"na\">selector</span><span class=\"pi\">:</span>    <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">kafka-app</span><span class=\"s\">EOF</span></code></pre></div></div><p>2) Create a topic</p><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>kubectl <span class=\"nb\">exec</span> <span class=\"nt\">-it</span> kafka-0 <span class=\"nt\">-n</span> kafka <span class=\"nt\">--</span> bashkafka-topics.sh <span class=\"nt\">--create</span> <span class=\"nt\">--topic</span> my-topic <span class=\"nt\">--bootstrap-server</span> kafka-svc:9092kafka-topics.sh <span class=\"nt\">--list</span> <span class=\"nt\">--topic</span> my-topic <span class=\"nt\">--bootstrap-server</span> kafka-svc:9092<span class=\"c\"># Produce message</span>kubectl <span class=\"nb\">exec</span> <span class=\"nt\">-it</span> kafka-1 <span class=\"nt\">-n</span> kafka <span class=\"nt\">--</span> bashkafka-console-producer.sh <span class=\"nt\">--bootstrap-server</span> kafka-svc:9092 <span class=\"nt\">--topic</span> my-topic</code></pre></div></div><blockquote>  <p>All pods must be running</p></blockquote><p>3) Consume message</p><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\"># consumer</span>kubectl <span class=\"nb\">exec</span> <span class=\"nt\">-it</span> kafka-1 <span class=\"nt\">-n</span> kafka <span class=\"nt\">--</span> bashkafka-console-consumer.sh <span class=\"nt\">--bootstrap-server</span> kafka-svc:9092 <span class=\"nt\">--topic</span> my-topic</code></pre></div></div><blockquote>  <p>Run the producer and consumer in different Linux terminals</p></blockquote><p>4) Delete topic</p><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>kafka-topics.sh <span class=\"nt\">--delete</span> <span class=\"nt\">--topic</span> my-topic <span class=\"nt\">--bootstrap-server</span> kafka-svc:9092</code></pre></div></div><h4 id=\"kafka-kraft-x-kafka-with-zookeeper\">Kafka KRaft x Kafka with ZooKeeper</h4><p><strong>Kafka KRaft Installation</strong>: KRaft is Kafka‚Äôs new built-in consensus mechanism that eliminates the need for ZooKeeper. In a KRaft-based installation, Kafka brokers manage metadata and leader election directly, which simplifies the architecture by reducing dependencies. KRaft is becoming the default option in newer Kafka versions because it provides better scalability, faster failover, and an overall more streamlined operation.</p><p><strong>Kafka with ZooKeeper</strong>: In traditional Kafka deployments, ZooKeeper is used to manage the cluster‚Äôs metadata, such as broker details and topic configurations. ZooKeeper handles tasks like leader election and tracking which brokers are active. While this setup has been robust for years, it adds complexity by requiring an additional service (ZooKeeper) that must be installed, managed, and maintained alongside Kafka.</p><h2 id=\"rabbitmq\">RabbitMQ</h2><p>1) Create a YAML file <em>/tmp/rabbitmq.yml</em> with the content below</p><div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Namespace</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span><span class=\"na\">spec</span><span class=\"pi\">:</span> <span class=\"pi\">{}</span><span class=\"na\">status</span><span class=\"pi\">:</span> <span class=\"pi\">{}</span><span class=\"nn\">---</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">ServiceAccount</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span><span class=\"nn\">---</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Role</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">rbac.authorization.k8s.io/v1</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span><span class=\"na\">rules</span><span class=\"pi\">:</span><span class=\"pi\">-</span> <span class=\"na\">apiGroups</span><span class=\"pi\">:</span>    <span class=\"pi\">-</span> <span class=\"s2\">\"</span><span class=\"s\">\"</span>  <span class=\"na\">resources</span><span class=\"pi\">:</span>    <span class=\"pi\">-</span> <span class=\"s\">endpoints</span>  <span class=\"na\">verbs</span><span class=\"pi\">:</span>    <span class=\"pi\">-</span> <span class=\"s\">get</span>    <span class=\"pi\">-</span> <span class=\"s\">list</span>    <span class=\"pi\">-</span> <span class=\"s\">watch</span><span class=\"nn\">---</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">RoleBinding</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">rbac.authorization.k8s.io/v1</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span><span class=\"na\">subjects</span><span class=\"pi\">:</span><span class=\"pi\">-</span> <span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">ServiceAccount</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span><span class=\"na\">roleRef</span><span class=\"pi\">:</span>  <span class=\"na\">apiGroup</span><span class=\"pi\">:</span> <span class=\"s\">rbac.authorization.k8s.io</span>  <span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Role</span>   <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span><span class=\"nn\">---</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Secret</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbit-secret</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span><span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">Opaque</span><span class=\"na\">data</span><span class=\"pi\">:</span>  <span class=\"na\">RABBITMQ_ERLANG_COOKIE</span><span class=\"pi\">:</span> <span class=\"s\">V0lXVkhDRFRDSVVBV0FOTE1RQVc=</span>  <span class=\"na\">RABBITMQ_DEFAULT_USER</span><span class=\"pi\">:</span> <span class=\"s\">Y29lbGhv</span>  <span class=\"na\">RABBITMQ_DEFAULT_PASS</span><span class=\"pi\">:</span> <span class=\"s\">Y29lbGhvQFBhc3M=</span><span class=\"nn\">---</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">ConfigMap</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq-config</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span><span class=\"na\">data</span><span class=\"pi\">:</span>  <span class=\"na\">enabled_plugins</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>    <span class=\"s\">[rabbitmq_management,rabbitmq_peer_discovery_k8s].</span>  <span class=\"na\">rabbitmq.conf</span><span class=\"pi\">:</span> <span class=\"pi\">|</span>    <span class=\"s\">## Cluster formation. See http://www.rabbitmq.com/cluster-formation.html to learn more.</span>    <span class=\"s\">cluster_formation.peer_discovery_backend  = rabbit_peer_discovery_k8s</span>    <span class=\"s\">cluster_formation.k8s.host = kubernetes.default.svc.cluster.local</span>    <span class=\"s\">## Should RabbitMQ node name be computed from the pod's hostname or IP address?</span>    <span class=\"s\">## IP addresses are not stable, so using [stable] hostnames is recommended when possible.</span>    <span class=\"s\">## Set to \"hostname\" to use pod hostnames.</span>    <span class=\"s\">## When this value is changed, so should the variable used to set the RABBITMQ_NODENAME</span>    <span class=\"s\">## environment variable.</span>    <span class=\"s\">cluster_formation.k8s.address_type = hostname\t  </span>    <span class=\"s\">## Important - this is the suffix of the hostname, as each node gets \"rabbitmq-#\", we need to tell what's the suffix</span>    <span class=\"s\">## it will give each new node that enters the way to contact the other peer node and join the cluster (if using hostname)</span>    <span class=\"s\">cluster_formation.k8s.hostname_suffix = .rabbitmq.test-rabbitmq.svc.cluster.local</span>    <span class=\"s\">## How often should node cleanup checks run?</span>    <span class=\"s\">cluster_formation.node_cleanup.interval = 30</span>    <span class=\"s\">## Set to false if automatic removal of unknown/absent nodes</span>    <span class=\"s\">## is desired. This can be dangerous, see</span>    <span class=\"s\">##  * http://www.rabbitmq.com/cluster-formation.html#node-health-checks-and-cleanup</span>    <span class=\"s\">##  * https://groups.google.com/forum/#!msg/rabbitmq-users/wuOfzEywHXo/k8z_HWIkBgAJ</span>    <span class=\"s\">cluster_formation.node_cleanup.only_log_warning = true</span>    <span class=\"s\">cluster_partition_handling = autoheal</span>    <span class=\"s\">## See http://www.rabbitmq.com/ha.html#master-migration-data-locality</span>    <span class=\"s\">queue_master_locator=min-masters</span>    <span class=\"s\">## See http://www.rabbitmq.com/access-control.html#loopback-users</span>    <span class=\"s\">loopback_users.guest = false</span><span class=\"s\">---</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">apps/v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">StatefulSet</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span><span class=\"na\">spec</span><span class=\"pi\">:</span>  <span class=\"na\">serviceName</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span>  <span class=\"na\">replicas</span><span class=\"pi\">:</span> <span class=\"m\">3</span>  <span class=\"na\">selector</span><span class=\"pi\">:</span>    <span class=\"na\">matchLabels</span><span class=\"pi\">:</span>      <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span>  <span class=\"na\">template</span><span class=\"pi\">:</span>    <span class=\"na\">metadata</span><span class=\"pi\">:</span>      <span class=\"na\">labels</span><span class=\"pi\">:</span>        <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span>    <span class=\"na\">spec</span><span class=\"pi\">:</span>      <span class=\"na\">serviceAccountName</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span>      <span class=\"na\">initContainers</span><span class=\"pi\">:</span>      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">config</span>        <span class=\"na\">image</span><span class=\"pi\">:</span> <span class=\"s\">busybox</span>        <span class=\"na\">command</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"s1\">'</span><span class=\"s\">/bin/sh'</span><span class=\"pi\">,</span> <span class=\"s1\">'</span><span class=\"s\">-c'</span><span class=\"pi\">,</span> <span class=\"s1\">'</span><span class=\"s\">cp</span><span class=\"nv\"> </span><span class=\"s\">/tmp/config/rabbitmq.conf</span><span class=\"nv\"> </span><span class=\"s\">/config/rabbitmq.conf</span><span class=\"nv\"> </span><span class=\"s\">&amp;&amp;</span><span class=\"nv\"> </span><span class=\"s\">ls</span><span class=\"nv\"> </span><span class=\"s\">-l</span><span class=\"nv\"> </span><span class=\"s\">/config/</span><span class=\"nv\"> </span><span class=\"s\">&amp;&amp;</span><span class=\"nv\"> </span><span class=\"s\">cp</span><span class=\"nv\"> </span><span class=\"s\">/tmp/config/enabled_plugins</span><span class=\"nv\"> </span><span class=\"s\">/etc/rabbitmq/enabled_plugins'</span><span class=\"pi\">]</span>        <span class=\"na\">volumeMounts</span><span class=\"pi\">:</span>         <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">config</span>          <span class=\"na\">mountPath</span><span class=\"pi\">:</span> <span class=\"s\">/tmp/config/</span>          <span class=\"na\">readOnly</span><span class=\"pi\">:</span> <span class=\"no\">false</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">config-file</span>          <span class=\"na\">mountPath</span><span class=\"pi\">:</span> <span class=\"s\">/config/</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">plugins-file</span>          <span class=\"na\">mountPath</span><span class=\"pi\">:</span> <span class=\"s\">/etc/rabbitmq/</span>        <span class=\"na\">resources</span><span class=\"pi\">:</span> <span class=\"c1\"># QoS Guaranteed limit e request iguais</span>          <span class=\"na\">limits</span><span class=\"pi\">:</span>            <span class=\"na\">cpu</span><span class=\"pi\">:</span> <span class=\"m\">1</span>            <span class=\"na\">memory</span><span class=\"pi\">:</span> <span class=\"s\">2Gi</span>          <span class=\"na\">requests</span><span class=\"pi\">:</span>            <span class=\"na\">cpu</span><span class=\"pi\">:</span> <span class=\"m\">1</span>            <span class=\"na\">memory</span><span class=\"pi\">:</span> <span class=\"s\">2Gi</span>      <span class=\"na\">containers</span><span class=\"pi\">:</span>      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span>        <span class=\"na\">image</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq:3.13.7-management</span>        <span class=\"na\">ports</span><span class=\"pi\">:</span>        <span class=\"pi\">-</span> <span class=\"na\">containerPort</span><span class=\"pi\">:</span> <span class=\"m\">15672</span>          <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">discovery</span>        <span class=\"pi\">-</span> <span class=\"na\">containerPort</span><span class=\"pi\">:</span> <span class=\"m\">5672</span>          <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">amqp</span>        <span class=\"na\">env</span><span class=\"pi\">:</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">RABBIT_POD_NAME</span>          <span class=\"na\">valueFrom</span><span class=\"pi\">:</span>            <span class=\"na\">fieldRef</span><span class=\"pi\">:</span>              <span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span>              <span class=\"na\">fieldPath</span><span class=\"pi\">:</span> <span class=\"s\">metadata.name</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">RABBIT_POD_NAMESPACE</span>          <span class=\"na\">valueFrom</span><span class=\"pi\">:</span>            <span class=\"na\">fieldRef</span><span class=\"pi\">:</span>              <span class=\"na\">fieldPath</span><span class=\"pi\">:</span> <span class=\"s\">metadata.namespace</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">RABBITMQ_NODENAME</span>          <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s\">rabbit@$(RABBIT_POD_NAME).rabbitmq.$(RABBIT_POD_NAMESPACE).svc.cluster.local</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">RABBITMQ_USE_LONGNAME</span>          <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">true\"</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">RABBITMQ_CONFIG_FILE</span>          <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">/config/rabbitmq\"</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">RABBITMQ_DEFAULT_USER</span>          <span class=\"c1\"># value: \"user\"</span>          <span class=\"na\">valueFrom</span><span class=\"pi\">:</span>            <span class=\"na\">secretKeyRef</span><span class=\"pi\">:</span>              <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbit-secret</span>              <span class=\"na\">key</span><span class=\"pi\">:</span> <span class=\"s\">RABBITMQ_DEFAULT_USER</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">RABBITMQ_DEFAULT_PASS</span>          <span class=\"c1\"># value: \"password\"</span>          <span class=\"na\">valueFrom</span><span class=\"pi\">:</span>            <span class=\"na\">secretKeyRef</span><span class=\"pi\">:</span>              <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbit-secret</span>              <span class=\"na\">key</span><span class=\"pi\">:</span> <span class=\"s\">RABBITMQ_DEFAULT_PASS</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">K8S_HOSTNAME_SUFFIX</span>          <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s\">.rabbitmq.$(RABBIT_POD_NAMESPACE).svc.cluster.local</span>        <span class=\"na\">volumeMounts</span><span class=\"pi\">:</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq-pvc-data</span>          <span class=\"na\">mountPath</span><span class=\"pi\">:</span> <span class=\"s\">/var/lib/rabbitmq</span>          <span class=\"na\">readOnly</span><span class=\"pi\">:</span> <span class=\"no\">false</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">config-file</span>          <span class=\"na\">mountPath</span><span class=\"pi\">:</span> <span class=\"s\">/config/</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">plugins-file</span>          <span class=\"na\">mountPath</span><span class=\"pi\">:</span> <span class=\"s\">/etc/rabbitmq/</span>        <span class=\"na\">resources</span><span class=\"pi\">:</span> <span class=\"c1\"># QoS Guaranteed limit e request iguais</span>          <span class=\"na\">limits</span><span class=\"pi\">:</span>            <span class=\"na\">cpu</span><span class=\"pi\">:</span> <span class=\"m\">1</span>            <span class=\"na\">memory</span><span class=\"pi\">:</span> <span class=\"s\">2Gi</span>          <span class=\"c1\"># requests:</span>          <span class=\"c1\">#   cpu: 0.2m</span>          <span class=\"c1\">#   memory: 128Mi</span>      <span class=\"na\">volumes</span><span class=\"pi\">:</span>      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">config-file</span>        <span class=\"na\">emptyDir</span><span class=\"pi\">:</span> <span class=\"pi\">{}</span>      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">plugins-file</span>        <span class=\"na\">emptyDir</span><span class=\"pi\">:</span> <span class=\"pi\">{}</span>      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">config</span>        <span class=\"na\">configMap</span><span class=\"pi\">:</span>          <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq-config</span>          <span class=\"na\">defaultMode</span><span class=\"pi\">:</span> <span class=\"m\">0755</span>  <span class=\"na\">volumeClaimTemplates</span><span class=\"pi\">:</span>  <span class=\"pi\">-</span> <span class=\"na\">metadata</span><span class=\"pi\">:</span>      <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq-pvc-data</span>    <span class=\"na\">spec</span><span class=\"pi\">:</span>      <span class=\"na\">accessModes</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"s2\">\"</span><span class=\"s\">ReadWriteOnce\"</span><span class=\"pi\">]</span>      <span class=\"c1\"># storageClassName: huawei-csi</span>      <span class=\"na\">storageClassName</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">standard\"</span>      <span class=\"na\">resources</span><span class=\"pi\">:</span>        <span class=\"na\">requests</span><span class=\"pi\">:</span>          <span class=\"na\">storage</span><span class=\"pi\">:</span> <span class=\"s\">1Gi</span><span class=\"nn\">---</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Service</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span><span class=\"na\">spec</span><span class=\"pi\">:</span>  <span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">ClusterIP</span>  <span class=\"na\">ports</span><span class=\"pi\">:</span>  <span class=\"pi\">-</span> <span class=\"na\">port</span><span class=\"pi\">:</span> <span class=\"m\">15672</span>    <span class=\"na\">targetPort</span><span class=\"pi\">:</span> <span class=\"m\">15672</span>    <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">discovery</span>  <span class=\"pi\">-</span> <span class=\"na\">port</span><span class=\"pi\">:</span> <span class=\"m\">5672</span>    <span class=\"na\">targetPort</span><span class=\"pi\">:</span> <span class=\"m\">5672</span>    <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">amqp</span>  <span class=\"na\">selector</span><span class=\"pi\">:</span>    <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">rabbitmq</span></code></pre></div></div><p>2) Apply file <em>/tmp/rabbitmq.yml</em></p><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>kubectl apply <span class=\"nt\">-f</span> /tmp/rabbitmq.yml</code></pre></div></div><p>3) Port-forward</p><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>kubectl port-forward svc/rabbitmq 15672:15672 <span class=\"nt\">-n</span> rabbitmq</code></pre></div></div><blockquote>  <p>Access http://localhost:15672/ User: coelho Password: coelho@Pass</p></blockquote>",
            "url": "https://apolzek.github.io/2024/09/29/kafka-and-rabbitmq-on-kubernetes",
            
            
            
            "tags": ["kafka","kind","kubernetes","rabbitmq"],
            
            "date_published": "2024-09-29T00:00:00+00:00",
            "date_modified": "2024-09-29T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2024/09/27/mvp-localhot-day1",
            "title": "üí° MVP localhot - day 1",
            "summary": "Building the localhot MVP",
            "content_text": "About this initiativeI recently saw a project on YouTube where the YouTuber created a complete product and put it into production (online). I liked the idea and thought about creating a real project‚Ä¶ starting from localhost to production. I don‚Äôt consider myself a good programmer, but I‚Äôm looking for a well-made bean and rice. My main focus is to launch a stable product with acceptable security standards and that simply implements the idea as it is now in my mind. I present to you the localhot project. You can follow the progress of this through a series of articles on this blog!üó£Ô∏è I intend to run this on-premisesI know there are already similar projects on the internet, but most of them focus on development and not on operations. I have two main goals. The first is to test technologies, discuss decisions and show concerns that usually arise when our project goes into production. The second is to perhaps make some money with this. My initial focus is Brazilian software developers. In general, I get along well with developers.Let‚Äôs get started. What follows is information about the project. To be quite honest, what I intend to build already exists, something similar to render.com.. but with some differences.localhot üöÄlocalhot is not introducing an innovative solution but rather offering a new way of delivering container-based application hosting, designed for developers of all levels, SREs, DevOps, and QAs. By abstracting infrastructure and networking, it enables fast, cost-effective container deployment. Users can make applications publicly accessible or control access as needed. Unlike traditional solutions focused on large enterprises with strict SLAs, localhot prioritizes simplicity and accessibility, creating an agile environment for rapid testing and iteration, without the complexity of managing traditional servers.I‚Äôm still thinking about the legal issues..About the ideaThe idea is basically a render.com with some differences. I want to do something more ‚Äúapi first‚Äù. I want to do it in a way that is similar to the way people work with containers locally and I also want to offer a way for them to have details about their applications by adding components to the infrastructure that abstract away the complexity of doing so.What do I need ?Considering that I have no money, no computing resources, and no advanced programming skills (that makes it too hard ü§£ü§£), I need to focus on something simple that works. I want to create a business abstraction on top of Kubernetes and put all the complexity into it using tools I have experience with. I need a cheap domain like localhot.io. I need a payment method and reasonable bandwidth. I want to physically separate the servers where applications are from the servers where the end-user containers will be. I need to think about security and a business model that is viable for Brazilian developers.For the first poc‚Äôs, the simpler the better. I intend to use python or golang for this. I will use kind as the local kubernetes environment, the local registry of my machine for the images and also my local network. The networking part is very important in this project, but first I want a functional MVP.to be continued..So, that‚Äôs it. I‚Äôve reached the end of my first article. I hope I‚Äôve been clear about my idea. In the end, even if everything goes wrong, I will have gained valuable knowledge. These notes may be useful to someone else, and even to my future self. What‚Äôs coming next? A series of reflections, articles about random tools, and some not-so-professional code (:See you around !",
            "content_html": "<h2 id=\"about-this-initiative\">About this initiative</h2><p>I recently saw a project on YouTube where the YouTuber created a complete product and put it into production (online). I liked the idea and thought about creating a real project‚Ä¶ starting from localhost to production. I don‚Äôt consider myself a good programmer, but I‚Äôm looking for a well-made bean and rice. My main focus is to launch a stable product with acceptable security standards and that simply implements the idea as it is now in my mind. I present to you the <strong>localhot</strong> project. You can follow the progress of this through a series of articles on this blog!</p><p>üó£Ô∏è <em>I intend to run this on-premises</em></p><p>I know there are already similar projects on the internet, but most of them focus on <em>development</em> and not on <em>operations</em>. I have two main goals. The first is to test technologies, discuss decisions and show concerns that usually arise when our project goes into production. The second is to perhaps make some money with this. My initial focus is Brazilian software developers. In general, I get along well with developers.</p><p>Let‚Äôs get started. What follows is information about the project. To be quite honest, what I intend to build already exists, something similar to <em>render.com</em>.. but with some differences.</p><h3 id=\"localhot-\">localhot üöÄ</h3><p><strong>localhot</strong> is <strong>not</strong> introducing an innovative solution but rather offering <strong>a new way of delivering container-based application hosting</strong>, designed for developers of all levels, SREs, DevOps, and QAs. By abstracting infrastructure and networking, it enables fast, cost-effective container deployment. Users can make applications publicly accessible or control access as needed. Unlike traditional solutions focused on large enterprises with strict SLAs, <strong>localhot</strong> prioritizes simplicity and accessibility, creating an agile environment for rapid testing and iteration, without the complexity of managing traditional servers.</p><p>I‚Äôm still thinking about the legal issues..</p><h3 id=\"about-the-idea\">About the idea</h3><p>The idea is basically a <em>render.com</em> with some differences. I want to do something more ‚Äúapi first‚Äù. I want to do it in a way that is similar to the way people work with containers locally and I also want to offer a way for them to have details about their applications by adding components to the infrastructure that abstract away the complexity of doing so.</p><h3 id=\"what-do-i-need-\">What do I need ?</h3><p>Considering that I have no money, no computing resources, and no advanced programming skills (that makes it too hard ü§£ü§£), I need to focus on something simple that works. I want to create a business abstraction on top of Kubernetes and put all the complexity into it using tools I have experience with. I need a cheap domain like <strong>localhot.io</strong>. I need a payment method and reasonable bandwidth. I want to physically separate the servers where applications are from the servers where the end-user containers will be. I need to think about security and a business model that is viable for Brazilian developers.</p><p>For the first poc‚Äôs, the simpler the better. I intend to use python or golang for this. I will use kind as the local kubernetes environment, the local registry of my machine for the images and also my local network. The networking part is very important in this project, but first I want a functional MVP.</p><h3 id=\"to-be-continued\">to be continued..</h3><p>So, that‚Äôs it. I‚Äôve reached the end of my first article. I hope I‚Äôve been clear about my idea. In the end, even if everything goes wrong, I will have gained valuable knowledge. These notes may be useful to someone else, and even to my future self. What‚Äôs coming next? A series of reflections, articles about random tools, and some not-so-professional code <strong>(</strong>:</p><p>See you around !</p><p><img src=\"https://raw.githubusercontent.com/apolzek/apolzek.github.io/refs/heads/main/assets/gif/working.webp\" alt=\"working\" /></p>",
            "url": "https://apolzek.github.io/2024/09/27/mvp-localhot-day1",
            
            
            
            "tags": ["devops","sre","project","startup"],
            
            "date_published": "2024-09-27T00:00:00+00:00",
            "date_modified": "2024-09-27T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "https://apolzek.github.io/2024/09/26/hello-world",
            "title": "Hello World =)",
            "summary": "ABOUT, GOALS and REMEMBER",
            "content_text": "ABOUT  This blog is a personal project where I share my reflections on reliability engineering, professional growth, and related topics;  English is not my native language, and I‚Äôm using this blog to practice and improve my skills. Please bear with me if you find any grammatical or stylistic errors;  I am a reliability engineer with experience working in Brazil. The views expressed here are my own and do not represent the opinions of my employer or any other organization;  I write primarily for myself;  The content here is for educational purposes and reflects only my personal views. It should not be considered professional advice;GOALS  Talk about tools that are not well-known but have great potential(maybe this will turn into a new project);  Track my studies with short reflective articles;  Share my views on technologies, processes, and products;  Soon, I will revisit my notes to see how my views on certain topics have changed;  Share the results of some POCs and labs with friends/colleagues;SOME RULES  When the üí¨ emoji appears, I want to introduce a point for reflection or an idea exchange(yes, I do talk to myself);  When you see the üó£Ô∏è emoji, it means I know I‚Äôm saying something completely absurd;  There is üïµÔ∏è hidden content within this blog; you can find it by exploring or inspecting the source code;  Fixing is better than criticizing, but any interaction is valuable;  Some articles will be categorized to make it easier to search. Some categories I thought of are:          Review: for reviewing tools, GitHub repositories, or other articles      Fundamentals: for discussing fundamental topics like networks and operating systems      News: for discussing news      REMEMBERüá∫üá∏ ‚ÄúThe only way to make things work well is by understanding why they break.‚Äùüáßüá∑ ‚ÄúA √∫nica maneira de fazer as coisas funcionarem bem √© entendendo o motivo pelo qual elas quebram.‚Äù",
            "content_html": "<h2 id=\"about\">ABOUT</h2><ul>  <li>This blog is a personal project where I share my reflections on reliability engineering, professional growth, and related topics;</li>  <li>English is <strong>not</strong> my native language, and I‚Äôm using this blog to practice and improve my skills. Please bear with me if you find any grammatical or stylistic errors;</li>  <li>I am a reliability engineer with experience working in Brazil. The views expressed here are my own and do not represent the opinions of my employer or any other organization;</li>  <li>I write primarily for myself;</li>  <li>The content here is for educational purposes and reflects only my personal views. It should not be considered professional advice;</li></ul><h2 id=\"goals\">GOALS</h2><ul>  <li>Talk about tools that are not well-known but have great potential(maybe this will turn into a new project);</li>  <li>Track my studies with short reflective articles;</li>  <li>Share my views on technologies, processes, and products;</li>  <li>Soon, I will revisit my notes to see how my views on certain topics have changed;</li>  <li>Share the results of some POCs and labs with friends/colleagues;</li></ul><h2 id=\"some-rules\">SOME RULES</h2><ul>  <li>When the üí¨ emoji appears, I want to introduce a point for reflection or an idea exchange(yes, I do talk to myself);</li>  <li>When you see the üó£Ô∏è emoji, it means I know I‚Äôm saying something completely absurd;</li>  <li>There is üïµÔ∏è hidden content within this blog; you can find it by exploring or inspecting the source code;</li>  <li>Fixing is better than criticizing, but any interaction is valuable;</li>  <li>Some articles will be categorized to make it easier to search. Some categories I thought of are:    <ul>      <li>Review: for reviewing tools, GitHub repositories, or other articles</li>      <li>Fundamentals: for discussing fundamental topics like networks and operating systems</li>      <li>News: for discussing news</li>    </ul>  </li></ul><h2 id=\"remember\">REMEMBER</h2><p>üá∫üá∏ ‚ÄúThe only way to make things work well is by understanding why they break.‚Äù</p><p>üáßüá∑ ‚ÄúA √∫nica maneira de fazer as coisas funcionarem bem √© entendendo o motivo pelo qual elas quebram.‚Äù</p>",
            "url": "https://apolzek.github.io/2024/09/26/hello-world",
            
            
            
            
            
            "date_published": "2024-09-26T00:00:00+00:00",
            "date_modified": "2024-09-26T00:00:00+00:00",
            
                "author":  {
                "name": "apolzek",
                "url": null,
                "avatar": null
                }
                
            
        }
    
    ]
}