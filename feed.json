{
    "version": "https://jsonfeed.org/version/1",
    "title": "apolzek",
    "home_page_url": "/",
    "feed_url": "/feed.json",
    "description": "",
    "icon": "/apple-touch-icon.png",
    "favicon": "/favicon.ico",
    "expired": false,
    
"items": [
    
        {
            "id": "/2024/10/10/sre-interview-questions.html",
            "title": "SRE interview questions",
            "summary": null,
            "content_text": "SRE interview questions",
            "content_html": "<h2 id=\"sre-interview-questions\">SRE interview questions</h2>",
            "url": "/2024/10/10/sre-interview-questions.html",
            
            
            
            "tags": ["sre","interview"],
            
            "date_published": "2024-10-10T00:00:00+00:00",
            "date_modified": "2024-10-10T00:00:00+00:00",
            
                "author": 
                ""
                
            
        },
    
        {
            "id": "/2024/10/10/l0calh0t-startup-day2.html",
            "title": "üí° l0calh0t Startup - day 2",
            "summary": "Building the l0calh0t Startup",
            "content_text": "##",
            "content_html": "<p>##</p>",
            "url": "/2024/10/10/l0calh0t-startup-day2.html",
            
            
            
            "tags": ["devops","sre","project","startup"],
            
            "date_published": "2024-10-10T00:00:00+00:00",
            "date_modified": "2024-10-10T00:00:00+00:00",
            
                "author": 
                ""
                
            
        },
    
        {
            "id": "/2024/10/10/getting-started-x-production-ready.html",
            "title": "The distance between \"getting started\" and \"production ready\"",
            "summary": null,
            "content_text": "The distance between ‚Äúgetting started‚Äù and ‚Äúproduction ready‚Äù",
            "content_html": "<h1 id=\"the-distance-between-getting-started-and-production-ready\">The distance between ‚Äúgetting started‚Äù and ‚Äúproduction ready‚Äù</h1>",
            "url": "/2024/10/10/getting-started-x-production-ready.html",
            
            
            
            
            
            "date_published": "2024-10-10T00:00:00+00:00",
            "date_modified": "2024-10-10T00:00:00+00:00",
            
                "author": 
                ""
                
            
        },
    
        {
            "id": "/2024/09/29/sre-kit-for-the-end-of-the-world.html",
            "title": "üõ†Ô∏è SRE Kit for the End of the World",
            "summary": "Chaos is Inevitable",
            "content_text": "in progress..",
            "content_html": "<p><em>in progress..</em></p>",
            "url": "/2024/09/29/sre-kit-for-the-end-of-the-world.html",
            
            
            
            "tags": ["tools","sre","toolbox","linux"],
            
            "date_published": "2024-09-29T00:00:00+00:00",
            "date_modified": "2024-09-29T00:00:00+00:00",
            
                "author": 
                ""
                
            
        },
    
        {
            "id": "/2024/09/29/spells-for-linux-shell.html",
            "title": "ü™Ñ Spells for Linux Shell",
            "summary": null,
            "content_text": "ü™Ñ Spells for Linux Shell1. loop command x scriptcommandfor i in {1..5}; do echo $i; donecount=1; while [ $count -le 5 ]; do echo $count; ((count++)); donescript#!/bin/bashecho \"Counting to 5 with a for loop:\"for i in {1..5}; do    echo $idoneecho \"Counting to 5 with a while loop:\"count=1while [ $count -le 5 ]; do    echo $count    ((count++))done2. signalsSIGINTThis script creates a temporary file and displays a goodbye message when it receives a SIGINT signal (e.g., when the user presses Ctrl+C).#!/bin/bash# Function that will be called when the script receives the SIGINT signalfunction exitMsg {    echo \"you sent a signal to end, byby !!\"    # command here    exit}# Sets up the trap to call the cleanup function when the script receives SIGINTtrap exitMsg SIGINTsleep 5echo \"Creating a temporary file...\"touch /tmp/apolzek || exit 1  # Creates a temporary file or exits with an errorSIGTERMThis script starts a web server that runs indefinitely and shuts down gracefully when it receives a SIGTERM signal. kill &lt;PID&gt;#!/bin/bash# Function called upon receiving SIGTERMfunction terminateMsg {    echo \"Received SIGTERM, shutting down the server gracefully...\"    # Here you can add commands to close connections or save the state    exit}# Sets up the trap for SIGTERMtrap terminateMsg SIGTERMecho \"Starting web server...\"while true; do    echo \"Server is running... (PID: $$)\"    sleep 2  # Simulates the server's running timedoneSIGHUBThis script starts a daemon that runs indefinitely and reloads its configuration when it receives a SIGHUP signal. kill -HUP &lt;PID&gt;#!/bin/bash# Function called upon receiving SIGHUPfunction reloadMsg {    echo \"Received SIGHUP, reloading configuration...\"    # Here you can add commands to reload the configurations    # Example: source /etc/mydaemon/config.conf}# Sets up the trap for SIGHUPtrap reloadMsg SIGHUPecho \"Starting my daemon...\"while true; do    echo \"Daemon is running... (PID: $$)\"    sleep 5  # Simulates the daemon's running timedone3. background processes#!/bin/bashecho \"Starting background processes...\"# Process 1sleep 3 &amp;  # This simulates a long-running taskpid1=$!  # Get the process ID of process 1# Process 2sleep 9 &amp;  # This simulates a shorter taskpid2=$!  # Get the process ID of process 2# Wait for process 1 to finish and notifywait $pid1echo \"Process 1 has completed.\"# Wait for process 2 to finish and notifywait $pid2echo \"Process 2 has completed.\"echo \"All processes have finished.\"4. debugging#!/bin/bashset -x  # Enable debugging modeecho \"Starting the script...\"echo \"Doing something...\"sleep 1echo \"Ending the script.\"set +x  # Disable debugging modeecho \"now debugging mode is disable\"echo \"did you understand ?\"",
            "content_html": "<h2 id=\"-spells-for-linux-shell\">ü™Ñ Spells for Linux Shell</h2><h3 id=\"1-loop-command-x-script\">1. loop command x script</h3><h4 id=\"command\">command</h4><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">for </span>i <span class=\"k\">in</span> <span class=\"o\">{</span>1..5<span class=\"o\">}</span><span class=\"p\">;</span> <span class=\"k\">do </span><span class=\"nb\">echo</span> <span class=\"nv\">$i</span><span class=\"p\">;</span> <span class=\"k\">done</span><span class=\"nv\">count</span><span class=\"o\">=</span>1<span class=\"p\">;</span> <span class=\"k\">while</span> <span class=\"o\">[</span> <span class=\"nv\">$count</span> <span class=\"nt\">-le</span> 5 <span class=\"o\">]</span><span class=\"p\">;</span> <span class=\"k\">do </span><span class=\"nb\">echo</span> <span class=\"nv\">$count</span><span class=\"p\">;</span> <span class=\"o\">((</span>count++<span class=\"o\">))</span><span class=\"p\">;</span> <span class=\"k\">done</span></code></pre></div></div><h4 id=\"script\">script</h4><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Counting to 5 with a for loop:\"</span><span class=\"k\">for </span>i <span class=\"k\">in</span> <span class=\"o\">{</span>1..5<span class=\"o\">}</span><span class=\"p\">;</span> <span class=\"k\">do    </span><span class=\"nb\">echo</span> <span class=\"nv\">$i</span><span class=\"k\">done</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Counting to 5 with a while loop:\"</span><span class=\"nv\">count</span><span class=\"o\">=</span>1<span class=\"k\">while</span> <span class=\"o\">[</span> <span class=\"nv\">$count</span> <span class=\"nt\">-le</span> 5 <span class=\"o\">]</span><span class=\"p\">;</span> <span class=\"k\">do    </span><span class=\"nb\">echo</span> <span class=\"nv\">$count</span>    <span class=\"o\">((</span>count++<span class=\"o\">))</span><span class=\"k\">done</span></code></pre></div></div><h3 id=\"2-signals\">2. signals</h3><h4 id=\"sigint\">SIGINT</h4><p>This script creates a temporary file and displays a goodbye message when it receives a SIGINT signal (e.g., when the user presses Ctrl+C).</p><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"c\"># Function that will be called when the script receives the SIGINT signal</span><span class=\"k\">function </span>exitMsg <span class=\"o\">{</span>    <span class=\"nb\">echo</span> <span class=\"s2\">\"you sent a signal to end, byby !!\"</span>    <span class=\"c\"># command here</span>    <span class=\"nb\">exit</span><span class=\"o\">}</span><span class=\"c\"># Sets up the trap to call the cleanup function when the script receives SIGINT</span><span class=\"nb\">trap </span>exitMsg SIGINT<span class=\"nb\">sleep </span>5<span class=\"nb\">echo</span> <span class=\"s2\">\"Creating a temporary file...\"</span><span class=\"nb\">touch</span> /tmp/apolzek <span class=\"o\">||</span> <span class=\"nb\">exit </span>1  <span class=\"c\"># Creates a temporary file or exits with an error</span></code></pre></div></div><h4 id=\"sigterm\">SIGTERM</h4><p>This script starts a web server that runs indefinitely and shuts down gracefully when it receives a SIGTERM signal. <code class=\"language-plaintext highlighter-rouge\">kill &lt;PID&gt;</code></p><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"c\"># Function called upon receiving SIGTERM</span><span class=\"k\">function </span>terminateMsg <span class=\"o\">{</span>    <span class=\"nb\">echo</span> <span class=\"s2\">\"Received SIGTERM, shutting down the server gracefully...\"</span>    <span class=\"c\"># Here you can add commands to close connections or save the state</span>    <span class=\"nb\">exit</span><span class=\"o\">}</span><span class=\"c\"># Sets up the trap for SIGTERM</span><span class=\"nb\">trap </span>terminateMsg SIGTERM<span class=\"nb\">echo</span> <span class=\"s2\">\"Starting web server...\"</span><span class=\"k\">while </span><span class=\"nb\">true</span><span class=\"p\">;</span> <span class=\"k\">do    </span><span class=\"nb\">echo</span> <span class=\"s2\">\"Server is running... (PID: </span><span class=\"nv\">$$</span><span class=\"s2\">)\"</span>    <span class=\"nb\">sleep </span>2  <span class=\"c\"># Simulates the server's running time</span><span class=\"k\">done</span></code></pre></div></div><h4 id=\"sighub\">SIGHUB</h4><p>This script starts a daemon that runs indefinitely and reloads its configuration when it receives a SIGHUP signal. <code class=\"language-plaintext highlighter-rouge\">kill -HUP &lt;PID&gt;</code></p><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"c\"># Function called upon receiving SIGHUP</span><span class=\"k\">function </span>reloadMsg <span class=\"o\">{</span>    <span class=\"nb\">echo</span> <span class=\"s2\">\"Received SIGHUP, reloading configuration...\"</span>    <span class=\"c\"># Here you can add commands to reload the configurations</span>    <span class=\"c\"># Example: source /etc/mydaemon/config.conf</span><span class=\"o\">}</span><span class=\"c\"># Sets up the trap for SIGHUP</span><span class=\"nb\">trap </span>reloadMsg SIGHUP<span class=\"nb\">echo</span> <span class=\"s2\">\"Starting my daemon...\"</span><span class=\"k\">while </span><span class=\"nb\">true</span><span class=\"p\">;</span> <span class=\"k\">do    </span><span class=\"nb\">echo</span> <span class=\"s2\">\"Daemon is running... (PID: </span><span class=\"nv\">$$</span><span class=\"s2\">)\"</span>    <span class=\"nb\">sleep </span>5  <span class=\"c\"># Simulates the daemon's running time</span><span class=\"k\">done</span></code></pre></div></div><h3 id=\"3-background-processes\">3. background processes</h3><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Starting background processes...\"</span><span class=\"c\"># Process 1</span><span class=\"nb\">sleep </span>3 &amp;  <span class=\"c\"># This simulates a long-running task</span><span class=\"nv\">pid1</span><span class=\"o\">=</span><span class=\"nv\">$!</span>  <span class=\"c\"># Get the process ID of process 1</span><span class=\"c\"># Process 2</span><span class=\"nb\">sleep </span>9 &amp;  <span class=\"c\"># This simulates a shorter task</span><span class=\"nv\">pid2</span><span class=\"o\">=</span><span class=\"nv\">$!</span>  <span class=\"c\"># Get the process ID of process 2</span><span class=\"c\"># Wait for process 1 to finish and notify</span><span class=\"nb\">wait</span> <span class=\"nv\">$pid1</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Process 1 has completed.\"</span><span class=\"c\"># Wait for process 2 to finish and notify</span><span class=\"nb\">wait</span> <span class=\"nv\">$pid2</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Process 2 has completed.\"</span><span class=\"nb\">echo</span> <span class=\"s2\">\"All processes have finished.\"</span></code></pre></div></div><h3 id=\"4-debugging\">4. debugging</h3><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span><span class=\"nb\">set</span> <span class=\"nt\">-x</span>  <span class=\"c\"># Enable debugging mode</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Starting the script...\"</span><span class=\"nb\">echo</span> <span class=\"s2\">\"Doing something...\"</span><span class=\"nb\">sleep </span>1<span class=\"nb\">echo</span> <span class=\"s2\">\"Ending the script.\"</span><span class=\"nb\">set</span> +x  <span class=\"c\"># Disable debugging mode</span><span class=\"nb\">echo</span> <span class=\"s2\">\"now debugging mode is disable\"</span><span class=\"nb\">echo</span> <span class=\"s2\">\"did you understand ?\"</span></code></pre></div></div>",
            "url": "/2024/09/29/spells-for-linux-shell.html",
            
            
            
            "tags": ["linux","shell","script","bash"],
            
            "date_published": "2024-09-29T00:00:00+00:00",
            "date_modified": "2024-09-29T00:00:00+00:00",
            
                "author": 
                ""
                
            
        },
    
        {
            "id": "/2024/09/29/kafka-on-kubernetes-using-kind.html",
            "title": "Kafka on Kubernetes using Kind",
            "summary": null,
            "content_text": "Kafka on Kubernetes using KindRecently, I came across an article on Medium that explains how to set up a local environment with Kafka in a test folder, using the Kubernetes StatefulSet concept. I decided to bring it to my blog, adding some tips and additional information. Although my knowledge of Kafka is still basic, I already have a few applications in production using this tool ‚Äî and it‚Äôs amazing how well they perform. I was also responsible for creating a solution using Kafka Connect, Kafka, and CDC for the Boleto product.What follows is a simple and easy way to set up a local development environment with Kafka. I‚Äôll also provide a brief introduction to Kafka and explain how you can use this solution in your projects. It‚Äôs important to note that this article is not a ‚ÄúHow to run Kafka in production‚Äù guide, so keep that in mind. I may also add a Kafka command cheatsheet to make my life easier in the future.If you‚Äôre not familiar with Kind, it‚Äôs an easy way to run Kubernetes locally. With Kind, you can use specific Kubernetes versions, configure the network to expose the API server or ports to the host, upload images, and do many other things. Simply install Docker or Podman first, and then install Kind. It‚Äôs a straightforward and easy process.1) Create kind configurationkind-config.yamlapiVersion: kind.x-k8s.io/v1alpha4kind: Clusternodes:- role: control-plane  extraPortMappings:  - containerPort: 30092    hostPort: 30092    listenAddress: \"0.0.0.0\" # Optional, defaults to \"0.0.0.0\"    protocol: tcp # Optional, defaults to tcp- role: worker- role: worker- role: worker2) Create a kind clusterkind create cluster --config kind-config.yaml --name my-cluster3) Create kafka StatefulSet and Namespacekafka.yamlapiVersion: v1kind: Namespacemetadata:  name: kafka  labels:    name: kafka---apiVersion: apps/v1kind: StatefulSetmetadata:  name: kafka  namespace: kafka  labels:    app: kafka-appspec:  serviceName: kafka-svc  replicas: 3  selector:    matchLabels:      app: kafka-app  template:    metadata:      labels:        app: kafka-app    spec:      containers:        - name: kafka-container          image: doughgle/kafka-kraft          ports:            - containerPort: 9092            - containerPort: 9093          env:            - name: REPLICAS              value: '3'            - name: SERVICE              value: kafka-svc            - name: NAMESPACE              value: kafka            - name: SHARE_DIR              value: /mnt/kafka            - name: CLUSTER_ID              value: bXktY2x1c3Rlci0xMjM0NQ==            - name: DEFAULT_REPLICATION_FACTOR              value: '3'            - name: DEFAULT_MIN_INSYNC_REPLICAS              value: '2'          volumeMounts:            - name: data              mountPath: /mnt/kafka  volumeClaimTemplates:    - metadata:        name: data      spec:        accessModes:          - \"ReadWriteOnce\"        resources:          requests:            storage: \"1Gi\"---apiVersion: v1kind: Servicemetadata:  name: kafka-svc  namespace: kafka  labels:    app: kafka-appspec:  type: NodePort  ports:    - name: '9092'      port: 9092      protocol: TCP      targetPort: 9092      nodePort: 30092  selector:    app: kafka-app4) Create a topickubectl exec -it kafka-0 -n kafka -- bashkafka-topics.sh --create --topic my-topic --bootstrap-server kafka-svc:9092kafka-topics.sh --list --topic my-topic --bootstrap-server kafka-svc:90925) Produce and consume messagekubectl exec -it kafka-1 -n kafka -- bashkafka-console-producer.sh  --bootstrap-server kafka-svc:9092 --topic my-topickafka-console-consumer.sh --bootstrap-server kafka-svc:9092 --topic my-topic6) Delete topickafka-topics.sh --delete --topic my-topic --bootstrap-server kafka-svc:9092Kafka KRaft x Kafka with ZooKeeperKafka KRaft Installation: KRaft is Kafka‚Äôs new built-in consensus mechanism that eliminates the need for ZooKeeper. In a KRaft-based installation, Kafka brokers manage metadata and leader election directly, which simplifies the architecture by reducing dependencies. KRaft is becoming the default option in newer Kafka versions because it provides better scalability, faster failover, and an overall more streamlined operation.Kafka with ZooKeeper: In traditional Kafka deployments, ZooKeeper is used to manage the cluster‚Äôs metadata, such as broker details and topic configurations. ZooKeeper handles tasks like leader election and tracking which brokers are active. While this setup has been robust for years, it adds complexity by requiring an additional service (ZooKeeper) that must be installed, managed, and maintained alongside Kafka.",
            "content_html": "<h2 id=\"kafka-on-kubernetes-using-kind\">Kafka on Kubernetes using Kind</h2><p>Recently, I came across an article on Medium that explains how to set up a local environment with Kafka in a test folder, using the Kubernetes StatefulSet concept. I decided to bring it to my blog, adding some tips and additional information. Although my knowledge of Kafka is still basic, I already have a few applications in production using this tool ‚Äî and it‚Äôs amazing how well they perform. I was also responsible for creating a solution using Kafka Connect, Kafka, and CDC for the Boleto product.</p><p>What follows is a simple and easy way to set up a local development environment with Kafka. I‚Äôll also provide a brief introduction to Kafka and explain how you can use this solution in your projects. It‚Äôs important to note that this article is not a ‚ÄúHow to run Kafka in production‚Äù guide, so keep that in mind. I may also add a Kafka command cheatsheet to make my life easier in the future.</p><p>If you‚Äôre not familiar with Kind, it‚Äôs an easy way to run Kubernetes locally. With Kind, you can use specific Kubernetes versions, configure the network to expose the API server or ports to the host, upload images, and do many other things. Simply install Docker or Podman first, and then install Kind. It‚Äôs a straightforward and easy process.</p><p>1) Create kind configuration</p><p><em>kind-config.yaml</em></p><div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">kind.x-k8s.io/v1alpha4</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Cluster</span><span class=\"na\">nodes</span><span class=\"pi\">:</span><span class=\"pi\">-</span> <span class=\"na\">role</span><span class=\"pi\">:</span> <span class=\"s\">control-plane</span>  <span class=\"na\">extraPortMappings</span><span class=\"pi\">:</span>  <span class=\"pi\">-</span> <span class=\"na\">containerPort</span><span class=\"pi\">:</span> <span class=\"m\">30092</span>    <span class=\"na\">hostPort</span><span class=\"pi\">:</span> <span class=\"m\">30092</span>    <span class=\"na\">listenAddress</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">0.0.0.0\"</span> <span class=\"c1\"># Optional, defaults to \"0.0.0.0\"</span>    <span class=\"na\">protocol</span><span class=\"pi\">:</span> <span class=\"s\">tcp</span> <span class=\"c1\"># Optional, defaults to tcp</span><span class=\"pi\">-</span> <span class=\"na\">role</span><span class=\"pi\">:</span> <span class=\"s\">worker</span><span class=\"pi\">-</span> <span class=\"na\">role</span><span class=\"pi\">:</span> <span class=\"s\">worker</span><span class=\"pi\">-</span> <span class=\"na\">role</span><span class=\"pi\">:</span> <span class=\"s\">worker</span></code></pre></div></div><p>2) Create a kind cluster</p><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>kind create cluster <span class=\"nt\">--config</span> kind-config.yaml <span class=\"nt\">--name</span> my-cluster</code></pre></div></div><p>3) Create kafka StatefulSet and Namespace</p><p><em>kafka.yaml</em></p><div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Namespace</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span>  <span class=\"na\">labels</span><span class=\"pi\">:</span>    <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span><span class=\"nn\">---</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">apps/v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">StatefulSet</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span>  <span class=\"na\">labels</span><span class=\"pi\">:</span>    <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">kafka-app</span><span class=\"na\">spec</span><span class=\"pi\">:</span>  <span class=\"na\">serviceName</span><span class=\"pi\">:</span> <span class=\"s\">kafka-svc</span>  <span class=\"na\">replicas</span><span class=\"pi\">:</span> <span class=\"m\">3</span>  <span class=\"na\">selector</span><span class=\"pi\">:</span>    <span class=\"na\">matchLabels</span><span class=\"pi\">:</span>      <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">kafka-app</span>  <span class=\"na\">template</span><span class=\"pi\">:</span>    <span class=\"na\">metadata</span><span class=\"pi\">:</span>      <span class=\"na\">labels</span><span class=\"pi\">:</span>        <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">kafka-app</span>    <span class=\"na\">spec</span><span class=\"pi\">:</span>      <span class=\"na\">containers</span><span class=\"pi\">:</span>        <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">kafka-container</span>          <span class=\"na\">image</span><span class=\"pi\">:</span> <span class=\"s\">doughgle/kafka-kraft</span>          <span class=\"na\">ports</span><span class=\"pi\">:</span>            <span class=\"pi\">-</span> <span class=\"na\">containerPort</span><span class=\"pi\">:</span> <span class=\"m\">9092</span>            <span class=\"pi\">-</span> <span class=\"na\">containerPort</span><span class=\"pi\">:</span> <span class=\"m\">9093</span>          <span class=\"na\">env</span><span class=\"pi\">:</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">REPLICAS</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">3'</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">SERVICE</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s\">kafka-svc</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">NAMESPACE</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">SHARE_DIR</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s\">/mnt/kafka</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">CLUSTER_ID</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s\">bXktY2x1c3Rlci0xMjM0NQ==</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">DEFAULT_REPLICATION_FACTOR</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">3'</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">DEFAULT_MIN_INSYNC_REPLICAS</span>              <span class=\"na\">value</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">2'</span>          <span class=\"na\">volumeMounts</span><span class=\"pi\">:</span>            <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">data</span>              <span class=\"na\">mountPath</span><span class=\"pi\">:</span> <span class=\"s\">/mnt/kafka</span>  <span class=\"na\">volumeClaimTemplates</span><span class=\"pi\">:</span>    <span class=\"pi\">-</span> <span class=\"na\">metadata</span><span class=\"pi\">:</span>        <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">data</span>      <span class=\"na\">spec</span><span class=\"pi\">:</span>        <span class=\"na\">accessModes</span><span class=\"pi\">:</span>          <span class=\"pi\">-</span> <span class=\"s2\">\"</span><span class=\"s\">ReadWriteOnce\"</span>        <span class=\"na\">resources</span><span class=\"pi\">:</span>          <span class=\"na\">requests</span><span class=\"pi\">:</span>            <span class=\"na\">storage</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">1Gi\"</span><span class=\"nn\">---</span><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span><span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Service</span><span class=\"na\">metadata</span><span class=\"pi\">:</span>  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">kafka-svc</span>  <span class=\"na\">namespace</span><span class=\"pi\">:</span> <span class=\"s\">kafka</span>  <span class=\"na\">labels</span><span class=\"pi\">:</span>    <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">kafka-app</span><span class=\"na\">spec</span><span class=\"pi\">:</span>  <span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">NodePort</span>  <span class=\"na\">ports</span><span class=\"pi\">:</span>    <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">9092'</span>      <span class=\"na\">port</span><span class=\"pi\">:</span> <span class=\"m\">9092</span>      <span class=\"na\">protocol</span><span class=\"pi\">:</span> <span class=\"s\">TCP</span>      <span class=\"na\">targetPort</span><span class=\"pi\">:</span> <span class=\"m\">9092</span>      <span class=\"na\">nodePort</span><span class=\"pi\">:</span> <span class=\"m\">30092</span>  <span class=\"na\">selector</span><span class=\"pi\">:</span>    <span class=\"na\">app</span><span class=\"pi\">:</span> <span class=\"s\">kafka-app</span></code></pre></div></div><p>4) Create a topic</p><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>kubectl <span class=\"nb\">exec</span> <span class=\"nt\">-it</span> kafka-0 <span class=\"nt\">-n</span> kafka <span class=\"nt\">--</span> bashkafka-topics.sh <span class=\"nt\">--create</span> <span class=\"nt\">--topic</span> my-topic <span class=\"nt\">--bootstrap-server</span> kafka-svc:9092kafka-topics.sh <span class=\"nt\">--list</span> <span class=\"nt\">--topic</span> my-topic <span class=\"nt\">--bootstrap-server</span> kafka-svc:9092</code></pre></div></div><p>5) Produce and consume message</p><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>kubectl <span class=\"nb\">exec</span> <span class=\"nt\">-it</span> kafka-1 <span class=\"nt\">-n</span> kafka <span class=\"nt\">--</span> bashkafka-console-producer.sh  <span class=\"nt\">--bootstrap-server</span> kafka-svc:9092 <span class=\"nt\">--topic</span> my-topickafka-console-consumer.sh <span class=\"nt\">--bootstrap-server</span> kafka-svc:9092 <span class=\"nt\">--topic</span> my-topic</code></pre></div></div><p>6) Delete topic</p><div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>kafka-topics.sh <span class=\"nt\">--delete</span> <span class=\"nt\">--topic</span> my-topic <span class=\"nt\">--bootstrap-server</span> kafka-svc:9092</code></pre></div></div><h2 id=\"kafka-kraft-x-kafka-with-zookeeper\">Kafka KRaft x Kafka with ZooKeeper</h2><p><strong>Kafka KRaft Installation</strong>: KRaft is Kafka‚Äôs new built-in consensus mechanism that eliminates the need for ZooKeeper. In a KRaft-based installation, Kafka brokers manage metadata and leader election directly, which simplifies the architecture by reducing dependencies. KRaft is becoming the default option in newer Kafka versions because it provides better scalability, faster failover, and an overall more streamlined operation.</p><p><strong>Kafka with ZooKeeper</strong>: In traditional Kafka deployments, ZooKeeper is used to manage the cluster‚Äôs metadata, such as broker details and topic configurations. ZooKeeper handles tasks like leader election and tracking which brokers are active. While this setup has been robust for years, it adds complexity by requiring an additional service (ZooKeeper) that must be installed, managed, and maintained alongside Kafka.</p>",
            "url": "/2024/09/29/kafka-on-kubernetes-using-kind.html",
            
            
            
            "tags": ["kafka","kind","kubernetes"],
            
            "date_published": "2024-09-29T00:00:00+00:00",
            "date_modified": "2024-09-29T00:00:00+00:00",
            
                "author": 
                ""
                
            
        },
    
        {
            "id": "/2024/09/28/containers-mastery.html",
            "title": "üì¶ Containers Mastery",
            "summary": "Tips and Tricks for Containers",
            "content_text": "What is Linux container ?A Linux container is a lightweight and portable unit that encapsulates an application and its dependencies. Containers utilize key Linux kernel features for process isolation and resource management, including namespaces (for isolating resources like PID, network, and filesystem) and control groups (cgroups) (for limiting and prioritizing resource usage). Additionally, union file systems enable efficient layering and storage of container images. Together, these features allow containers to operate efficiently and securely on a shared host. Basically a container image is composed of  Dependencies  Application code  Container configuration  Base imageContainer runtimeA container runtime is a software component that is responsible for running and managing containers. Containers are lightweight, portable units that package an application and its dependencies, allowing them to run consistently across different environments.  Docker  containerd  CRI-O  runc  Podman  LXC/LXD  systemd-nspawn (Don‚Äôt be angry with me)Don‚Äôt compare Docker with KubernetesIt just doesn‚Äôt make sense.. comparing Docker and Kubernetes can be confusing for beginners because they serve different purposes: Docker implements the concept of containers, while Kubernetes orchestrates those containers. An analogy is comparing a car (Docker) to a traffic system (Kubernetes); the car allows you to drive (create and run containers), while the traffic system manages the flow of multiple cars (orchestrates the deployment and scaling of containers). This distinction is crucial, as it clarifies that Docker focuses on the containerization process itself, while Kubernetes handles the management of containerized applications at scale.Container SecurityHaving secure base images for containers is crucial for maintaining the overall security of the host system. Images without elevated privileges help minimize potential attack vectors, reducing the risk of container escape and unauthorized access to the host. While concerns about insecure images are valid, it‚Äôs important to note that this is not the worst-case scenario, as containers typically run in a private network. For an attacker to exploit these vulnerabilities significantly, they would need to compromise additional components of the infrastructure, making it a more complex attack path. Therefore, while secure base images are essential, the overall security posture can still be robust with proper network isolation and access controls in place.SAST (Static Application Security Testing) and SCA (Software Composition Analysis) are essential complementary approaches for ensuring application security. While SAST analyzes the source code for vulnerabilities before execution, SCA focuses on third-party libraries and dependencies, checking for known flaws. Integrating both practices is crucial, as it allows for the identification of internal code issues and external risks associated with software components. Tools like SonarQube and Fortify for SAST, and Black Duck and Snyk for SCA, provide robust solutions to mitigate vulnerabilities, offering more comprehensive security throughout the software development lifecycle.In summary, ensure that you use secure base images that prevent vulnerabilities and do not allow root access. Conduct thorough security testing and utilize a scanning tool with an up-to-date CVE database. Keep your images minimal, as even a simple curl command can be exploited by skilled attackers. Implement read-only filesystems to enhance security and adopt practices that make updating images simple and efficient.  Quay  trivy  Docker Desktop (Docker Scout) Vulnerability ScanContainer registryA container registry is a centralized repository where container images are stored, managed, and distributed. Examples of usage include:  Docker Hub  Google Container Registry (GCR)  Amazon Elastic Container Registry (ECR)  Azure Container Registry (ACR)  Harbor  Quay  GitLab Container Registry  JFrog Container RegistryTools for working with containers  dive  Docker CLI  ctr  lazydockerSpecial images  dbeaver/cloudbeaver  netdata/netdata  lscr.io/linuxserver/wireshark:latest  nicolargo/glances  minio/minioBuilding my imagesTypically, each programming language adheres to certain conventions for images. The goal is usually to create a lightweight and secure image. We can leverage concepts such as multi-stage builds and base images with community support. Some best practices include:  Use Multi-Stage Builds: This approach allows you to minimize the final image size by separating the build environment from the production environment.  Choose Official Base Images: Opt for official images from reputable sources to ensure security and reliability.  Keep Images Lightweight: Remove unnecessary files and dependencies to reduce the image size and improve performance.  Regularly Update Images: Stay current with updates to base images and dependencies to mitigate security vulnerabilities.  Use Specific Version Tags: Instead of using ‚Äúlatest,‚Äù specify the exact version of images to avoid unexpected changes in your application.  Scan for Vulnerabilities: Regularly scan your images for known vulnerabilities to maintain security.  Document Image Purpose and Usage: Include clear documentation about the image‚Äôs purpose, usage, and configuration to facilitate easier maintenance and onboarding.Deep dive ? not today..Namespaces and Cgroups ArchitectureNamespaces are a fundamental aspect of containerization, providing isolation for various resources on a Linux system. Each namespace creates a distinct environment for processes, ensuring that they only interact with their own set of resources. For example, the PID namespace allows processes to have their own process IDs, making it appear as though they are the only ones running on the system. Similarly, network namespaces enable containers to have unique network interfaces and IP addresses, preventing interference between containers. Understanding how these namespaces work is essential for developers to effectively manage resource allocation and maintain a secure environment.Control groups (cgroups) complement namespaces by allowing for fine-grained resource management. They enable administrators to limit and prioritize CPU, memory, and I/O usage for groups of processes, ensuring that no single container can monopolize system resources. With cgroups, users can define resource limits, monitor usage, and enforce constraints in a way that is transparent to the applications running within the containers. This architecture not only optimizes resource allocation but also enhances overall system stability by preventing resource contention.Overlay Filesystem and Copy-on-WriteThe Overlay filesystem is a crucial technology in containerization, facilitating the creation of layered filesystems that optimize storage and performance. By allowing multiple layers to be stacked, OverlayFS enables efficient management of container images, where each layer can be modified without affecting the underlying layers. This Copy-on-Write (CoW) mechanism ensures that changes made to a file in a container do not overwrite the original file in the base image. Instead, the container creates a new layer for modifications, allowing for quick and efficient updates while conserving disk space.Using OverlayFS not only improves storage efficiency but also enhances the speed of container operations. As containers are deployed, they only need to load the layers that have changed, significantly reducing the time required to start a container. Additionally, this layering approach allows for easy version control and rollback capabilities. If a change introduces an issue, reverting to a previous version can be done swiftly by switching back to the corresponding base image, thereby minimizing downtime and potential disruptions.Container Runtimes ComparisonContainer runtimes are essential components that facilitate the execution and management of containers, each with unique features and capabilities. Docker, for instance, is a widely recognized runtime that simplifies the process of building, running, and sharing containers. On the other hand, containerd serves as a high-level container runtime, providing a robust platform for managing the complete lifecycle of containers. CRI-O, specifically designed for Kubernetes, focuses on optimizing the performance and resource utilization of containerized applications within orchestration environments. Each runtime caters to different needs, making it important for developers to choose the right one based on their specific use cases and operational requirements.When comparing these runtimes, one must consider factors such as performance, compatibility, and community support. While Docker provides an all-in-one solution for container management, it may introduce overhead that isn‚Äôt present in lighter runtimes like runc, which focuses solely on running containers. Additionally, Podman offers a daemonless experience that enables users to run containers without needing a central service, appealing to those who prioritize security and simplicity. Ultimately, understanding the distinctions between these runtimes helps developers select the most appropriate tools for their containerization strategies.Network Namespaces and Networking ModelsNetwork namespaces are critical for ensuring that containers can communicate while remaining isolated from one another. Each network namespace has its own network stack, including interfaces, routing tables, and firewall rules, allowing containers to function as if they are on separate hosts. This isolation is essential for security, as it prevents unauthorized access between containers and enhances overall system integrity. Additionally, networking models such as bridge networking, overlay networking, and macvlan provide different levels of connectivity and isolation, enabling users to tailor their networking setup based on application needs and deployment scenarios.Understanding these networking models is crucial for optimizing communication between containers. For instance, bridge networking is often used for simpler applications that require direct communication with the host, while overlay networking is ideal for applications deployed across multiple hosts in a cluster, such as those orchestrated by Kubernetes. By leveraging tools like Flannel, Calico, or Cilium, developers can create robust networking solutions that enhance container security and performance. The choice of networking model significantly impacts the architecture of containerized applications and their ability to scale effectively.Advanced Container SecurityContainer security is a multifaceted discipline that involves implementing various strategies to safeguard containerized applications from potential threats. One of the primary focuses is ensuring the use of secure base images, as vulnerabilities in these images can lead to significant risks. Images should be built without elevated privileges to minimize the attack surface, reducing the chances of container escape and unauthorized access to the host system. Additionally, regular vulnerability scanning is essential to identify and remediate any security flaws in the base images and application dependencies, maintaining a strong security posture throughout the container lifecycle.Advanced security measures extend beyond just using secure images; they also encompass implementing Linux capabilities to limit permissions, using Seccomp to filter system calls, and configuring AppArmor profiles for enhanced security. Rootless containers further elevate security by allowing users to run containers without root privileges, significantly reducing the risk of privilege escalation attacks. By integrating these practices, organizations can create a layered security approach that effectively mitigates potential risks while ensuring that containerized applications remain robust and resilient against emerging threats.Volume Management and Data PersistenceEffective volume management is essential for ensuring data persistence in containerized applications. Unlike traditional virtual machines, containers are ephemeral, meaning any data stored within a container is lost once it is stopped or removed. To address this challenge, Docker and other container orchestration platforms provide mechanisms for managing volumes, which allow data to persist independently of the container lifecycle. Volumes can be created and managed easily, enabling developers to store important data, such as databases or user uploads, securely.There are two primary types of storage options for containers: bind mounts and named volumes. Bind mounts allow specific directories on the host to be mounted into a container, providing direct access to host files. However, they can introduce complexity and potential security risks if not managed properly. In contrast, named volumes are managed by the container runtime, offering a more abstracted approach that simplifies data management. By adopting best practices for volume management, such as isolating data from application logic and regularly backing up volumes, developers can ensure that their applications maintain data integrity and resilience in production environments.Advanced Container OrchestrationAdvanced container orchestration is crucial for managing the deployment, scaling, and operation of containerized applications in complex environments. Kubernetes, as a leading orchestration platform, provides robust features for automating the management of containerized applications across clusters. It facilitates load balancing, automated scaling, and self-healing capabilities, allowing organizations to maintain high availability and performance in their applications. Understanding Kubernetes internals, such as the roles of the kubelet, kube-scheduler, and controller manager, empowers developers to optimize their deployment strategies and resource allocation effectively.In addition to Kubernetes, modern orchestration frameworks also support advanced deployment strategies, such as blue-green deployments and canary releases. These methods enable teams to introduce new features gradually, minimizing risk and ensuring a smooth user experience. By leveraging ConfigMaps and Secrets, developers can manage application configurations and sensitive data securely within the orchestration platform. Ultimately, mastering advanced orchestration techniques enhances the efficiency and reliability of containerized applications, driving innovation and agility in software development and deployment.",
            "content_html": "<h2 id=\"what-is-linux-container-\">What is Linux container ?</h2><p>A Linux container is a lightweight and portable unit that encapsulates an application and its dependencies. Containers utilize key Linux kernel features for process isolation and resource management, including namespaces (for isolating resources like PID, network, and filesystem) and control groups (cgroups) (for limiting and prioritizing resource usage). Additionally, union file systems enable efficient layering and storage of container images. Together, these features allow containers to operate efficiently and securely on a shared host. Basically a container image is composed of</p><ul>  <li>Dependencies</li>  <li>Application code</li>  <li>Container configuration</li>  <li>Base image</li></ul><h2 id=\"container-runtime\">Container runtime</h2><p>A container runtime is a software component that is responsible for running and managing containers. Containers are lightweight, portable units that package an application and its dependencies, allowing them to run consistently across different environments.</p><ul>  <li>Docker</li>  <li>containerd</li>  <li>CRI-O</li>  <li>runc</li>  <li>Podman</li>  <li>LXC/LXD</li>  <li>systemd-nspawn (Don‚Äôt be angry with me)</li></ul><h2 id=\"dont-compare-docker-with-kubernetes\">Don‚Äôt compare Docker with Kubernetes</h2><p>It just doesn‚Äôt make sense.. comparing Docker and Kubernetes can be confusing for beginners because they serve different purposes: Docker implements the concept of containers, while Kubernetes orchestrates those containers. An analogy is comparing a car (Docker) to a traffic system (Kubernetes); the car allows you to drive (create and run containers), while the traffic system manages the flow of multiple cars (orchestrates the deployment and scaling of containers). This distinction is crucial, as it clarifies that Docker focuses on the containerization process itself, while Kubernetes handles the management of containerized applications at scale.</p><h2 id=\"container-security\">Container Security</h2><p>Having secure base images for containers is crucial for maintaining the overall security of the host system. Images without elevated privileges help minimize potential attack vectors, reducing the risk of container escape and unauthorized access to the host. While concerns about insecure images are valid, it‚Äôs important to note that this is not the worst-case scenario, as containers typically run in a private network. For an attacker to exploit these vulnerabilities significantly, they would need to compromise additional components of the infrastructure, making it a more complex attack path. Therefore, while secure base images are essential, the overall security posture can still be robust with proper network isolation and access controls in place.</p><p>SAST (Static Application Security Testing) and SCA (Software Composition Analysis) are essential complementary approaches for ensuring application security. While SAST analyzes the source code for vulnerabilities before execution, SCA focuses on third-party libraries and dependencies, checking for known flaws. Integrating both practices is crucial, as it allows for the identification of internal code issues and external risks associated with software components. Tools like SonarQube and Fortify for SAST, and Black Duck and Snyk for SCA, provide robust solutions to mitigate vulnerabilities, offering more comprehensive security throughout the software development lifecycle.</p><p>In summary, ensure that you use secure base images that prevent vulnerabilities and do not allow root access. Conduct thorough security testing and utilize a scanning tool with an up-to-date CVE database. Keep your images minimal, as even a simple curl command can be exploited by skilled attackers. Implement read-only filesystems to enhance security and adopt practices that make updating images simple and efficient.</p><ul>  <li>Quay</li>  <li>trivy</li>  <li>Docker Desktop (Docker Scout) Vulnerability Scan</li></ul><h2 id=\"container-registry\">Container registry</h2><p>A container registry is a centralized repository where container images are stored, managed, and distributed. Examples of usage include:</p><ul>  <li>Docker Hub</li>  <li>Google Container Registry (GCR)</li>  <li>Amazon Elastic Container Registry (ECR)</li>  <li>Azure Container Registry (ACR)</li>  <li>Harbor</li>  <li>Quay</li>  <li>GitLab Container Registry</li>  <li>JFrog Container Registry</li></ul><h2 id=\"tools-for-working-with-containers\">Tools for working with containers</h2><ul>  <li>dive</li>  <li>Docker CLI</li>  <li>ctr</li>  <li>lazydocker</li></ul><h2 id=\"special-images\">Special images</h2><ul>  <li>dbeaver/cloudbeaver</li>  <li>netdata/netdata</li>  <li>lscr.io/linuxserver/wireshark:latest</li>  <li>nicolargo/glances</li>  <li>minio/minio</li></ul><h2 id=\"building-my-images\">Building my images</h2><p>Typically, each programming language adheres to certain conventions for images. The goal is usually to create a lightweight and secure image. We can leverage concepts such as multi-stage builds and base images with community support. Some best practices include:</p><ul>  <li>Use Multi-Stage Builds: This approach allows you to minimize the final image size by separating the build environment from the production environment.</li>  <li>Choose Official Base Images: Opt for official images from reputable sources to ensure security and reliability.</li>  <li>Keep Images Lightweight: Remove unnecessary files and dependencies to reduce the image size and improve performance.</li>  <li>Regularly Update Images: Stay current with updates to base images and dependencies to mitigate security vulnerabilities.</li>  <li>Use Specific Version Tags: Instead of using ‚Äúlatest,‚Äù specify the exact version of images to avoid unexpected changes in your application.</li>  <li>Scan for Vulnerabilities: Regularly scan your images for known vulnerabilities to maintain security.</li>  <li>Document Image Purpose and Usage: Include clear documentation about the image‚Äôs purpose, usage, and configuration to facilitate easier maintenance and onboarding.</li></ul><h2 id=\"deep-dive--not-today\">Deep dive ? not today..</h2><h4 id=\"namespaces-and-cgroups-architecture\">Namespaces and Cgroups Architecture</h4><p>Namespaces are a fundamental aspect of containerization, providing isolation for various resources on a Linux system. Each namespace creates a distinct environment for processes, ensuring that they only interact with their own set of resources. For example, the PID namespace allows processes to have their own process IDs, making it appear as though they are the only ones running on the system. Similarly, network namespaces enable containers to have unique network interfaces and IP addresses, preventing interference between containers. Understanding how these namespaces work is essential for developers to effectively manage resource allocation and maintain a secure environment.</p><p>Control groups (cgroups) complement namespaces by allowing for fine-grained resource management. They enable administrators to limit and prioritize CPU, memory, and I/O usage for groups of processes, ensuring that no single container can monopolize system resources. With cgroups, users can define resource limits, monitor usage, and enforce constraints in a way that is transparent to the applications running within the containers. This architecture not only optimizes resource allocation but also enhances overall system stability by preventing resource contention.</p><h4 id=\"overlay-filesystem-and-copy-on-write\">Overlay Filesystem and Copy-on-Write</h4><p>The Overlay filesystem is a crucial technology in containerization, facilitating the creation of layered filesystems that optimize storage and performance. By allowing multiple layers to be stacked, OverlayFS enables efficient management of container images, where each layer can be modified without affecting the underlying layers. This Copy-on-Write (CoW) mechanism ensures that changes made to a file in a container do not overwrite the original file in the base image. Instead, the container creates a new layer for modifications, allowing for quick and efficient updates while conserving disk space.</p><p>Using OverlayFS not only improves storage efficiency but also enhances the speed of container operations. As containers are deployed, they only need to load the layers that have changed, significantly reducing the time required to start a container. Additionally, this layering approach allows for easy version control and rollback capabilities. If a change introduces an issue, reverting to a previous version can be done swiftly by switching back to the corresponding base image, thereby minimizing downtime and potential disruptions.</p><h4 id=\"container-runtimes-comparison\">Container Runtimes Comparison</h4><p>Container runtimes are essential components that facilitate the execution and management of containers, each with unique features and capabilities. Docker, for instance, is a widely recognized runtime that simplifies the process of building, running, and sharing containers. On the other hand, containerd serves as a high-level container runtime, providing a robust platform for managing the complete lifecycle of containers. CRI-O, specifically designed for Kubernetes, focuses on optimizing the performance and resource utilization of containerized applications within orchestration environments. Each runtime caters to different needs, making it important for developers to choose the right one based on their specific use cases and operational requirements.</p><p>When comparing these runtimes, one must consider factors such as performance, compatibility, and community support. While Docker provides an all-in-one solution for container management, it may introduce overhead that isn‚Äôt present in lighter runtimes like runc, which focuses solely on running containers. Additionally, Podman offers a daemonless experience that enables users to run containers without needing a central service, appealing to those who prioritize security and simplicity. Ultimately, understanding the distinctions between these runtimes helps developers select the most appropriate tools for their containerization strategies.</p><h4 id=\"network-namespaces-and-networking-models\">Network Namespaces and Networking Models</h4><p>Network namespaces are critical for ensuring that containers can communicate while remaining isolated from one another. Each network namespace has its own network stack, including interfaces, routing tables, and firewall rules, allowing containers to function as if they are on separate hosts. This isolation is essential for security, as it prevents unauthorized access between containers and enhances overall system integrity. Additionally, networking models such as bridge networking, overlay networking, and macvlan provide different levels of connectivity and isolation, enabling users to tailor their networking setup based on application needs and deployment scenarios.</p><p>Understanding these networking models is crucial for optimizing communication between containers. For instance, bridge networking is often used for simpler applications that require direct communication with the host, while overlay networking is ideal for applications deployed across multiple hosts in a cluster, such as those orchestrated by Kubernetes. By leveraging tools like Flannel, Calico, or Cilium, developers can create robust networking solutions that enhance container security and performance. The choice of networking model significantly impacts the architecture of containerized applications and their ability to scale effectively.</p><h4 id=\"advanced-container-security\">Advanced Container Security</h4><p>Container security is a multifaceted discipline that involves implementing various strategies to safeguard containerized applications from potential threats. One of the primary focuses is ensuring the use of secure base images, as vulnerabilities in these images can lead to significant risks. Images should be built without elevated privileges to minimize the attack surface, reducing the chances of container escape and unauthorized access to the host system. Additionally, regular vulnerability scanning is essential to identify and remediate any security flaws in the base images and application dependencies, maintaining a strong security posture throughout the container lifecycle.</p><p>Advanced security measures extend beyond just using secure images; they also encompass implementing Linux capabilities to limit permissions, using Seccomp to filter system calls, and configuring AppArmor profiles for enhanced security. Rootless containers further elevate security by allowing users to run containers without root privileges, significantly reducing the risk of privilege escalation attacks. By integrating these practices, organizations can create a layered security approach that effectively mitigates potential risks while ensuring that containerized applications remain robust and resilient against emerging threats.</p><h4 id=\"volume-management-and-data-persistence\">Volume Management and Data Persistence</h4><p>Effective volume management is essential for ensuring data persistence in containerized applications. Unlike traditional virtual machines, containers are ephemeral, meaning any data stored within a container is lost once it is stopped or removed. To address this challenge, Docker and other container orchestration platforms provide mechanisms for managing volumes, which allow data to persist independently of the container lifecycle. Volumes can be created and managed easily, enabling developers to store important data, such as databases or user uploads, securely.</p><p>There are two primary types of storage options for containers: bind mounts and named volumes. Bind mounts allow specific directories on the host to be mounted into a container, providing direct access to host files. However, they can introduce complexity and potential security risks if not managed properly. In contrast, named volumes are managed by the container runtime, offering a more abstracted approach that simplifies data management. By adopting best practices for volume management, such as isolating data from application logic and regularly backing up volumes, developers can ensure that their applications maintain data integrity and resilience in production environments.</p><h4 id=\"advanced-container-orchestration\">Advanced Container Orchestration</h4><p>Advanced container orchestration is crucial for managing the deployment, scaling, and operation of containerized applications in complex environments. Kubernetes, as a leading orchestration platform, provides robust features for automating the management of containerized applications across clusters. It facilitates load balancing, automated scaling, and self-healing capabilities, allowing organizations to maintain high availability and performance in their applications. Understanding Kubernetes internals, such as the roles of the kubelet, kube-scheduler, and controller manager, empowers developers to optimize their deployment strategies and resource allocation effectively.</p><p>In addition to Kubernetes, modern orchestration frameworks also support advanced deployment strategies, such as blue-green deployments and canary releases. These methods enable teams to introduce new features gradually, minimizing risk and ensuring a smooth user experience. By leveraging ConfigMaps and Secrets, developers can manage application configurations and sensitive data securely within the orchestration platform. Ultimately, mastering advanced orchestration techniques enhances the efficiency and reliability of containerized applications, driving innovation and agility in software development and deployment.</p>",
            "url": "/2024/09/28/containers-mastery.html",
            
            
            
            "tags": ["linux","containers","docker"],
            
            "date_published": "2024-09-28T00:00:00+00:00",
            "date_modified": "2024-09-28T00:00:00+00:00",
            
                "author": 
                ""
                
            
        },
    
        {
            "id": "/2024/09/27/l0calh0t-startup-day1.html",
            "title": "üí° l0calh0t Startup - day 1",
            "summary": "Building the l0calh0t Startup",
            "content_text": "About the projectI recently saw a project on YouTube where the YouTuber created a complete technology environment to support a fake product. I liked the idea and thought about creating a real project‚Ä¶ starting from localhost to production. I don‚Äôt consider myself a good programmer, but I‚Äôm looking for a well-made bean and rice. My main focus is to launch a stable product with acceptable security standards and that simply implements the idea as it is now in my mind. I present to you the l0calh0t startup. You can follow the progress of this through a series of articles on this blog!note: don‚Äôt take me too seriouslyI know there are already similar projects on the internet, but most of them focus on development and not on operations. I have two main goals. The first is to test technologies, discuss decisions and show concerns that usually arise when our project goes into production. The second is to perhaps make some money with this. My initial focus is Brazilian software developers. In general, I get along well with developers. I believe it is because every day I help them solve problems. Developers change, but the problems are usually the same.Let‚Äôs get started. What follows is information about the startup. To be quite honest, what I intend to build already exists, something similar to render.com.. but my ideas go a little further(if I can implement it, of course xD).l0calh0t üöÄüöÄüöÄAbout the startupl0calh0t is not introducing an innovative solution but rather offering a new way of delivering container-based application hosting, designed for developers of all levels, SREs, DevOps, and QAs. By abstracting infrastructure and networking, it enables fast, cost-effective container deployment. Users can make applications publicly accessible or control access as needed. Unlike traditional solutions focused on large enterprises with strict SLAs, l0calh0t prioritizes simplicity and accessibility, creating an agile environment for rapid testing and iteration, without the complexity of managing traditional servers.I‚Äôm still thinking about the legal issues..About the ideaThe idea is basically a render.com with some differences. I want to do something more ‚Äúapi first‚Äù. I want to do it in a way that is similar to the way people work with containers locally and I also want to offer a way for them to have details about their applications by adding components to the infrastructure that abstract away the complexity of doing so.What do I need?Considering that I have no money, no computing resources, and no advanced programming skills (that makes it hard ü§£ü§£), I need to focus on something simple that works. I want to create a business abstraction on top of Kubernetes and put all the complexity into it using tools I have experience with. I need a cheap domain like localhot.io. I need a payment method and reasonable bandwidth. I want to physically separate the servers where the startup‚Äôs applications are from the servers where the end-user containers will be. I need to think about security and a business model that is viable for Brazilian developers.For the first poc‚Äôs, the simpler the better. I intend to use python or golang for this. I will use kind as the local kubernetes environment, the local registry of my machine for the images and also my local network (I run a certain risk).The networking part is very important in this project, but first I want a functional MVP.About my localhost (workstation)My computer settings are  Intel(R) Core(TM) i5-9400 CPU @ 2.90GHz;  16 RAM;  440G SSD;  EndeavourOS[2024-10-02 15:27:45] UPDATE - I‚Äôve decided that a hardware upgrade is unfeasible‚Ä¶ It‚Äôs time to build a new PC. !!!End(?)So, that‚Äôs it. I‚Äôve reached the end of my first article. I hope I‚Äôve been clear about my idea. In the end, even if everything goes wrong, I will have gained valuable knowledge. These notes may be useful to someone else, and even to my future self. What‚Äôs coming next? A series of reflections, articles about random tools, and some not-so-professional code (:See you around, fellas!!",
            "content_html": "<h2 id=\"about-the-project\">About the project</h2><p>I recently saw a project on YouTube where the YouTuber created a complete technology environment to support a fake product. I liked the idea and thought about creating a real project‚Ä¶ starting from localhost to production. I don‚Äôt consider myself a good programmer, but I‚Äôm looking for a well-made bean and rice. My main focus is to launch a stable product with acceptable security standards and that simply implements the idea as it is now in my mind. I present to you the <strong>l0calh0t</strong> startup. You can follow the progress of this through a series of articles on this blog!</p><p><strong>note</strong>: <em>don‚Äôt take me too seriously</em></p><p>I know there are already similar projects on the internet, but most of them focus on <em>development</em> and not on <em>operations</em>. I have two main goals. The first is to test technologies, discuss decisions and show concerns that usually arise when our project goes into production. The second is to perhaps make some money with this. My initial focus is Brazilian software developers. In general, I get along well with developers. I believe it is because every day I help them solve problems. Developers change, but the problems are usually the same.</p><p>Let‚Äôs get started. What follows is information about the startup. To be quite honest, what I intend to build already exists, something similar to <em>render.com</em>.. but my ideas go a little further(if I can implement it, of course xD).</p><h2 id=\"l0calh0t-\">l0calh0t üöÄüöÄüöÄ</h2><h3 id=\"about-the-startup\">About the startup</h3><p><strong>l0calh0t</strong> is not introducing an innovative solution but rather offering <strong>a new way of delivering container-based application hosting</strong>, designed for developers of all levels, SREs, DevOps, and QAs. By abstracting infrastructure and networking, it enables fast, cost-effective container deployment. Users can make applications publicly accessible or control access as needed. Unlike traditional solutions focused on large enterprises with strict SLAs, <strong>l0calh0t</strong> prioritizes simplicity and accessibility, creating an agile environment for rapid testing and iteration, without the complexity of managing traditional servers.</p><p>I‚Äôm still thinking about the legal issues..</p><h3 id=\"about-the-idea\">About the idea</h3><p>The idea is basically a <em>render.com</em> with some differences. I want to do something more ‚Äúapi first‚Äù. I want to do it in a way that is similar to the way people work with containers locally and I also want to offer a way for them to have details about their applications by adding components to the infrastructure that abstract away the complexity of doing so.</p><h3 id=\"what-do-i-need\">What do I need?</h3><p>Considering that I have no money, no computing resources, and no advanced programming skills (that makes it hard ü§£ü§£), I need to focus on something simple that works. I want to create a business abstraction on top of Kubernetes and put all the complexity into it using tools I have experience with. I need a cheap domain like <strong>localhot.io</strong>. I need a payment method and reasonable bandwidth. I want to physically separate the servers where the startup‚Äôs applications are from the servers where the end-user containers will be. I need to think about security and a business model that is viable for Brazilian developers.</p><p>For the first poc‚Äôs, the simpler the better. I intend to use python or golang for this. I will use kind as the local kubernetes environment, the local registry of my machine for the images and also my local network (I run a certain risk).The networking part is very important in this project, but first I want a functional MVP.</p><h3 id=\"about-my-localhost-workstation\">About my localhost (workstation)</h3><p>My computer settings are</p><ul>  <li>Intel(R) Core(TM) i5-9400 CPU @ 2.90GHz;</li>  <li>16 RAM;</li>  <li>440G SSD;</li>  <li>EndeavourOS</li></ul><p><strong>[2024-10-02 15:27:45]</strong> UPDATE - <em>I‚Äôve decided that a hardware upgrade is unfeasible‚Ä¶ It‚Äôs time to build a new PC. !!!</em></p><h3 id=\"end\">End(?)</h3><p>So, that‚Äôs it. I‚Äôve reached the end of my first article. I hope I‚Äôve been clear about my idea. In the end, even if everything goes wrong, I will have gained valuable knowledge. These notes may be useful to someone else, and even to my future self. What‚Äôs coming next? A series of reflections, articles about random tools, and some not-so-professional code <strong>(</strong>:</p><p>See you around, fellas!!</p>",
            "url": "/2024/09/27/l0calh0t-startup-day1.html",
            
            
            
            "tags": ["devops","sre","project","startup"],
            
            "date_published": "2024-09-27T00:00:00+00:00",
            "date_modified": "2024-09-27T00:00:00+00:00",
            
                "author": 
                ""
                
            
        },
    
        {
            "id": "/2024/09/26/DISCLAIMER.html",
            "title": "‚ö†Ô∏è DISCLAIMER",
            "summary": "DISCLAIMER and GOALS",
            "content_text": "DISCLAIMER  I write for myself  My first language is Brazilian Portuguese, but I‚Äôm learning English and will use it here. You will likely see some writing mistakes; it‚Äôs part of learning  I have worked as a Reliability Engineer only in Brazil (until now)  I plan to discuss reliability topics and other subjects like security, processes, governance, and soft skills  Feedback is always welcome as long as it‚Äôs constructive. Feel free to contact me on Telegram or Discord, but please be respectful (@apolzek)  Remember, everything here is open to discussion. You should form your own opinionsGOALS  Talk about tools that are not well-known but have great potential  Track my studies with short reflective articles  Share my views on technologies, processes, and products  Soon, I will revisit my notes to see how my views on certain topics have changedREMEMBERüá∫üá∏ ‚ÄúThe only way to make things work well is by understanding why they break.‚Äùüáßüá∑ ‚ÄúA √∫nica maneira de fazer as coisas funcionarem bem √© entendendo o motivo pelo qual elas quebram.‚Äù",
            "content_html": "<h2 id=\"disclaimer\">DISCLAIMER</h2><ul>  <li>I write for myself</li>  <li>My first language is Brazilian Portuguese, but I‚Äôm learning English and will use it here. You will likely see some writing mistakes; it‚Äôs part of learning</li>  <li>I have worked as a Reliability Engineer only in Brazil (<em>until now</em>)</li>  <li>I plan to discuss reliability topics and other subjects like security, processes, governance, and soft skills</li>  <li>Feedback is always welcome as long as it‚Äôs constructive. Feel free to contact me on Telegram or Discord, but please be respectful (<em>@apolzek</em>)</li>  <li>Remember, everything here is open to discussion. You should form your <strong>own opinions</strong></li></ul><h2 id=\"goals\">GOALS</h2><ul>  <li>Talk about tools that are not well-known but have great potential</li>  <li>Track my studies with short reflective articles</li>  <li>Share my views on technologies, processes, and products</li>  <li>Soon, I will revisit my notes to see how my views on certain topics have changed</li></ul><h2 id=\"remember\">REMEMBER</h2><p>üá∫üá∏ ‚ÄúThe only way to make things work well is by understanding why they break.‚Äù</p><p>üáßüá∑ ‚ÄúA √∫nica maneira de fazer as coisas funcionarem bem √© entendendo o motivo pelo qual elas quebram.‚Äù</p>",
            "url": "/2024/09/26/DISCLAIMER.html",
            
            
            
            "tags": ["disclaimer","goals"],
            
            "date_published": "2024-09-26T00:00:00+00:00",
            "date_modified": "2024-09-26T00:00:00+00:00",
            
                "author": 
                ""
                
            
        }
    
    ]
}